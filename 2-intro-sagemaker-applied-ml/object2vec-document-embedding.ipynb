{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Embedding with Amazon SageMaker Object2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Background](#Background)\n",
    "  1. [Embedding documents using Object2Vec](#Embedding-documents-using-Object2Vec)\n",
    "3. [Download and preprocess Wikipedia data](#Download-and-preprocess-Wikipedia-data)\n",
    "  1. [Install and load dependencies](#Install-and-load-dependencies)\n",
    "  2. [Build vocabulary and tokenize datasets](#Build-vocabulary-and-tokenize-datasets)\n",
    "  3. [Upload preprocessed data to S3](#Upload-preprocessed-data-to-S3)\n",
    "4. [Define SageMaker session, Object2Vec image, S3 input and output paths](#Define-SageMaker-session,-Object2Vec-image,-S3-input-and-output-paths)\n",
    "5. [Train and deploy doc2vec](#Train-and-deploy-doc2vec)\n",
    "  1. [Learning performance boost with new features](#Learning-performance-boost-with-new-features)\n",
    "  2. [Training speedup with sparse gradient update](#Training-speedup-with-sparse-gradient-update)\n",
    "6. [Apply learned embeddings to document retrieval task](#Apply-learned-embeddings-to-document-retrieval-task)\n",
    "  1. [Comparison with the StarSpace algorithm](#Comparison-with-the-StarSpace-algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we introduce four new features to Object2Vec, a general-purpose neural embedding algorithm: negative sampling, sparse gradient update, weight-sharing, and comparator operator customization. The new features together broaden the applicability of Object2Vec, improve its training speed and accuracy, and provide users with greater flexibility. See [Introduction to the Amazon SageMaker Object2Vec](https://aws.amazon.com/blogs/machine-learning/introduction-to-amazon-sagemaker-object2vec/) if you arenâ€™t already familiar with Object2Vec.\n",
    "\n",
    "We demonstrate how these new features extend the applicability of Object2Vec to a new Document Embedding use-case: A customer has a large collection of documents. Instead of storing these documents in its raw format or as sparse bag-of-words vectors, to achieve training efficiency in the various downstream tasks, she would like to instead embed all documents in a common low-dimensional space, so that the semantic distance between these documents are preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object2Vec is a highly customizable multi-purpose algorithm that can learn embeddings of pairs of objects. The embeddings are learned such that it preserves their pairwise similarities in the original space.\n",
    "\n",
    "- Similarity is user-defined: users need to provide the algorithm with pairs of objects that they define as similar (1) or dissimilar (0); alternatively, the users can define similarity in a continuous sense (provide a real-valued similarity score).\n",
    "\n",
    "- The learned embeddings can be used to efficiently compute nearest neighbors of objects, as well as to visualize natural clusters of related objects in the embedding space. In addition, the embeddings can also be used as features of the corresponding objects in downstream supervised tasks such as classification or regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding documents using Object2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We demonstrate how, with the new features, Object2Vec can be used to embed a large collection of documents into vectors in the same latent space.\n",
    "\n",
    "Similar to the widely used Word2Vec algorithm for word embedding, a natural approach to document embedding is to preprocess documents as (sentence, context) pairs, where the sentence and its matching context come from the same document. The matching context is the entire document with the given sentence removed. The idea is to embed both sentence and context into a low dimensional space such that their mutual similarity is maximized, since they belong to the same document and therefore should be semantically related. The learned encoder for the context can then be used to encode new documents into the same embedding space. In order to train the encoders for sentences and documents, we also need negative (sentence, context) pairs so that the model can learn to discriminate between semantically similar and dissimilar pairs. It is easy to generate such negatives by pairing sentences with documents that they do not belong to. Since there are many more negative pairs than positives in naturally occurring data, we typically resort to random sampling techniques to achieve a balance between positive and negative pairs in the training data. The figure below shows pictorially how the positive pairs and negative pairs are generated from unlabeled data for the purpose of learning embeddings for documents (and sentences)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"doc_embedding_illustration.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show how Object2Vec with the new *negative sampling feature* can be applied to the document embedding use-case. In addition, we show how the other new features, namely, *weight-sharing*, *customization of comparator operator*, and *sparse gradient update*, together enhance the algorithm's performance and user-experience in and beyond this use-case. Sections [Learning performance boost with new features](#Learning-performance-boost-with-new-features) and [Training speedup with sparse gradient update](#Training-speedup-with-sparse-gradient-update) in this notebook provide a detailed introduction to the new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess Wikipedia data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please be aware of the following requirements about the acknowledgment, copyright and availability, cited from the [data source description page](https://github.com/facebookresearch/StarSpace/blob/master/LICENSE.md).\n",
    "\n",
    "> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading wikipedia data\n",
      "wikipedia_train250k.txt\n",
      "wikipedia_dev10k.txt\n",
      "wikipedia_dev_basedocs.txt\n",
      "wikipedia_test_basedocs.txt\n",
      "wikipedia_test10k.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "DATANAME=\"wikipedia\"\n",
    "DATADIR=\"/tmp/wiki\"\n",
    "\n",
    "mkdir -p \"${DATADIR}\"\n",
    "\n",
    "if [ ! -f \"${DATADIR}/${DATANAME}_train250k.txt\" ]\n",
    "then\n",
    "    echo \"Downloading wikipedia data\"\n",
    "    wget --quiet -c \"https://dl.fbaipublicfiles.com/starspace/wikipedia_train250k.tgz\" -O \"${DATADIR}/${DATANAME}_train.tar.gz\"\n",
    "    tar -xzvf \"${DATADIR}/${DATANAME}_train.tar.gz\" -C \"${DATADIR}\"\n",
    "    wget --quiet -c \"https://dl.fbaipublicfiles.com/starspace/wikipedia_devtst.tgz\" -O \"${DATADIR}/${DATANAME}_test.tar.gz\"\n",
    "    tar -xzvf \"${DATADIR}/${DATANAME}_test.tar.gz\" -C \"${DATADIR}\"\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/tmp/wiki'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia_dev10k.txt\t    wikipedia_test_basedocs.txt  wikipedia_train.tar.gz\n",
      "wikipedia_dev_basedocs.txt  wikipedia_test.tar.gz\n",
      "wikipedia_test10k.txt\t    wikipedia_train250k.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /tmp/wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonlines\n",
      "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jsonlines) (1.14.0)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-1.2.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: please run on python 3 kernel\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import math\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "import json, jsonlines\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from itertools import chain, islice\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "## sagemaker api\n",
    "import sagemaker, boto3\n",
    "from sagemaker.session import s3_input\n",
    "from sagemaker.predictor import json_serializer, json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocabulary and tokenize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_SYMBOL = \"<s>\"\n",
    "EOS_SYMBOL = \"</s>\"\n",
    "UNK_SYMBOL = \"<unk>\"\n",
    "PAD_SYMBOL = \"<pad>\"\n",
    "PAD_ID = 0\n",
    "TOKEN_SEPARATOR = \" \"\n",
    "VOCAB_SYMBOLS = [PAD_SYMBOL, UNK_SYMBOL, BOS_SYMBOL, EOS_SYMBOL]\n",
    "\n",
    "\n",
    "##### utility functions for preprocessing\n",
    "def get_article_iter_from_file(fname):\n",
    "    with open(fname) as f:\n",
    "        for article in f:\n",
    "            yield article\n",
    "\n",
    "def get_article_iter_from_channel(channel, datadir='/tmp/wiki'):\n",
    "    if channel == 'train':\n",
    "        fname = os.path.join(datadir, 'wikipedia_train250k.txt')\n",
    "        return get_article_iter_from_file(fname)\n",
    "    else:\n",
    "        iterlist = []\n",
    "        suffix_list = ['train250k.txt', 'test10k.txt', 'dev10k.txt', 'test_basedocs.txt']\n",
    "        for suffix in suffix_list:\n",
    "            fname = os.path.join(datadir, 'wikipedia_'+suffix)\n",
    "            iterlist.append(get_article_iter_from_file(fname))\n",
    "        return chain.from_iterable(iterlist)\n",
    "\n",
    "\n",
    "def readlines_from_article(article):\n",
    "    return article.strip().split('\\t')\n",
    "\n",
    "\n",
    "def sentence_to_integers(sentence, word_dict, trim_size=None):\n",
    "    \"\"\"\n",
    "    Converts a string of tokens to a list of integers\n",
    "    \"\"\"\n",
    "    if not trim_size:\n",
    "        return [word_dict[token] if token in word_dict else 0 for token in get_tokens_from_sentence(sentence)]\n",
    "    else:\n",
    "        integer_list = []\n",
    "        for token in get_tokens_from_sentence(sentence):\n",
    "            if len(integer_list) < trim_size:\n",
    "                if token in word_dict:\n",
    "                    integer_list.append(word_dict[token])\n",
    "                else:\n",
    "                    integer_list.append(0)\n",
    "            else:\n",
    "                break\n",
    "        return integer_list\n",
    "\n",
    "\n",
    "def get_tokens_from_sentence(sent):\n",
    "    \"\"\"\n",
    "    Yields tokens from input string.\n",
    "\n",
    "    :param line: Input string.\n",
    "    :return: Iterator over tokens.\n",
    "    \"\"\"\n",
    "    for token in sent.split():\n",
    "        if len(token) > 0:\n",
    "            yield normalize_token(token)\n",
    "\n",
    "\n",
    "def get_tokens_from_article(article):\n",
    "    iterlist = []\n",
    "    for sent in readlines_from_article(article):\n",
    "        iterlist.append(get_tokens_from_sentence(sent))\n",
    "    return chain.from_iterable(iterlist)\n",
    "\n",
    "\n",
    "def normalize_token(token):\n",
    "    token = token.lower()\n",
    "    if all(s.isdigit() or s in string.punctuation for s in token):\n",
    "        tok = list(token)\n",
    "        for i in range(len(tok)):\n",
    "            if tok[i].isdigit():\n",
    "                tok[i] = '0'\n",
    "        token = \"\".join(tok)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build vocabulary\n",
    "\n",
    "def build_vocab(channel, num_words=50000, min_count=1, use_reserved_symbols=True, sort=True):\n",
    "    \"\"\"\n",
    "    Creates a vocabulary mapping from words to ids. Increasing integer ids are assigned by word frequency,\n",
    "    using lexical sorting as a tie breaker. The only exception to this are special symbols such as the padding symbol\n",
    "    (PAD).\n",
    "\n",
    "    :param num_words: Maximum number of words in the vocabulary.\n",
    "    :param min_count: Minimum occurrences of words to be included in the vocabulary.\n",
    "    :return: word-to-id mapping.\n",
    "    \"\"\"\n",
    "    vocab_symbols_set = set(VOCAB_SYMBOLS)\n",
    "    raw_vocab = Counter()\n",
    "    for article in get_article_iter_from_channel(channel):\n",
    "        article_wise_vocab_list = list()\n",
    "        for token in get_tokens_from_article(article):\n",
    "            if token not in vocab_symbols_set:\n",
    "                article_wise_vocab_list.append(token)\n",
    "        raw_vocab.update(article_wise_vocab_list)\n",
    "\n",
    "    print(\"Initial vocabulary: {} types\".format(len(raw_vocab)))\n",
    "\n",
    "    # For words with the same count, they will be ordered reverse alphabetically.\n",
    "    # Not an issue since we only care for consistency\n",
    "    pruned_vocab = sorted(((c, w) for w, c in raw_vocab.items() if c >= min_count), reverse=True)\n",
    "    print(\"Pruned vocabulary: {} types (min frequency {})\".format(len(pruned_vocab), min_count))\n",
    "\n",
    "    # truncate the vocabulary to fit size num_words (only includes the most frequent ones)\n",
    "    vocab = islice((w for c, w in pruned_vocab), num_words)\n",
    "\n",
    "    if sort:\n",
    "        # sort the vocabulary alphabetically\n",
    "        vocab = sorted(vocab)\n",
    "    if use_reserved_symbols:\n",
    "        vocab = chain(VOCAB_SYMBOLS, vocab)\n",
    "\n",
    "    word_to_id = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "    print(\"Final vocabulary: {} types\".format(len(word_to_id)))\n",
    "\n",
    "    if use_reserved_symbols:\n",
    "        # Important: pad symbol becomes index 0\n",
    "        assert word_to_id[PAD_SYMBOL] == PAD_ID\n",
    "    \n",
    "    return word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial vocabulary: 1257162 types\n",
      "Pruned vocabulary: 267518 types (min frequency 5)\n",
      "Final vocabulary: 267522 types\n"
     ]
    }
   ],
   "source": [
    "# build vocab dictionary\n",
    "\n",
    "def build_vocabulary_file(vocab_fname, channel, num_words=50000, min_count=1, \n",
    "                          use_reserved_symbols=True, sort=True, force=False):\n",
    "    if not os.path.exists(vocab_fname) or force:\n",
    "        w_dict = build_vocab(channel, num_words=num_words, min_count=min_count, \n",
    "                             use_reserved_symbols=True, sort=True)\n",
    "        with open(vocab_fname, \"w\") as write_file:\n",
    "            json.dump(w_dict, write_file)\n",
    "\n",
    "channel = 'train'\n",
    "min_count = 5\n",
    "vocab_fname = os.path.join(datadir, 'wiki-vocab-{}250k-mincount-{}.json'.format(channel, min_count))\n",
    "\n",
    "build_vocabulary_file(vocab_fname, channel, num_words=500000, min_count=min_count, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocab file /tmp/wiki/wiki-vocab-train250k-mincount-5.json ...\n",
      "The vocabulary size is 267522\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading vocab file {} ...\".format(vocab_fname))\n",
    "\n",
    "with open(vocab_fname) as f:\n",
    "    w_dict = json.load(f)\n",
    "    print(\"The vocabulary size is {}\".format(len(w_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to build training data \n",
    "# Tokenize wiki articles to (sentence, document) pairs\n",
    "def generate_sent_article_pairs_from_single_article(article, word_dict):\n",
    "    sent_list = readlines_from_article(article)\n",
    "    art_len = len(sent_list)\n",
    "    idx = random.randint(0, art_len-1)\n",
    "    wrapper_text_idx = list(range(idx)) + list(range((idx+1) % art_len, art_len))\n",
    "    wrapper_text_list = sent_list[:idx] + sent_list[(idx+1) % art_len : art_len]\n",
    "    wrapper_tokens = []\n",
    "    for sent1 in wrapper_text_list:\n",
    "        wrapper_tokens += sentence_to_integers(sent1, word_dict)\n",
    "    sent_tokens = sentence_to_integers(sent_list[idx], word_dict)\n",
    "    yield {'in0':sent_tokens, 'in1':wrapper_tokens, 'label':1}\n",
    "\n",
    "\n",
    "def generate_sent_article_pairs_from_single_file(fname, word_dict):\n",
    "    with open(fname) as reader:\n",
    "        iter_list = []\n",
    "        for article in reader:\n",
    "            iter_list.append(generate_sent_article_pairs_from_single_article(article, word_dict))\n",
    "    return chain.from_iterable(iter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating train250k data of size 250000\n"
     ]
    }
   ],
   "source": [
    "# Build training data\n",
    "\n",
    "# Generate integer positive labeled data\n",
    "train_prefix = 'train250k'\n",
    "fname = \"wikipedia_{}.txt\".format(train_prefix)\n",
    "outfname = os.path.join(datadir, '{}_tokenized.jsonl'.format(train_prefix))\n",
    "counter = 0\n",
    "\n",
    "with jsonlines.open(outfname, 'w') as writer:\n",
    "    for sample in generate_sent_article_pairs_from_single_file(os.path.join(datadir, fname), w_dict):\n",
    "        writer.write(sample)\n",
    "        counter += 1\n",
    "        \n",
    "print(\"Finished generating {} data of size {}\".format(train_prefix, counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle training data\n",
    "!shuf {outfname} > {train_prefix}_tokenized_shuf.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to generate dev/test data (with both positive and negative labels)\n",
    "\n",
    "def generate_pos_neg_samples_from_single_article(word_dict, article_idx, article_buffer, negative_sampling_rate=1):\n",
    "    sample_list = []\n",
    "    # generate positive samples\n",
    "    sent_list = readlines_from_article(article_buffer[article_idx])\n",
    "    art_len = len(sent_list)\n",
    "    idx = random.randint(0, art_len-1)\n",
    "    wrapper_text_idx = list(range(idx)) + list(range((idx+1) % art_len, art_len))\n",
    "    wrapper_text_list = sent_list[:idx] + sent_list[(idx+1) % art_len : art_len]\n",
    "    wrapper_tokens = []\n",
    "    for sent1 in wrapper_text_list:\n",
    "        wrapper_tokens += sentence_to_integers(sent1, word_dict)\n",
    "    sent_tokens = sentence_to_integers(sent_list[idx], word_dict)\n",
    "    sample_list.append({'in0':sent_tokens, 'in1':wrapper_tokens, 'label':1})\n",
    "    # generate negative sample\n",
    "    buff_len = len(article_buffer)\n",
    "    sampled_inds = np.random.choice(list(range(article_idx)) + list(range((article_idx+1) % buff_len, buff_len)), \n",
    "                                    size=negative_sampling_rate)\n",
    "    for n_idx in sampled_inds:\n",
    "        other_article = article_buffer[n_idx]\n",
    "        context_list = readlines_from_article(other_article)\n",
    "        context_tokens = []\n",
    "        for sent2 in context_list:\n",
    "            context_tokens += sentence_to_integers(sent2, word_dict)\n",
    "        sample_list.append({'in0': sent_tokens, 'in1':context_tokens, 'label':0})\n",
    "    return sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dev and test data\n",
    "for data in ['dev10k', 'test10k']:\n",
    "    fname = os.path.join(datadir,'wikipedia_{}.txt'.format(data))\n",
    "    test_nsr = 5\n",
    "    outfname = '{}_tokenized-nsr{}.jsonl'.format(data, test_nsr)\n",
    "    article_buffer = list(get_article_iter_from_file(fname))\n",
    "    sample_buffer = []\n",
    "    for article_idx in range(len(article_buffer)):\n",
    "        sample_buffer += generate_pos_neg_samples_from_single_article(w_dict, article_idx, \n",
    "                                                                      article_buffer, \n",
    "                                                                      negative_sampling_rate=test_nsr)\n",
    "    with jsonlines.open(outfname, 'w') as writer:\n",
    "        writer.write_all(sample_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload preprocessed data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA=\"train250k_tokenized_shuf.jsonl\"\n",
    "DEV_DATA=\"dev10k_tokenized-nsr{}.jsonl\".format(test_nsr)\n",
    "TEST_DATA=\"test10k_tokenized-nsr{}.jsonl\".format(test_nsr)\n",
    "\n",
    "bucket = 'fab-sagemaker'\n",
    "S3_KEY = 'object2vec-doc2vec'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./train250k_tokenized_shuf.jsonl to s3://fab-sagemaker/object2vec-doc2vec/input/train/train250k_tokenized_shuf.jsonl\n",
      "upload: ./dev10k_tokenized-nsr5.jsonl to s3://fab-sagemaker/object2vec-doc2vec/input/validation/dev10k_tokenized-nsr5.jsonl\n",
      "upload: ./test10k_tokenized-nsr5.jsonl to s3://fab-sagemaker/object2vec-doc2vec/input/test/test10k_tokenized-nsr5.jsonl\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$TRAIN_DATA\" \"$DEV_DATA\" \"$TEST_DATA\" \"$bucket\" \"$S3_KEY\"\n",
    "\n",
    "aws s3 cp \"$1\" s3://$4/$5/input/train/\n",
    "aws s3 cp \"$2\" s3://$4/$5/input/validation/\n",
    "aws s3 cp \"$3\" s3://$4/$5/input/test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Sagemaker session, Object2Vec image, S3 input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your notebook is running on region 'us-east-1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your IAM role: 'arn:aws:iam::640463227255:role/service-role/AmazonSageMaker-ExecutionRole-20200822T102773'\n",
      "The image uri used is '382416733822.dkr.ecr.us-east-1.amazonaws.com/object2vec:1'\n",
      "Using s3 buceket: fab-sagemaker and key prefix: object2vec-doc2vec\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "print(\"Your notebook is running on region '{}'\".format(region))\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    " \n",
    "role = get_execution_role()\n",
    "print(\"Your IAM role: '{}'\".format(role))\n",
    "\n",
    "container = get_image_uri(region, 'object2vec')\n",
    "print(\"The image uri used is '{}'\".format(container))\n",
    "\n",
    "print(\"Using s3 buceket: {} and key prefix: {}\".format(bucket, S3_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "## define input channels\n",
    "\n",
    "s3_input_path = os.path.join('s3://', bucket, S3_KEY, 'input')\n",
    "\n",
    "s3_train = s3_input(os.path.join(s3_input_path, 'train', TRAIN_DATA), \n",
    "                    distribution='ShardedByS3Key', content_type='application/jsonlines')\n",
    "\n",
    "s3_valid = s3_input(os.path.join(s3_input_path, 'validation', DEV_DATA), \n",
    "                    distribution='ShardedByS3Key', content_type='application/jsonlines')\n",
    "\n",
    "s3_test = s3_input(os.path.join(s3_input_path, 'test', TEST_DATA), \n",
    "                   distribution='ShardedByS3Key', content_type='application/jsonlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define output path\n",
    "output_path = os.path.join('s3://', bucket, S3_KEY, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and deploy doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine four new features into our training of Object2Vec:\n",
    "\n",
    "- Negative sampling: With the new `negative_sampling_rate` hyperparameter, users of Object2Vec only need to provide positively labeled data pairs, and the algorithm automatically samples for negative data internally during training.\n",
    "\n",
    "- Weight-sharing of embedding layer: The new `tied_token_embedding_weight` hyperparameter gives user the flexibility to share the embedding weights for both encoders, and it improves the performance of the algorithm in this use-case\n",
    "\n",
    "- The new `comparator_list` hyperparameter gives users the flexibility to mix-and-match different operators so that they can tune the algorithm towards optimal performance for their applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning performance boost with new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Table 1_ below shows the effect of these features on these two metrics evaluated on a test set obtained from the same data creation process. \n",
    "\n",
    "We see that when negative sampling and weight-sharing of embedding layer is on, and when we use a customized comparator operator (Hadamard product), the model has improved test performance. When all these features are combined together (last row of Table 1), the algorithm has the best performance as measured by accuracy and cross-entropy.\n",
    "\n",
    "\n",
    "### Table 1\n",
    "\n",
    "|negative_sampling_rate|weight-sharing|comparator operator| Test accuracy | Test cross-entropy|\n",
    "| :-------------       | :----------: | :-----------:     | :----------:  | ----------:       |\n",
    "|  off                 | off          | default           | 0.167         |  23               |\n",
    "|  3                 | off          | default             | 0.92          |  0.21             |\n",
    "|  5                 | off          | default             | 0.92          |   0.19            |\n",
    "|  off               | on           | default           | 0.167         |  23               |\n",
    "|  3                 | on           | default           | 0.93         |  0.18               |\n",
    "|  5                 | on           | default           | 0.936         |  0.17               |\n",
    "|  off               | on           | customized        | 0.17         |  23               |\n",
    "|  3                 | on           | customized        | 0.93         |  0.18               |\n",
    "|  5                 | on           | customized        | 0.94         |  0.17               |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- The new `token_embedding_storage_type` hyperparameter flags the use of sparse gradient update, which takes advantage of the sparse input format of Object2Vec. We tested and summarized the training speedup with different GPU and `max_seq_len` configurations in the table below. In a word, we see 2-20 times speed up on different machine and algorithm configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training speedup with sparse gradient update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Table 2_ below shows the training speeds up with sparse gradient update feature turned on, as a function of number of GPUs used for training.\n",
    "\n",
    "### Table 2\n",
    "\n",
    "|num_gpus|Throughput (samples/sec) with dense storage|Throughput with sparse storage|max_seq_len (in0/in1)|Speedup X-times  |\n",
    "| :------------- | :----------: | :-----------:| :----------: | ----------: |\n",
    "|  1             | 5k           | 14k          | 50           |  2.8        |\n",
    "|  2             | 2.7k         | 23k          | 50           |  8.5        |\n",
    "|  3             | 2k           | 23~26k       | 50           |  10         |\n",
    "|  4             | 2k           | 23k          | 50           |  10         |\n",
    "|  8             | 1.1k         | 19k~20k      | 50           |  20         |\n",
    "|  1             | 1.1k         | 2k           | 500          |  2          |\n",
    "|  2             | 1.5k         | 3.6k         | 500          |  2.4        |\n",
    "|  4             | 1.6k         | 6k           | 500          |  3.75       |\n",
    "|  6             | 1.3k         | 6.7k         | 500          |  5.15       |\n",
    "|  8             | 1.1k        | 5.6k         | 500          |  5          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# Define training hyperparameters\n",
    "\n",
    "hyperparameters = {\n",
    "      \"_kvstore\": \"device\",\n",
    "      \"_num_gpus\": 'auto',\n",
    "      \"_num_kv_servers\": \"auto\",\n",
    "      \"bucket_width\": 0,\n",
    "      \"dropout\": 0.4,\n",
    "      \"early_stopping_patience\": 2,\n",
    "      \"early_stopping_tolerance\": 0.01,\n",
    "      \"enc0_layers\": \"auto\",\n",
    "      \"enc0_max_seq_len\": 50,\n",
    "      \"enc0_network\": \"pooled_embedding\",\n",
    "      \"enc0_pretrained_embedding_file\": \"\",\n",
    "      \"enc0_token_embedding_dim\": 300,\n",
    "      \"enc0_vocab_size\": 267522,\n",
    "      \"enc1_network\": \"enc0\",\n",
    "      \"enc_dim\": 300,\n",
    "      \"epochs\": 20,\n",
    "      \"learning_rate\": 0.01,\n",
    "      \"mini_batch_size\": 512,\n",
    "      \"mlp_activation\": \"relu\",\n",
    "      \"mlp_dim\": 512,\n",
    "      \"mlp_layers\": 2,\n",
    "      \"num_classes\": 2,\n",
    "      \"optimizer\": \"adam\",\n",
    "      \"output_layer\": \"softmax\",\n",
    "      \"weight_decay\": 0\n",
    "}\n",
    "\n",
    "\n",
    "hyperparameters['negative_sampling_rate'] = 3\n",
    "hyperparameters['tied_token_embedding_weight'] = \"true\"\n",
    "hyperparameters['comparator_list'] = \"hadamard\"\n",
    "hyperparameters['token_embedding_storage_type'] = 'row_sparse'\n",
    "\n",
    "    \n",
    "# get estimator\n",
    "doc2vec = sagemaker.estimator.Estimator(container,\n",
    "                                          role, \n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.p2.xlarge',\n",
    "                                          output_path=output_path,\n",
    "                                          sagemaker_session=sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 12:57:24 Starting - Starting the training job...\n",
      "2020-10-16 12:57:27 Starting - Launching requested ML instances......\n",
      "2020-10-16 12:58:56 Starting - Preparing the instances for training.........\n",
      "2020-10-16 13:00:09 Downloading - Downloading input data......\n",
      "2020-10-16 13:01:05 Training - Downloading the training image...\n",
      "2020-10-16 13:01:45 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:01:49 INFO 139950662330176] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': 3, u'epochs': 30, u'mlp_dim': 512, u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': 2, u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': 300, u'tied_token_embedding_weight': u'false', u'learning_rate': 0.0004, u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': 0, u'enc0_network': u'hcnn', u'enc1_layers': u'auto', u'early_stopping_patience': 3, u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': 0.01, u'dropout': 0, u'bucket_width': 0, u'enc_dim': 4096, u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': 32, u'enc1_pretrained_embedding_file': u'', u'num_classes': 2, u'_num_gpus': u'auto', u'enc1_token_embedding_dim': 300, u'mlp_activation': u'linear', u'enc1_network': u'enc0', u'_kvstore': u'auto_gpu'}\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:01:49 INFO 139950662330176] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'comparator_list': u'hadamard', u'output_layer': u'softmax', u'epochs': u'20', u'mlp_dim': u'512', u'mlp_layers': u'2', u'_num_kv_servers': u'auto', u'weight_decay': u'0', u'mini_batch_size': u'512', u'token_embedding_storage_type': u'row_sparse', u'enc0_token_embedding_dim': u'300', u'enc1_network': u'enc0', u'learning_rate': u'0.01', u'negative_sampling_rate': u'3', u'enc0_network': u'pooled_embedding', u'early_stopping_patience': u'2', u'optimizer': u'adam', u'early_stopping_tolerance': u'0.01', u'dropout': u'0.4', u'bucket_width': u'0', u'enc_dim': u'300', u'enc0_layers': u'auto', u'enc0_max_seq_len': u'50', u'num_classes': u'2', u'_num_gpus': u'auto', u'mlp_activation': u'relu', u'tied_token_embedding_weight': u'true', u'_kvstore': u'device', u'enc0_vocab_size': u'267522'}\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:01:49 INFO 139950662330176] Final configuration: {u'comparator_list': u'hadamard', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': 3, u'epochs': u'20', u'mlp_dim': u'512', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'2', u'_num_kv_servers': u'auto', u'weight_decay': u'0', u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'50', u'token_embedding_storage_type': u'row_sparse', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'true', u'learning_rate': u'0.01', u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': u'3', u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'2', u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': u'0.4', u'bucket_width': u'0', u'enc_dim': u'300', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'512', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': 300, u'mlp_activation': u'relu', u'enc1_network': u'enc0', u'_kvstore': u'device', u'enc0_vocab_size': u'267522'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:01:49 INFO 139950662330176] Using default worker.\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:01:49 INFO 139950662330176] Loaded iterator creator application/jsonlines for content type ('application/jsonlines', '1.0')\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:01:49 INFO 139950662330176] create_iter params {u'comparator_list': u'hadamard', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': 3, u'epochs': u'20', u'mlp_dim': u'512', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'2', u'_num_kv_servers': u'auto', u'weight_decay': u'0', u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'50', u'token_embedding_storage_type': u'row_sparse', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'true', u'learning_rate': u'0.01', u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': u'3', u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'2', u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': u'0.4', u'bucket_width': u'0', u'enc_dim': u'300', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'512', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': 300, u'mlp_activation': u'relu', u'enc1_network': u'enc0', u'_kvstore': u'device', u'enc0_vocab_size': u'267522'}\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:01:49 INFO 139950662330176] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:01:49 INFO 139950662330176] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'267522', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': u'300', u'max_seq_len': u'50', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'network': u'enc0', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': 300, u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:01:49 INFO 139950662330176] Encoder configs: [{'vocab_size': 267522, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}, {'vocab_size': 267522, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:01:49 INFO 139950662330176] Config: {'comparator_list': ['hadamard'], 'epochs': 20, 'mini_batch_size': 512, 'optimizer': 'adam', 'output_layer': 'softmax', 'token_embedding_storage_type': 'row_sparse', 'mlp_dim': 512, 'early_stopping_tolerance': 0.01, 'dropout': 0.4, 'bucket_width': 0, 'enc_dim': 300, 'negative_sampling_rate': 3, 'early_stopping_patience': 2, 'learning_rate': 0.01, 'max_seq_lens': [50, 50], 'tied_token_embedding_weight': True, 'enc_configs': [{'vocab_size': 267522, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}, {'vocab_size': 267522, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}], 'mlp_layers': 2, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'num_classes': 2}\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:01:49 INFO 139950662330176] use bucketing: False\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:01:49 INFO 139950662330176] Creating data iterator for /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:01:49 INFO 139950662330176] One or more sequences have been truncated because they exceeded max_seq_len\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:10 INFO 139950662330176] Source words: 4389071\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:10 INFO 139950662330176] Target words: 10930565\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:10 INFO 139950662330176] Total: 250000 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:10 INFO 139950662330176] Bucket of (50, 50) : 250000 samples in 488 batches of 512, approx 22016.0 words/batch\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:10 INFO 139950662330176] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:10 INFO 139950662330176] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:10 INFO 139950662330176] \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:10 INFO 139950662330176] Negative sampling enabled with sampling rate 3\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:11 INFO 139950662330176] Replicating 368 random sentences from bucket (50, 50) to size it to multiple of 512\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:11 INFO 139950662330176] Bucket batch sizes: [BucketBatchSize(batch_size=512, average_words_per_batch=22016)]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:11 INFO 139950662330176] create_iter params {u'comparator_list': u'hadamard', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': 3, u'epochs': u'20', u'mlp_dim': u'512', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'2', u'_num_kv_servers': u'auto', u'weight_decay': u'0', u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'50', u'token_embedding_storage_type': u'row_sparse', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'true', u'learning_rate': u'0.01', u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': u'3', u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'2', u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': u'0.4', u'bucket_width': u'0', u'enc_dim': u'300', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'512', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': 300, u'mlp_activation': u'relu', u'enc1_network': u'enc0', u'_kvstore': u'device', u'enc0_vocab_size': u'267522'}\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:11 INFO 139950662330176] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:11 INFO 139950662330176] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'267522', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': u'300', u'max_seq_len': u'50', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'network': u'enc0', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': 300, u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:11 INFO 139950662330176] Encoder configs: [{'vocab_size': 267522, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}, {'vocab_size': 267522, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:11 INFO 139950662330176] Config: {'comparator_list': ['hadamard'], 'epochs': 20, 'mini_batch_size': 512, 'optimizer': 'adam', 'output_layer': 'softmax', 'token_embedding_storage_type': 'row_sparse', 'mlp_dim': 512, 'early_stopping_tolerance': 0.01, 'dropout': 0.4, 'bucket_width': 0, 'enc_dim': 300, 'negative_sampling_rate': 3, 'early_stopping_patience': 2, 'learning_rate': 0.01, 'max_seq_lens': [50, 50], 'tied_token_embedding_weight': True, 'enc_configs': [{'vocab_size': 267522, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}, {'vocab_size': 267522, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}], 'mlp_layers': 2, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'num_classes': 2}\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:11 INFO 139950662330176] use bucketing: False\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:11 INFO 139950662330176] Creating data iterator for /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:11 INFO 139950662330176] One or more sequences have been truncated because they exceeded max_seq_len\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] Source words: 1033014\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] Target words: 2662845\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] Total: 60000 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] Bucket of (50, 50) : 60000 samples in 117 batches of 512, approx 22528.0 words/batch\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] Replicating 416 random sentences from bucket (50, 50) to size it to multiple of 512\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] create_iter params {u'comparator_list': u'hadamard', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': 3, u'epochs': u'20', u'mlp_dim': u'512', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'2', u'_num_kv_servers': u'auto', u'weight_decay': u'0', u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'50', u'token_embedding_storage_type': u'row_sparse', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'true', u'learning_rate': u'0.01', u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': u'3', u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'2', u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': u'0.4', u'bucket_width': u'0', u'enc_dim': u'300', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'512', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': 300, u'mlp_activation': u'relu', u'enc1_network': u'enc0', u'_kvstore': u'device', u'enc0_vocab_size': u'267522'}\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'267522', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': u'300', u'max_seq_len': u'50', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'network': u'enc0', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': 300, u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] Encoder configs: [{'vocab_size': 267522, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}, {'vocab_size': 267522, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] Config: {'comparator_list': ['hadamard'], 'epochs': 20, 'mini_batch_size': 512, 'optimizer': 'adam', 'output_layer': 'softmax', 'token_embedding_storage_type': 'row_sparse', 'mlp_dim': 512, 'early_stopping_tolerance': 0.01, 'dropout': 0.4, 'bucket_width': 0, 'enc_dim': 300, 'negative_sampling_rate': 3, 'early_stopping_patience': 2, 'learning_rate': 0.01, 'max_seq_lens': [50, 50], 'tied_token_embedding_weight': True, 'enc_configs': [{'vocab_size': 267522, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}, {'vocab_size': 267522, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}], 'mlp_layers': 2, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'num_classes': 2}\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] use bucketing: False\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] Creating data iterator for /opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:30 INFO 139950662330176] One or more sequences have been truncated because they exceeded max_seq_len\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] Source words: 1057896\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] Target words: 2678455\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] Total: 60000 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] Bucket of (50, 50) : 60000 samples in 117 batches of 512, approx 22528.0 words/batch\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] Replicating 416 random sentences from bucket (50, 50) to size it to multiple of 512\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'267522', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': u'300', u'max_seq_len': u'50', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'network': u'enc0', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': 300, u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] Encoder configs: [{'vocab_size': 267522, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}, {'vocab_size': 267522, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] Config: {'comparator_list': ['hadamard'], 'epochs': 20, 'mini_batch_size': 512, 'optimizer': 'adam', 'output_layer': 'softmax', 'token_embedding_storage_type': 'row_sparse', 'mlp_dim': 512, 'early_stopping_tolerance': 0.01, 'dropout': 0.4, 'bucket_width': 0, 'enc_dim': 300, 'negative_sampling_rate': 3, 'early_stopping_patience': 2, 'learning_rate': 0.01, 'max_seq_lens': [50, 50], 'tied_token_embedding_weight': True, 'enc_configs': [{'vocab_size': 267522, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}, {'vocab_size': 267522, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.4, 'pretrained_embedding_file': ''}], 'mlp_layers': 2, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'num_classes': 2}\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] Creating new state\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] params {u'comparator_list': u'hadamard', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': 3, u'epochs': u'20', u'mlp_dim': u'512', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'2', u'_num_kv_servers': u'auto', u'weight_decay': u'0', u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'50', u'token_embedding_storage_type': u'row_sparse', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'true', u'learning_rate': u'0.01', u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': u'3', u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'2', u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': u'0.4', u'bucket_width': u'0', u'enc_dim': u'300', 'default_bucket_key': (50, 50), u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'512', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': 300, u'mlp_activation': u'relu', u'enc1_network': u'enc0', u'_kvstore': u'device', u'enc0_vocab_size': u'267522'}\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] default_bucket_key (50, 50)\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] nvidia-smi took: 0.0251951217651 secs to identify 1 gpus\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] context [gpu(0)]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] Create Store: device\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] data_names: ['source', 'target']\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] label_names: ['out_layer_label']\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                                        Output Shape            Param #     Previous Layer                  \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34msource(null)                                        50                      0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_shared(_contrib_SparseEmbedding)              50x300                  0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar0(_not_equal_scalar)               50                      0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape0(Reshape)                                   50x1                    0           _not_equal_scalar0              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul0(broadcast_mul)                       50x300                  0           embed_shared                    \n",
      "                                                                                        reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum0(sum)                                           300                     0           broadcast_mul0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum1(sum)                                           1                       0           reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like0(zeros_like)                             1                       0           sum1                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal0(_equal)                                     1                       0           sum1                            \n",
      "                                                                                        zeros_like0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus0(elemwise_add)                                1                       0           sum1                            \n",
      "                                                                                        _equal0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div0(broadcast_div)                       300                     0           sum0                            \n",
      "                                                                                        _plus0                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout0(Dropout)                                   300                     0           broadcast_div0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_shared(_contrib_SparseEmbedding)              50x300                  0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar1(_not_equal_scalar)               50                      0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape1(Reshape)                                   50x1                    0           _not_equal_scalar1              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul1(broadcast_mul)                       50x300                  0           embed_shared                    \n",
      "                                                                                        reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum2(sum)                                           300                     0           broadcast_mul1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum3(sum)                                           1                       0           reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like1(zeros_like)                             1                       0           sum3                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal1(_equal)                                     1                       0           sum3                            \n",
      "                                                                                        zeros_like1                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus1(elemwise_add)                                1                       0           sum3                            \n",
      "                                                                                        _equal1                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div1(broadcast_div)                       300                     0           sum2                            \n",
      "                                                                                        _plus1                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout1(Dropout)                                   300                     0           broadcast_div1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_mul0(elemwise_mul)                                 300                     0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcat0(Concat)                                     300                     0           _mul0                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmlp_fc0(FullyConnected)                             512                     154112      concat0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation0(Activation)                             512                     0           mlp_fc0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout2(Dropout)                                   512                     0           activation0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmlp_fc1(FullyConnected)                             512                     262656      dropout2                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation1(Activation)                             512                     0           mlp_fc1                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout3(Dropout)                                   512                     0           activation1                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34moutput_layer(FullyConnected)                        2                       1026        dropout3                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mout_layer(SoftmaxOutput)                            2                       0           output_layer                    \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 417794\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] data_shapes [DataDesc[source,(512, 50),<type 'numpy.float32'>,NTC], DataDesc[target,(512, 50),<type 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] label_shapes [DataDesc[out_layer_label,(512,),<type 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] fixed_param_names: []\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:50 INFO 139950662330176] Initialized BucketingPlus Module\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:56 INFO 139950662330176] arg_params keys for module initialization: []\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:03:56 INFO 139950662330176] all params:['output_layer_weight', 'embed_shared_weight', 'mlp_fc0_weight', 'mlp_fc0_bias', 'mlp_fc1_weight', 'output_layer_bias', 'mlp_fc1_bias']\u001b[0m\n",
      "\u001b[34m[13:03:56] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_10.1.x.1334.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 6284.719944000244, \"sum\": 6284.719944000244, \"min\": 6284.719944000244}}, \"EndTime\": 1602853436.572123, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1602853309.875396}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1602853436.572367, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1602853436.572305}\n",
      "\u001b[0m\n",
      "\u001b[34m[13:03:57] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_10.1.x.1334.0/AL2012/generic-flavor/src/src/operator/././../common/utils.h:450: Optimizer with lazy_update = True detected. Be aware that lazy update with row_sparse gradient is different from standard update, and may lead to different empirical results. See https://mxnet.incubator.apache.org/api/python/optimization/optimization.html for more details.\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:01 INFO 139950662330176] Epoch: 0, batches: 100, num_examples: 51200, 14340.7 samples/sec, epoch time so far: 0:00:03.570270\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:01 INFO 139950662330176] #011Training metrics: perplexity: 1.627 cross_entropy: 0.487 accuracy: 0.770 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:04 INFO 139950662330176] Epoch: 0, batches: 200, num_examples: 102400, 14574.6 samples/sec, epoch time so far: 0:00:07.025931\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:04 INFO 139950662330176] #011Training metrics: perplexity: 1.548 cross_entropy: 0.437 accuracy: 0.797 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:08 INFO 139950662330176] Epoch: 0, batches: 300, num_examples: 153600, 14646.5 samples/sec, epoch time so far: 0:00:10.487172\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:08 INFO 139950662330176] #011Training metrics: perplexity: 1.502 cross_entropy: 0.407 accuracy: 0.814 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:11 INFO 139950662330176] Epoch: 0, batches: 400, num_examples: 204800, 14686.2 samples/sec, epoch time so far: 0:00:13.945068\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:11 INFO 139950662330176] #011Training metrics: perplexity: 1.474 cross_entropy: 0.388 accuracy: 0.825 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:15 INFO 139950662330176] Epoch: 0, batches: 500, num_examples: 256000, 14707.7 samples/sec, epoch time so far: 0:00:17.405829\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:15 INFO 139950662330176] #011Training metrics: perplexity: 1.452 cross_entropy: 0.373 accuracy: 0.834 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:18 INFO 139950662330176] Epoch: 0, batches: 600, num_examples: 307200, 14732.4 samples/sec, epoch time so far: 0:00:20.851971\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:18 INFO 139950662330176] #011Training metrics: perplexity: 1.435 cross_entropy: 0.361 accuracy: 0.841 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:22 INFO 139950662330176] Epoch: 0, batches: 700, num_examples: 358400, 14747.5 samples/sec, epoch time so far: 0:00:24.302371\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:22 INFO 139950662330176] #011Training metrics: perplexity: 1.422 cross_entropy: 0.352 accuracy: 0.846 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:25 INFO 139950662330176] Epoch: 0, batches: 800, num_examples: 409600, 14751.8 samples/sec, epoch time so far: 0:00:27.766056\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:25 INFO 139950662330176] #011Training metrics: perplexity: 1.411 cross_entropy: 0.344 accuracy: 0.850 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:28 INFO 139950662330176] Epoch: 0, batches: 900, num_examples: 460800, 14764.0 samples/sec, epoch time so far: 0:00:31.211038\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:28 INFO 139950662330176] #011Training metrics: perplexity: 1.402 cross_entropy: 0.338 accuracy: 0.854 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:32 INFO 139950662330176] Epoch: 0, batches: 1000, num_examples: 512000, 14775.8 samples/sec, epoch time so far: 0:00:34.651229\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:32 INFO 139950662330176] #011Training metrics: perplexity: 1.394 cross_entropy: 0.332 accuracy: 0.857 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:35 INFO 139950662330176] Epoch: 0, batches: 1100, num_examples: 563200, 14776.4 samples/sec, epoch time so far: 0:00:38.114708\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:35 INFO 139950662330176] #011Training metrics: perplexity: 1.387 cross_entropy: 0.327 accuracy: 0.860 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:39 INFO 139950662330176] Epoch: 0, batches: 1200, num_examples: 614400, 14773.6 samples/sec, epoch time so far: 0:00:41.587580\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:39 INFO 139950662330176] #011Training metrics: perplexity: 1.380 cross_entropy: 0.322 accuracy: 0.862 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:42 INFO 139950662330176] Epoch: 0, batches: 1300, num_examples: 665600, 14771.6 samples/sec, epoch time so far: 0:00:45.059358\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:42 INFO 139950662330176] #011Training metrics: perplexity: 1.375 cross_entropy: 0.319 accuracy: 0.865 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:46 INFO 139950662330176] Epoch: 0, batches: 1400, num_examples: 716800, 14770.6 samples/sec, epoch time so far: 0:00:48.528841\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:46 INFO 139950662330176] #011Training metrics: perplexity: 1.370 cross_entropy: 0.315 accuracy: 0.867 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:49 INFO 139950662330176] Epoch: 0, batches: 1500, num_examples: 768000, 14776.4 samples/sec, epoch time so far: 0:00:51.974886\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:49 INFO 139950662330176] #011Training metrics: perplexity: 1.366 cross_entropy: 0.312 accuracy: 0.869 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:53 INFO 139950662330176] Epoch: 0, batches: 1600, num_examples: 819200, 14779.8 samples/sec, epoch time so far: 0:00:55.426865\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:53 INFO 139950662330176] #011Training metrics: perplexity: 1.361 cross_entropy: 0.309 accuracy: 0.870 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:56 INFO 139950662330176] Epoch: 0, batches: 1700, num_examples: 870400, 14787.1 samples/sec, epoch time so far: 0:00:58.862276\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:04:56 INFO 139950662330176] #011Training metrics: perplexity: 1.358 cross_entropy: 0.306 accuracy: 0.872 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:00 INFO 139950662330176] Epoch: 0, batches: 1800, num_examples: 921600, 14789.2 samples/sec, epoch time so far: 0:01:02.315807\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:00 INFO 139950662330176] #011Training metrics: perplexity: 1.354 cross_entropy: 0.303 accuracy: 0.873 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:03 INFO 139950662330176] Epoch: 0, batches: 1900, num_examples: 972800, 14782.8 samples/sec, epoch time so far: 0:01:05.806145\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:03 INFO 139950662330176] #011Training metrics: perplexity: 1.351 cross_entropy: 0.301 accuracy: 0.874 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:05 INFO 139950662330176] **************\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:05 INFO 139950662330176] Completed Epoch: 0, time taken: 0:01:07.633009\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:05 INFO 139950662330176] Epoch 0 Training metrics:   perplexity: 1.350 cross_entropy: 0.300 accuracy: 0.875 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:05 INFO 139950662330176] #quality_metric: host=algo-1, epoch=0, train cross_entropy <loss>=0.299794203972\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:05 INFO 139950662330176] #quality_metric: host=algo-1, epoch=0, train accuracy <score>=0.874950996864\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:08 INFO 139950662330176] Epoch 0 Validation metrics: perplexity: 1.248 cross_entropy: 0.221 accuracy: 0.918 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:08 INFO 139950662330176] #quality_metric: host=algo-1, epoch=0, validation cross_entropy <loss>=0.221478772365\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:08 INFO 139950662330176] #quality_metric: host=algo-1, epoch=0, validation accuracy <score>=0.917852886653\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:08 INFO 139950662330176] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}, \"early_stop.time\": {\"count\": 1, \"max\": 0.5970001220703125, \"sum\": 0.5970001220703125, \"min\": 0.5970001220703125}, \"update.time\": {\"count\": 1, \"max\": 70656.24690055847, \"sum\": 70656.24690055847, \"min\": 70656.24690055847}}, \"EndTime\": 1602853508.359384, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1602853436.572248}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:08 INFO 139950662330176] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1953, \"sum\": 1953.0, \"min\": 1953}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1953, \"sum\": 1953.0, \"min\": 1953}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 999936, \"sum\": 999936.0, \"min\": 999936}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1953, \"sum\": 1953.0, \"min\": 1953}, \"Total Records Seen\": {\"count\": 1, \"max\": 999936, \"sum\": 999936.0, \"min\": 999936}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 999936, \"sum\": 999936.0, \"min\": 999936}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1602853508.359994, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 0}, \"StartTime\": 1602853437.703108}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:08 INFO 139950662330176] #throughput_metric: host=algo-1, train throughput=14151.9497773 records/second\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:12 INFO 139950662330176] Epoch: 1, batches: 100, num_examples: 51200, 14637.1 samples/sec, epoch time so far: 0:00:03.497971\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:12 INFO 139950662330176] #011Training metrics: perplexity: 1.216 cross_entropy: 0.195 accuracy: 0.923 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:16 INFO 139950662330176] Epoch: 1, batches: 200, num_examples: 102400, 14738.5 samples/sec, epoch time so far: 0:00:06.947807\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:16 INFO 139950662330176] #011Training metrics: perplexity: 1.212 cross_entropy: 0.192 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:19 INFO 139950662330176] Epoch: 1, batches: 300, num_examples: 153600, 14786.9 samples/sec, epoch time so far: 0:00:10.387564\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:19 INFO 139950662330176] #011Training metrics: perplexity: 1.210 cross_entropy: 0.191 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:22 INFO 139950662330176] Epoch: 1, batches: 400, num_examples: 204800, 14820.3 samples/sec, epoch time so far: 0:00:13.818897\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:22 INFO 139950662330176] #011Training metrics: perplexity: 1.211 cross_entropy: 0.192 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:26 INFO 139950662330176] Epoch: 1, batches: 500, num_examples: 256000, 14823.0 samples/sec, epoch time so far: 0:00:17.270456\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:26 INFO 139950662330176] #011Training metrics: perplexity: 1.211 cross_entropy: 0.192 accuracy: 0.925 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:29 INFO 139950662330176] Epoch: 1, batches: 600, num_examples: 307200, 14831.3 samples/sec, epoch time so far: 0:00:20.713013\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:29 INFO 139950662330176] #011Training metrics: perplexity: 1.212 cross_entropy: 0.192 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:33 INFO 139950662330176] Epoch: 1, batches: 700, num_examples: 358400, 14829.7 samples/sec, epoch time so far: 0:00:24.167708\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:33 INFO 139950662330176] #011Training metrics: perplexity: 1.212 cross_entropy: 0.193 accuracy: 0.925 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:36 INFO 139950662330176] Epoch: 1, batches: 800, num_examples: 409600, 14834.8 samples/sec, epoch time so far: 0:00:27.610842\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:36 INFO 139950662330176] #011Training metrics: perplexity: 1.213 cross_entropy: 0.193 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:40 INFO 139950662330176] Epoch: 1, batches: 900, num_examples: 460800, 14836.9 samples/sec, epoch time so far: 0:00:31.057660\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:40 INFO 139950662330176] #011Training metrics: perplexity: 1.213 cross_entropy: 0.193 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:43 INFO 139950662330176] Epoch: 1, batches: 1000, num_examples: 512000, 14831.7 samples/sec, epoch time so far: 0:00:34.520702\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:43 INFO 139950662330176] #011Training metrics: perplexity: 1.214 cross_entropy: 0.194 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:47 INFO 139950662330176] Epoch: 1, batches: 1100, num_examples: 563200, 14835.6 samples/sec, epoch time so far: 0:00:37.962792\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:47 INFO 139950662330176] #011Training metrics: perplexity: 1.214 cross_entropy: 0.194 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:50 INFO 139950662330176] Epoch: 1, batches: 1200, num_examples: 614400, 14840.4 samples/sec, epoch time so far: 0:00:41.400639\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:50 INFO 139950662330176] #011Training metrics: perplexity: 1.214 cross_entropy: 0.194 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:53 INFO 139950662330176] Epoch: 1, batches: 1300, num_examples: 665600, 14846.4 samples/sec, epoch time so far: 0:00:44.832344\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:53 INFO 139950662330176] #011Training metrics: perplexity: 1.215 cross_entropy: 0.194 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:57 INFO 139950662330176] Epoch: 1, batches: 1400, num_examples: 716800, 14851.8 samples/sec, epoch time so far: 0:00:48.263430\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:05:57 INFO 139950662330176] #011Training metrics: perplexity: 1.215 cross_entropy: 0.195 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:00 INFO 139950662330176] Epoch: 1, batches: 1500, num_examples: 768000, 14854.6 samples/sec, epoch time so far: 0:00:51.701131\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:00 INFO 139950662330176] #011Training metrics: perplexity: 1.215 cross_entropy: 0.195 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:04 INFO 139950662330176] Epoch: 1, batches: 1600, num_examples: 819200, 14854.8 samples/sec, epoch time so far: 0:00:55.147027\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:04 INFO 139950662330176] #011Training metrics: perplexity: 1.215 cross_entropy: 0.195 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:07 INFO 139950662330176] Epoch: 1, batches: 1700, num_examples: 870400, 14855.4 samples/sec, epoch time so far: 0:00:58.591468\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:07 INFO 139950662330176] #011Training metrics: perplexity: 1.216 cross_entropy: 0.195 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:11 INFO 139950662330176] Epoch: 1, batches: 1800, num_examples: 921600, 14856.4 samples/sec, epoch time so far: 0:01:02.034074\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:11 INFO 139950662330176] #011Training metrics: perplexity: 1.216 cross_entropy: 0.195 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:14 INFO 139950662330176] Epoch: 1, batches: 1900, num_examples: 972800, 14856.1 samples/sec, epoch time so far: 0:01:05.481451\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:14 INFO 139950662330176] #011Training metrics: perplexity: 1.216 cross_entropy: 0.195 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:16 INFO 139950662330176] **************\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:16 INFO 139950662330176] Completed Epoch: 1, time taken: 0:01:07.411063\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:16 INFO 139950662330176] Epoch 1 Training metrics:   perplexity: 1.216 cross_entropy: 0.196 accuracy: 0.924 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:16 INFO 139950662330176] #quality_metric: host=algo-1, epoch=1, train cross_entropy <loss>=0.19560667018\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:16 INFO 139950662330176] #quality_metric: host=algo-1, epoch=1, train accuracy <score>=0.923812148517\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:19 INFO 139950662330176] Epoch 1 Validation metrics: perplexity: 1.214 cross_entropy: 0.194 accuracy: 0.921 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:19 INFO 139950662330176] #quality_metric: host=algo-1, epoch=1, validation cross_entropy <loss>=0.194109261415\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:19 INFO 139950662330176] #quality_metric: host=algo-1, epoch=1, validation accuracy <score>=0.920981197034\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:19 INFO 139950662330176] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 12.82501220703125, \"sum\": 12.82501220703125, \"min\": 12.82501220703125}, \"update.time\": {\"count\": 1, \"max\": 70412.96100616455, \"sum\": 70412.96100616455, \"min\": 70412.96100616455}}, \"EndTime\": 1602853579.511344, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1602853508.359495}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:19 INFO 139950662330176] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1956, \"sum\": 1956.0, \"min\": 1956}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1956, \"sum\": 1956.0, \"min\": 1956}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1001472, \"sum\": 1001472.0, \"min\": 1001472}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3909, \"sum\": 3909.0, \"min\": 3909}, \"Total Records Seen\": {\"count\": 1, \"max\": 2001408, \"sum\": 2001408.0, \"min\": 2001408}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1001472, \"sum\": 1001472.0, \"min\": 1001472}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1602853579.511639, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 1}, \"StartTime\": 1602853509.098358}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:19 INFO 139950662330176] #throughput_metric: host=algo-1, train throughput=14222.7387195 records/second\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:23 INFO 139950662330176] Epoch: 2, batches: 100, num_examples: 51200, 14806.2 samples/sec, epoch time so far: 0:00:03.458016\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:23 INFO 139950662330176] #011Training metrics: perplexity: 1.163 cross_entropy: 0.151 accuracy: 0.942 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:26 INFO 139950662330176] Epoch: 2, batches: 200, num_examples: 102400, 14851.0 samples/sec, epoch time so far: 0:00:06.895167\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:26 INFO 139950662330176] #011Training metrics: perplexity: 1.164 cross_entropy: 0.152 accuracy: 0.942 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:30 INFO 139950662330176] Epoch: 2, batches: 300, num_examples: 153600, 14866.0 samples/sec, epoch time so far: 0:00:10.332336\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:30 INFO 139950662330176] #011Training metrics: perplexity: 1.165 cross_entropy: 0.152 accuracy: 0.942 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:33 INFO 139950662330176] Epoch: 2, batches: 400, num_examples: 204800, 14865.8 samples/sec, epoch time so far: 0:00:13.776589\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:33 INFO 139950662330176] #011Training metrics: perplexity: 1.164 cross_entropy: 0.152 accuracy: 0.942 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:37 INFO 139950662330176] Epoch: 2, batches: 500, num_examples: 256000, 14866.2 samples/sec, epoch time so far: 0:00:17.220267\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:37 INFO 139950662330176] #011Training metrics: perplexity: 1.164 cross_entropy: 0.152 accuracy: 0.942 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:40 INFO 139950662330176] Epoch: 2, batches: 600, num_examples: 307200, 14878.9 samples/sec, epoch time so far: 0:00:20.646679\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:40 INFO 139950662330176] #011Training metrics: perplexity: 1.164 cross_entropy: 0.152 accuracy: 0.942 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:44 INFO 139950662330176] Epoch: 2, batches: 700, num_examples: 358400, 14870.0 samples/sec, epoch time so far: 0:00:24.102284\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:44 INFO 139950662330176] #011Training metrics: perplexity: 1.164 cross_entropy: 0.152 accuracy: 0.942 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:47 INFO 139950662330176] Epoch: 2, batches: 800, num_examples: 409600, 14873.6 samples/sec, epoch time so far: 0:00:27.538693\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:47 INFO 139950662330176] #011Training metrics: perplexity: 1.164 cross_entropy: 0.152 accuracy: 0.942 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:50 INFO 139950662330176] Epoch: 2, batches: 900, num_examples: 460800, 14875.0 samples/sec, epoch time so far: 0:00:30.978091\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:50 INFO 139950662330176] #011Training metrics: perplexity: 1.165 cross_entropy: 0.153 accuracy: 0.942 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:54 INFO 139950662330176] Epoch: 2, batches: 1000, num_examples: 512000, 14871.2 samples/sec, epoch time so far: 0:00:34.428862\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:54 INFO 139950662330176] #011Training metrics: perplexity: 1.166 cross_entropy: 0.153 accuracy: 0.942 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:57 INFO 139950662330176] Epoch: 2, batches: 1100, num_examples: 563200, 14871.9 samples/sec, epoch time so far: 0:00:37.870113\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:06:57 INFO 139950662330176] #011Training metrics: perplexity: 1.166 cross_entropy: 0.154 accuracy: 0.941 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:01 INFO 139950662330176] Epoch: 2, batches: 1200, num_examples: 614400, 14873.8 samples/sec, epoch time so far: 0:00:41.307656\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:01 INFO 139950662330176] #011Training metrics: perplexity: 1.166 cross_entropy: 0.154 accuracy: 0.941 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:04 INFO 139950662330176] Epoch: 2, batches: 1300, num_examples: 665600, 14869.6 samples/sec, epoch time so far: 0:00:44.762535\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:04 INFO 139950662330176] #011Training metrics: perplexity: 1.166 cross_entropy: 0.154 accuracy: 0.941 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:08 INFO 139950662330176] Epoch: 2, batches: 1400, num_examples: 716800, 14868.9 samples/sec, epoch time so far: 0:00:48.207894\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:08 INFO 139950662330176] #011Training metrics: perplexity: 1.167 cross_entropy: 0.154 accuracy: 0.941 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:11 INFO 139950662330176] Epoch: 2, batches: 1500, num_examples: 768000, 14869.0 samples/sec, epoch time so far: 0:00:51.651153\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:11 INFO 139950662330176] #011Training metrics: perplexity: 1.167 cross_entropy: 0.155 accuracy: 0.941 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:15 INFO 139950662330176] Epoch: 2, batches: 1600, num_examples: 819200, 14863.9 samples/sec, epoch time so far: 0:00:55.113469\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:15 INFO 139950662330176] #011Training metrics: perplexity: 1.167 cross_entropy: 0.155 accuracy: 0.941 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:18 INFO 139950662330176] Epoch: 2, batches: 1700, num_examples: 870400, 14859.9 samples/sec, epoch time so far: 0:00:58.573689\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:18 INFO 139950662330176] #011Training metrics: perplexity: 1.168 cross_entropy: 0.155 accuracy: 0.941 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:21 INFO 139950662330176] Epoch: 2, batches: 1800, num_examples: 921600, 14859.5 samples/sec, epoch time so far: 0:01:02.020733\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:21 INFO 139950662330176] #011Training metrics: perplexity: 1.168 cross_entropy: 0.156 accuracy: 0.941 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:25 INFO 139950662330176] Epoch: 2, batches: 1900, num_examples: 972800, 14860.6 samples/sec, epoch time so far: 0:01:05.461525\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:25 INFO 139950662330176] #011Training metrics: perplexity: 1.169 cross_entropy: 0.156 accuracy: 0.941 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:27 INFO 139950662330176] **************\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:27 INFO 139950662330176] Completed Epoch: 2, time taken: 0:01:07.388640\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:27 INFO 139950662330176] Epoch 2 Training metrics:   perplexity: 1.169 cross_entropy: 0.156 accuracy: 0.941 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:27 INFO 139950662330176] #quality_metric: host=algo-1, epoch=2, train cross_entropy <loss>=0.155856276297\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:27 INFO 139950662330176] #quality_metric: host=algo-1, epoch=2, train accuracy <score>=0.940545516999\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:30 INFO 139950662330176] Epoch 2 Validation metrics: perplexity: 1.194 cross_entropy: 0.177 accuracy: 0.931 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:30 INFO 139950662330176] #quality_metric: host=algo-1, epoch=2, validation cross_entropy <loss>=0.177284472701\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:30 INFO 139950662330176] #quality_metric: host=algo-1, epoch=2, validation accuracy <score>=0.930829581568\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:30 INFO 139950662330176] **************\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:30 INFO 139950662330176] patience losses: [0.22147877236544075, 0.19410926141476226]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:30 INFO 139950662330176] min patience losses: 0.194109261415\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:30 INFO 139950662330176] current loss: 0.177284472701\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:30 INFO 139950662330176] absolute loss difference: 0.0168247887139\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 14.532089233398438, \"sum\": 14.532089233398438, \"min\": 14.532089233398438}, \"update.time\": {\"count\": 1, \"max\": 70401.77607536316, \"sum\": 70401.77607536316, \"min\": 70401.77607536316}}, \"EndTime\": 1602853650.330032, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1602853579.511422}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:30 INFO 139950662330176] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1956, \"sum\": 1956.0, \"min\": 1956}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1956, \"sum\": 1956.0, \"min\": 1956}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1001472, \"sum\": 1001472.0, \"min\": 1001472}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5865, \"sum\": 5865.0, \"min\": 5865}, \"Total Records Seen\": {\"count\": 1, \"max\": 3002880, \"sum\": 3002880.0, \"min\": 3002880}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1001472, \"sum\": 1001472.0, \"min\": 1001472}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1602853650.330306, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 2}, \"StartTime\": 1602853579.928225}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:30 INFO 139950662330176] #throughput_metric: host=algo-1, train throughput=14225.0065969 records/second\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:34 INFO 139950662330176] Epoch: 3, batches: 100, num_examples: 51200, 14800.9 samples/sec, epoch time so far: 0:00:03.459253\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:34 INFO 139950662330176] #011Training metrics: perplexity: 1.140 cross_entropy: 0.132 accuracy: 0.950 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:37 INFO 139950662330176] Epoch: 3, batches: 200, num_examples: 102400, 14808.3 samples/sec, epoch time so far: 0:00:06.915024\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:37 INFO 139950662330176] #011Training metrics: perplexity: 1.139 cross_entropy: 0.130 accuracy: 0.951 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:41 INFO 139950662330176] Epoch: 3, batches: 300, num_examples: 153600, 14788.7 samples/sec, epoch time so far: 0:00:10.386286\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:41 INFO 139950662330176] #011Training metrics: perplexity: 1.139 cross_entropy: 0.130 accuracy: 0.951 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:44 INFO 139950662330176] Epoch: 3, batches: 400, num_examples: 204800, 14791.3 samples/sec, epoch time so far: 0:00:13.845961\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:44 INFO 139950662330176] #011Training metrics: perplexity: 1.139 cross_entropy: 0.130 accuracy: 0.951 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:48 INFO 139950662330176] Epoch: 3, batches: 500, num_examples: 256000, 14807.8 samples/sec, epoch time so far: 0:00:17.288135\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:48 INFO 139950662330176] #011Training metrics: perplexity: 1.140 cross_entropy: 0.131 accuracy: 0.951 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:51 INFO 139950662330176] Epoch: 3, batches: 600, num_examples: 307200, 14806.1 samples/sec, epoch time so far: 0:00:20.748207\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:51 INFO 139950662330176] #011Training metrics: perplexity: 1.140 cross_entropy: 0.131 accuracy: 0.951 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:54 INFO 139950662330176] Epoch: 3, batches: 700, num_examples: 358400, 14810.6 samples/sec, epoch time so far: 0:00:24.198845\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:54 INFO 139950662330176] #011Training metrics: perplexity: 1.140 cross_entropy: 0.131 accuracy: 0.951 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:58 INFO 139950662330176] Epoch: 3, batches: 800, num_examples: 409600, 14821.8 samples/sec, epoch time so far: 0:00:27.634982\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:07:58 INFO 139950662330176] #011Training metrics: perplexity: 1.140 cross_entropy: 0.131 accuracy: 0.951 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:01 INFO 139950662330176] Epoch: 3, batches: 900, num_examples: 460800, 14817.6 samples/sec, epoch time so far: 0:00:31.098234\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:01 INFO 139950662330176] #011Training metrics: perplexity: 1.140 cross_entropy: 0.131 accuracy: 0.950 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:05 INFO 139950662330176] Epoch: 3, batches: 1000, num_examples: 512000, 14817.0 samples/sec, epoch time so far: 0:00:34.554974\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:05 INFO 139950662330176] #011Training metrics: perplexity: 1.141 cross_entropy: 0.132 accuracy: 0.950 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:08 INFO 139950662330176] Epoch: 3, batches: 1100, num_examples: 563200, 14819.7 samples/sec, epoch time so far: 0:00:38.003522\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:08 INFO 139950662330176] #011Training metrics: perplexity: 1.141 cross_entropy: 0.132 accuracy: 0.950 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:12 INFO 139950662330176] Epoch: 3, batches: 1200, num_examples: 614400, 14813.4 samples/sec, epoch time so far: 0:00:41.475840\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:12 INFO 139950662330176] #011Training metrics: perplexity: 1.141 cross_entropy: 0.132 accuracy: 0.950 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:15 INFO 139950662330176] Epoch: 3, batches: 1300, num_examples: 665600, 14814.4 samples/sec, epoch time so far: 0:00:44.929220\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:15 INFO 139950662330176] #011Training metrics: perplexity: 1.142 cross_entropy: 0.133 accuracy: 0.950 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:19 INFO 139950662330176] Epoch: 3, batches: 1400, num_examples: 716800, 14819.4 samples/sec, epoch time so far: 0:00:48.368983\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:19 INFO 139950662330176] #011Training metrics: perplexity: 1.142 cross_entropy: 0.133 accuracy: 0.950 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:22 INFO 139950662330176] Epoch: 3, batches: 1500, num_examples: 768000, 14817.9 samples/sec, epoch time so far: 0:00:51.829036\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:22 INFO 139950662330176] #011Training metrics: perplexity: 1.143 cross_entropy: 0.134 accuracy: 0.950 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:26 INFO 139950662330176] Epoch: 3, batches: 1600, num_examples: 819200, 14818.0 samples/sec, epoch time so far: 0:00:55.284022\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:26 INFO 139950662330176] #011Training metrics: perplexity: 1.144 cross_entropy: 0.134 accuracy: 0.950 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:29 INFO 139950662330176] Epoch: 3, batches: 1700, num_examples: 870400, 14822.7 samples/sec, epoch time so far: 0:00:58.720692\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:29 INFO 139950662330176] #011Training metrics: perplexity: 1.144 cross_entropy: 0.135 accuracy: 0.950 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:32 INFO 139950662330176] Epoch: 3, batches: 1800, num_examples: 921600, 14819.9 samples/sec, epoch time so far: 0:01:02.186495\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:32 INFO 139950662330176] #011Training metrics: perplexity: 1.144 cross_entropy: 0.135 accuracy: 0.949 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:36 INFO 139950662330176] Epoch: 3, batches: 1900, num_examples: 972800, 14819.2 samples/sec, epoch time so far: 0:01:05.644512\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:36 INFO 139950662330176] #011Training metrics: perplexity: 1.144 cross_entropy: 0.135 accuracy: 0.949 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:38 INFO 139950662330176] **************\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:38 INFO 139950662330176] Completed Epoch: 3, time taken: 0:01:07.568284\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:38 INFO 139950662330176] Epoch 3 Training metrics:   perplexity: 1.145 cross_entropy: 0.135 accuracy: 0.949 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:38 INFO 139950662330176] #quality_metric: host=algo-1, epoch=3, train cross_entropy <loss>=0.135079859465\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:38 INFO 139950662330176] #quality_metric: host=algo-1, epoch=3, train accuracy <score>=0.94921875\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:41 INFO 139950662330176] Epoch 3 Validation metrics: perplexity: 1.205 cross_entropy: 0.187 accuracy: 0.930 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:41 INFO 139950662330176] #quality_metric: host=algo-1, epoch=3, validation cross_entropy <loss>=0.186672900945\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:41 INFO 139950662330176] #quality_metric: host=algo-1, epoch=3, validation accuracy <score>=0.929538532839\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:41 INFO 139950662330176] **************\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:41 INFO 139950662330176] patience losses: [0.19410926141476226, 0.17728447270090297]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:41 INFO 139950662330176] min patience losses: 0.177284472701\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:41 INFO 139950662330176] current loss: 0.186672900945\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:41 INFO 139950662330176] absolute loss difference: 0.00938842824455\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:41 INFO 139950662330176] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.5080699920654297, \"sum\": 0.5080699920654297, \"min\": 0.5080699920654297}, \"update.time\": {\"count\": 1, \"max\": 70565.0110244751, \"sum\": 70565.0110244751, \"min\": 70565.0110244751}}, \"EndTime\": 1602853721.330189, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1602853650.330123}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:41 INFO 139950662330176] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1956, \"sum\": 1956.0, \"min\": 1956}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1956, \"sum\": 1956.0, \"min\": 1956}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1001472, \"sum\": 1001472.0, \"min\": 1001472}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7821, \"sum\": 7821.0, \"min\": 7821}, \"Total Records Seen\": {\"count\": 1, \"max\": 4004352, \"sum\": 4004352.0, \"min\": 4004352}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1001472, \"sum\": 1001472.0, \"min\": 1001472}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1602853721.33045, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 3}, \"StartTime\": 1602853650.765146}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:41 INFO 139950662330176] #throughput_metric: host=algo-1, train throughput=14192.0978887 records/second\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:44 INFO 139950662330176] Epoch: 4, batches: 100, num_examples: 51200, 14808.7 samples/sec, epoch time so far: 0:00:03.457420\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:44 INFO 139950662330176] #011Training metrics: perplexity: 1.129 cross_entropy: 0.121 accuracy: 0.954 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:48 INFO 139950662330176] Epoch: 4, batches: 200, num_examples: 102400, 14827.1 samples/sec, epoch time so far: 0:00:06.906250\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:48 INFO 139950662330176] #011Training metrics: perplexity: 1.128 cross_entropy: 0.120 accuracy: 0.955 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:51 INFO 139950662330176] Epoch: 4, batches: 300, num_examples: 153600, 14820.7 samples/sec, epoch time so far: 0:00:10.363864\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:51 INFO 139950662330176] #011Training metrics: perplexity: 1.126 cross_entropy: 0.119 accuracy: 0.955 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:55 INFO 139950662330176] Epoch: 4, batches: 400, num_examples: 204800, 14827.0 samples/sec, epoch time so far: 0:00:13.812674\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:55 INFO 139950662330176] #011Training metrics: perplexity: 1.125 cross_entropy: 0.118 accuracy: 0.956 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:58 INFO 139950662330176] Epoch: 4, batches: 500, num_examples: 256000, 14836.6 samples/sec, epoch time so far: 0:00:17.254662\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:08:58 INFO 139950662330176] #011Training metrics: perplexity: 1.126 cross_entropy: 0.119 accuracy: 0.956 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:02 INFO 139950662330176] Epoch: 4, batches: 600, num_examples: 307200, 14805.8 samples/sec, epoch time so far: 0:00:20.748587\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:02 INFO 139950662330176] #011Training metrics: perplexity: 1.126 cross_entropy: 0.119 accuracy: 0.956 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:05 INFO 139950662330176] Epoch: 4, batches: 700, num_examples: 358400, 14797.7 samples/sec, epoch time so far: 0:00:24.219903\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:05 INFO 139950662330176] #011Training metrics: perplexity: 1.127 cross_entropy: 0.119 accuracy: 0.956 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:09 INFO 139950662330176] Epoch: 4, batches: 800, num_examples: 409600, 14803.0 samples/sec, epoch time so far: 0:00:27.669988\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:09 INFO 139950662330176] #011Training metrics: perplexity: 1.127 cross_entropy: 0.119 accuracy: 0.956 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:12 INFO 139950662330176] Epoch: 4, batches: 900, num_examples: 460800, 14803.5 samples/sec, epoch time so far: 0:00:31.127856\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:12 INFO 139950662330176] #011Training metrics: perplexity: 1.127 cross_entropy: 0.119 accuracy: 0.956 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:16 INFO 139950662330176] Epoch: 4, batches: 1000, num_examples: 512000, 14801.3 samples/sec, epoch time so far: 0:00:34.591522\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:16 INFO 139950662330176] #011Training metrics: perplexity: 1.127 cross_entropy: 0.120 accuracy: 0.956 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:19 INFO 139950662330176] Epoch: 4, batches: 1100, num_examples: 563200, 14808.4 samples/sec, epoch time so far: 0:00:38.032560\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:19 INFO 139950662330176] #011Training metrics: perplexity: 1.128 cross_entropy: 0.120 accuracy: 0.955 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:23 INFO 139950662330176] Epoch: 4, batches: 1200, num_examples: 614400, 14809.3 samples/sec, epoch time so far: 0:00:41.487404\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:23 INFO 139950662330176] #011Training metrics: perplexity: 1.128 cross_entropy: 0.121 accuracy: 0.955 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:26 INFO 139950662330176] Epoch: 4, batches: 1300, num_examples: 665600, 14811.0 samples/sec, epoch time so far: 0:00:44.939673\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:26 INFO 139950662330176] #011Training metrics: perplexity: 1.128 cross_entropy: 0.121 accuracy: 0.955 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:29 INFO 139950662330176] Epoch: 4, batches: 1400, num_examples: 716800, 14816.0 samples/sec, epoch time so far: 0:00:48.379985\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:29 INFO 139950662330176] #011Training metrics: perplexity: 1.129 cross_entropy: 0.121 accuracy: 0.955 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:33 INFO 139950662330176] Epoch: 4, batches: 1500, num_examples: 768000, 14815.8 samples/sec, epoch time so far: 0:00:51.836423\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:33 INFO 139950662330176] #011Training metrics: perplexity: 1.129 cross_entropy: 0.122 accuracy: 0.955 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:36 INFO 139950662330176] Epoch: 4, batches: 1600, num_examples: 819200, 14814.9 samples/sec, epoch time so far: 0:00:55.295645\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:36 INFO 139950662330176] #011Training metrics: perplexity: 1.130 cross_entropy: 0.122 accuracy: 0.955 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:40 INFO 139950662330176] Epoch: 4, batches: 1700, num_examples: 870400, 14817.4 samples/sec, epoch time so far: 0:00:58.741605\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:40 INFO 139950662330176] #011Training metrics: perplexity: 1.130 cross_entropy: 0.122 accuracy: 0.955 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:43 INFO 139950662330176] Epoch: 4, batches: 1800, num_examples: 921600, 14818.1 samples/sec, epoch time so far: 0:01:02.194200\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:43 INFO 139950662330176] #011Training metrics: perplexity: 1.130 cross_entropy: 0.123 accuracy: 0.955 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:47 INFO 139950662330176] Epoch: 4, batches: 1900, num_examples: 972800, 14819.1 samples/sec, epoch time so far: 0:01:05.645006\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:47 INFO 139950662330176] #011Training metrics: perplexity: 1.130 cross_entropy: 0.123 accuracy: 0.955 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:49 INFO 139950662330176] **************\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:49 INFO 139950662330176] Completed Epoch: 4, time taken: 0:01:07.564889\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:49 INFO 139950662330176] Epoch 4 Training metrics:   perplexity: 1.131 cross_entropy: 0.123 accuracy: 0.955 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:49 INFO 139950662330176] #quality_metric: host=algo-1, epoch=4, train cross_entropy <loss>=0.122839106582\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:49 INFO 139950662330176] #quality_metric: host=algo-1, epoch=4, train accuracy <score>=0.954619799655\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:52 INFO 139950662330176] Epoch 4 Validation metrics: perplexity: 1.213 cross_entropy: 0.193 accuracy: 0.932 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:52 INFO 139950662330176] #quality_metric: host=algo-1, epoch=4, validation cross_entropy <loss>=0.192773067598\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:52 INFO 139950662330176] #quality_metric: host=algo-1, epoch=4, validation accuracy <score>=0.932170286017\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:52 INFO 139950662330176] **************\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:52 INFO 139950662330176] patience losses: [0.17728447270090297, 0.18667290094545333]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:52 INFO 139950662330176] min patience losses: 0.177284472701\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:52 INFO 139950662330176] current loss: 0.192773067598\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:52 INFO 139950662330176] absolute loss difference: 0.0154885948967\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:52 INFO 139950662330176] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.5588531494140625, \"sum\": 0.5588531494140625, \"min\": 0.5588531494140625}, \"update.time\": {\"count\": 1, \"max\": 70572.26204872131, \"sum\": 70572.26204872131, \"min\": 70572.26204872131}}, \"EndTime\": 1602853792.094654, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1602853721.330268}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:52 INFO 139950662330176] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1956, \"sum\": 1956.0, \"min\": 1956}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1956, \"sum\": 1956.0, \"min\": 1956}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1001472, \"sum\": 1001472.0, \"min\": 1001472}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9777, \"sum\": 9777.0, \"min\": 9777}, \"Total Records Seen\": {\"count\": 1, \"max\": 5005824, \"sum\": 5005824.0, \"min\": 5005824}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1001472, \"sum\": 1001472.0, \"min\": 1001472}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1602853792.094956, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 4}, \"StartTime\": 1602853721.522362}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:52 INFO 139950662330176] #throughput_metric: host=algo-1, train throughput=14190.6342502 records/second\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:55 INFO 139950662330176] Epoch: 5, batches: 100, num_examples: 51200, 14896.0 samples/sec, epoch time so far: 0:00:03.437171\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:55 INFO 139950662330176] #011Training metrics: perplexity: 1.116 cross_entropy: 0.110 accuracy: 0.958 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:59 INFO 139950662330176] Epoch: 5, batches: 200, num_examples: 102400, 14892.2 samples/sec, epoch time so far: 0:00:06.876095\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:09:59 INFO 139950662330176] #011Training metrics: perplexity: 1.114 cross_entropy: 0.108 accuracy: 0.959 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:02 INFO 139950662330176] Epoch: 5, batches: 300, num_examples: 153600, 14849.4 samples/sec, epoch time so far: 0:00:10.343846\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:02 INFO 139950662330176] #011Training metrics: perplexity: 1.115 cross_entropy: 0.109 accuracy: 0.959 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:06 INFO 139950662330176] Epoch: 5, batches: 400, num_examples: 204800, 14833.7 samples/sec, epoch time so far: 0:00:13.806370\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:06 INFO 139950662330176] #011Training metrics: perplexity: 1.114 cross_entropy: 0.108 accuracy: 0.960 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:09 INFO 139950662330176] Epoch: 5, batches: 500, num_examples: 256000, 14844.0 samples/sec, epoch time so far: 0:00:17.246030\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:09 INFO 139950662330176] #011Training metrics: perplexity: 1.115 cross_entropy: 0.109 accuracy: 0.959 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:12 INFO 139950662330176] Epoch: 5, batches: 600, num_examples: 307200, 14843.7 samples/sec, epoch time so far: 0:00:20.695653\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:12 INFO 139950662330176] #011Training metrics: perplexity: 1.116 cross_entropy: 0.109 accuracy: 0.960 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:16 INFO 139950662330176] Epoch: 5, batches: 700, num_examples: 358400, 14844.2 samples/sec, epoch time so far: 0:00:24.144050\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:16 INFO 139950662330176] #011Training metrics: perplexity: 1.116 cross_entropy: 0.110 accuracy: 0.960 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:19 INFO 139950662330176] Epoch: 5, batches: 800, num_examples: 409600, 14847.9 samples/sec, epoch time so far: 0:00:27.586376\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:19 INFO 139950662330176] #011Training metrics: perplexity: 1.116 cross_entropy: 0.110 accuracy: 0.959 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:23 INFO 139950662330176] Epoch: 5, batches: 900, num_examples: 460800, 14847.6 samples/sec, epoch time so far: 0:00:31.035224\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:23 INFO 139950662330176] #011Training metrics: perplexity: 1.117 cross_entropy: 0.110 accuracy: 0.959 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:26 INFO 139950662330176] Epoch: 5, batches: 1000, num_examples: 512000, 14848.7 samples/sec, epoch time so far: 0:00:34.481242\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:26 INFO 139950662330176] #011Training metrics: perplexity: 1.117 cross_entropy: 0.111 accuracy: 0.959 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:30 INFO 139950662330176] Epoch: 5, batches: 1100, num_examples: 563200, 14850.8 samples/sec, epoch time so far: 0:00:37.923912\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:30 INFO 139950662330176] #011Training metrics: perplexity: 1.118 cross_entropy: 0.111 accuracy: 0.959 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:33 INFO 139950662330176] Epoch: 5, batches: 1200, num_examples: 614400, 14848.7 samples/sec, epoch time so far: 0:00:41.377283\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:33 INFO 139950662330176] #011Training metrics: perplexity: 1.118 cross_entropy: 0.112 accuracy: 0.959 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:37 INFO 139950662330176] Epoch: 5, batches: 1300, num_examples: 665600, 14847.8 samples/sec, epoch time so far: 0:00:44.828081\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:37 INFO 139950662330176] #011Training metrics: perplexity: 1.119 cross_entropy: 0.112 accuracy: 0.959 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:40 INFO 139950662330176] Epoch: 5, batches: 1400, num_examples: 716800, 14847.2 samples/sec, epoch time so far: 0:00:48.278379\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:40 INFO 139950662330176] #011Training metrics: perplexity: 1.119 cross_entropy: 0.112 accuracy: 0.959 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:44 INFO 139950662330176] Epoch: 5, batches: 1500, num_examples: 768000, 14843.0 samples/sec, epoch time so far: 0:00:51.741471\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:44 INFO 139950662330176] #011Training metrics: perplexity: 1.119 cross_entropy: 0.113 accuracy: 0.959 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:47 INFO 139950662330176] Epoch: 5, batches: 1600, num_examples: 819200, 14843.5 samples/sec, epoch time so far: 0:00:55.189019\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:47 INFO 139950662330176] #011Training metrics: perplexity: 1.120 cross_entropy: 0.113 accuracy: 0.958 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:50 INFO 139950662330176] Epoch: 5, batches: 1700, num_examples: 870400, 14846.0 samples/sec, epoch time so far: 0:00:58.628600\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:50 INFO 139950662330176] #011Training metrics: perplexity: 1.120 cross_entropy: 0.114 accuracy: 0.958 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:54 INFO 139950662330176] Epoch: 5, batches: 1800, num_examples: 921600, 14848.2 samples/sec, epoch time so far: 0:01:02.068159\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:54 INFO 139950662330176] #011Training metrics: perplexity: 1.120 cross_entropy: 0.114 accuracy: 0.958 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:57 INFO 139950662330176] Epoch: 5, batches: 1900, num_examples: 972800, 14847.7 samples/sec, epoch time so far: 0:01:05.518706\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:57 INFO 139950662330176] #011Training metrics: perplexity: 1.120 cross_entropy: 0.114 accuracy: 0.958 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:59 INFO 139950662330176] **************\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:59 INFO 139950662330176] Completed Epoch: 5, time taken: 0:01:07.435113\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:59 INFO 139950662330176] Epoch 5 Training metrics:   perplexity: 1.121 cross_entropy: 0.114 accuracy: 0.958 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:59 INFO 139950662330176] #quality_metric: host=algo-1, epoch=5, train cross_entropy <loss>=0.114010479054\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:10:59 INFO 139950662330176] #quality_metric: host=algo-1, epoch=5, train accuracy <score>=0.958123641999\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] Epoch 5 Validation metrics: perplexity: 1.229 cross_entropy: 0.207 accuracy: 0.930 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] #quality_metric: host=algo-1, epoch=5, validation cross_entropy <loss>=0.206759172223\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] #quality_metric: host=algo-1, epoch=5, validation accuracy <score>=0.92963784428\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] **************\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] patience losses: [0.18667290094545333, 0.1927730675976155]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] min patience losses: 0.186672900945\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] current loss: 0.206759172223\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] absolute loss difference: 0.0200862712779\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] Bad epochs exceeded patience. Stopping training early!\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] Early stopping criterion met! Stopping training at epoch: 5\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.6787776947021484, \"sum\": 0.6787776947021484, \"min\": 0.6787776947021484}, \"update.time\": {\"count\": 1, \"max\": 70427.56986618042, \"sum\": 70427.56986618042, \"min\": 70427.56986618042}}, \"EndTime\": 1602853862.710668, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1602853792.094765}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1956, \"sum\": 1956.0, \"min\": 1956}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1956, \"sum\": 1956.0, \"min\": 1956}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1001472, \"sum\": 1001472.0, \"min\": 1001472}, \"Total Batches Seen\": {\"count\": 1, \"max\": 11733, \"sum\": 11733.0, \"min\": 11733}, \"Total Records Seen\": {\"count\": 1, \"max\": 6007296, \"sum\": 6007296.0, \"min\": 6007296}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1001472, \"sum\": 1001472.0, \"min\": 1001472}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1602853862.711024, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 5}, \"StartTime\": 1602853792.283069}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] #throughput_metric: host=algo-1, train throughput=14219.7781534 records/second\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 WARNING 139950662330176] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] Best model based on epoch 2. Best loss: 0.177\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 1.2791156768798828, \"sum\": 1.2791156768798828, \"min\": 1.2791156768798828}}, \"EndTime\": 1602853862.712642, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1602853862.710766}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] Serializing model to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:02 INFO 139950662330176] Saved checkpoint to \"/tmp/tmpccwCwP/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:06 INFO 139950662330176] Finished scoring on 60416 examples from 118 batches, each of size 512.\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:06 INFO 139950662330176] Test Metrics:perplexity: 1.204 cross_entropy: 0.186 accuracy: 0.928 \u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:06 INFO 139950662330176] Test Metric names:['perplexity', 'cross_entropy', 'accuracy']\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:06 INFO 139950662330176] Test Metric values:[1.204453543356123, 0.186025965011726, 0.9282143802966102]\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:06 INFO 139950662330176] Test Metric names and values:[('perplexity', 1.204453543356123), ('cross_entropy', 0.186025965011726), ('accuracy', 0.9282143802966102)]\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 118, \"sum\": 118.0, \"min\": 118}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 118, \"sum\": 118.0, \"min\": 118}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 60416, \"sum\": 60416.0, \"min\": 60416}, \"Total Batches Seen\": {\"count\": 1, \"max\": 118, \"sum\": 118.0, \"min\": 118}, \"Total Records Seen\": {\"count\": 1, \"max\": 60416, \"sum\": 60416.0, \"min\": 60416}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 60416, \"sum\": 60416.0, \"min\": 60416}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1602853866.944379, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1602853863.944186}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:06 INFO 139950662330176] #test_score (algo-1) : ('perplexity', 1.204453543356123)\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:06 INFO 139950662330176] #test_score (algo-1) : ('cross_entropy', 0.186025965011726)\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:06 INFO 139950662330176] #test_score (algo-1) : ('accuracy', 0.9282143802966102)\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:06 INFO 139950662330176] #quality_metric: host=algo-1, test cross_entropy <loss>=0.186025965012\u001b[0m\n",
      "\u001b[34m[10/16/2020 13:11:06 INFO 139950662330176] #quality_metric: host=algo-1, test accuracy <score>=0.928214380297\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 557515.7330036163, \"sum\": 557515.7330036163, \"min\": 557515.7330036163}, \"model.score.time\": {\"count\": 1, \"max\": 3000.1018047332764, \"sum\": 3000.1018047332764, \"min\": 3000.1018047332764}, \"model.serialize.time\": {\"count\": 1, \"max\": 1231.1139106750488, \"sum\": 1231.1139106750488, \"min\": 1231.1139106750488}, \"setuptime\": {\"count\": 1, \"max\": 333.1270217895508, \"sum\": 333.1270217895508, \"min\": 333.1270217895508}}, \"EndTime\": 1602853866.977745, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1602853862.712693}\n",
      "\u001b[0m\n",
      "\n",
      "2020-10-16 13:11:51 Uploading - Uploading generated training model\n",
      "2020-10-16 13:12:39 Completed - Training job completed\n",
      "Training seconds: 750\n",
      "Billable seconds: 750\n"
     ]
    }
   ],
   "source": [
    "# set hyperparameters\n",
    "doc2vec.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "# fit estimator with data\n",
    "doc2vec.fit({'train': s3_train, 'validation':s3_valid, 'test':s3_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# deploy model\n",
    "\n",
    "doc2vec_model = doc2vec.create_model(\n",
    "                        serializer=json_serializer,\n",
    "                        deserializer=json_deserializer,\n",
    "                        content_type='application/json')\n",
    "\n",
    "predictor = doc2vec_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply learned embeddings to document retrieval task\n",
    "\n",
    "After training the model, we can use the encoders in Object2Vec to map new articles and sentences into a shared embedding space. Then we evaluate the quality of these embeddings with a downstream document retrieval task.\n",
    "\n",
    "In the retrieval task, given a sentence query, the trained algorithm needs to find its best matching document (the ground-truth document is the one that contains it) from a pool of documents, where the pool contains 10,000 other non ground-truth documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tokenized_articles_from_single_file(fname, word_dict):\n",
    "    for article in get_article_iter_from_file(fname):\n",
    "        integer_article = []\n",
    "        for sent in readlines_from_article(article):\n",
    "            integer_article += sentence_to_integers(sent, word_dict)\n",
    "        yield integer_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonline(fname):\n",
    "    \"\"\"\n",
    "    Reads jsonline files and returns iterator\n",
    "    \"\"\"\n",
    "    with jsonlines.open(fname) as reader:\n",
    "        for line in reader:\n",
    "            yield line\n",
    "\n",
    "def send_payload(predictor, payload):\n",
    "    return predictor.predict(payload)\n",
    "\n",
    "def write_to_jsonlines(data, fname):\n",
    "    with jsonlines.open(fname, 'a') as writer:\n",
    "        data = data['predictions']\n",
    "        writer.write_all(data)\n",
    "\n",
    "\n",
    "def eval_and_write(predictor, fname, to_fname,  batch_size):\n",
    "    if os.path.exists(to_fname):\n",
    "        print(\"Removing exisiting embedding file {}\".format(to_fname))\n",
    "        os.remove(to_fname)\n",
    "    print(\"Getting embedding of data in {} and store to {}...\".format(fname, to_fname))\n",
    "    test_data_content = list(read_jsonline(fname))\n",
    "    n_test = len(test_data_content)\n",
    "    n_batches = math.ceil(n_test / float(batch_size))\n",
    "    start = 0\n",
    "    for idx in range(n_batches):\n",
    "        if idx % 10 == 0:\n",
    "            print(\"Inference on the {}-th batch\".format(idx+1))\n",
    "        end = (start + batch_size) if (start + batch_size) <= n_test else n_test\n",
    "        payload = {'instances': test_data_content[start:end]}\n",
    "        data = send_payload(predictor, payload)\n",
    "        write_to_jsonlines(data, to_fname)\n",
    "        start = end\n",
    "\n",
    "def get_embeddings(predictor, test_data_content, batch_size):\n",
    "    n_test = len(test_data_content)\n",
    "    n_batches = math.ceil(n_test / float(batch_size))\n",
    "    start = 0\n",
    "    embeddings = []\n",
    "    for idx in range(n_batches):\n",
    "        if idx % 10 == 0:\n",
    "            print(\"Inference the {}-th batch\".format(idx+1))\n",
    "        end = (start + batch_size) if (start + batch_size) <= n_test else n_test\n",
    "        payload = {'instances': test_data_content[start:end]}\n",
    "        data = send_payload(predictor, payload)\n",
    "        embeddings += data['predictions']\n",
    "        start = end\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedocs_fpath = os.path.join(datadir, 'wikipedia_test_basedocs.txt')\n",
    "test_fpath = '{}_tokenized-nsr{}.jsonl'.format('test10k', test_nsr)\n",
    "eval_basedocs = 'test_basedocs_tokenized_in0.jsonl'\n",
    "basedocs_emb = 'test_basedocs_embeddings.jsonl'\n",
    "sent_doc_emb = 'test10k_embeddings_pairs.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import numpy as np\n",
    "basedocs_emb = 'test_basedocs_embeddings.jsonl'\n",
    "sent_doc_emb = 'test10k_embeddings_pairs.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting embedding of data in test_basedocs_tokenized_in0.jsonl and store to test_basedocs_embeddings.jsonl...\n",
      "Inference on the 1-th batch\n",
      "Inference on the 11-th batch\n",
      "Inference on the 21-th batch\n",
      "Inference on the 31-th batch\n",
      "Inference on the 41-th batch\n",
      "Inference on the 51-th batch\n",
      "Inference on the 61-th batch\n",
      "Inference on the 71-th batch\n",
      "Inference on the 81-th batch\n",
      "Inference on the 91-th batch\n",
      "Inference the 1-th batch\n",
      "Inference the 11-th batch\n",
      "Inference the 21-th batch\n",
      "Inference the 31-th batch\n",
      "Inference the 41-th batch\n",
      "Inference the 51-th batch\n",
      "Inference the 61-th batch\n",
      "Inference the 71-th batch\n",
      "Inference the 81-th batch\n",
      "Inference the 91-th batch\n",
      "Inference the 1-th batch\n",
      "Inference the 11-th batch\n",
      "Inference the 21-th batch\n",
      "Inference the 31-th batch\n",
      "Inference the 41-th batch\n",
      "Inference the 51-th batch\n",
      "Inference the 61-th batch\n",
      "Inference the 71-th batch\n",
      "Inference the 81-th batch\n",
      "Inference the 91-th batch\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# tokenize basedocs\n",
    "with jsonlines.open(eval_basedocs, 'w') as writer:\n",
    "    for data in generate_tokenized_articles_from_single_file(basedocs_fpath, w_dict):\n",
    "        writer.write({'in0': data})\n",
    "\n",
    "# get basedocs embedding\n",
    "eval_and_write(predictor, eval_basedocs, basedocs_emb, batch_size)\n",
    "\n",
    "\n",
    "# get embeddings for sentence and ground-truth article pairs\n",
    "sentences = []\n",
    "gt_articles = []\n",
    "for data in read_jsonline(test_fpath):\n",
    "    if data['label'] == 1:\n",
    "        sentences.append({'in0': data['in0']})\n",
    "        gt_articles.append({'in0': data['in1']})\n",
    "        \n",
    "sent_emb = get_embeddings(predictor, sentences, batch_size)\n",
    "doc_emb = get_embeddings(predictor, gt_articles, batch_size)\n",
    "\n",
    "with jsonlines.open(sent_doc_emb, 'w') as writer:\n",
    "    for (sent, doc) in zip(sent_emb, doc_emb):\n",
    "        writer.write({'sent': sent['embeddings'], 'doc': doc['embeddings']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del w_dict\n",
    "del sent_emb, doc_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blocks below evaluate the performance of Object2Vec model on the document retrieval task.\n",
    "\n",
    "We use two metrics hits@k and mean rank to evaluate the retrieval performance. Note that the ground-truth documents in the pool have the query sentence removed from them -- else the task would have been trivial.\n",
    "\n",
    "* hits@k:  It calculates the fraction of queries where its best-matching (ground-truth) document is contained in top k retrieved documents by the algorithm.\n",
    "* mean rank: It is the average rank of the best-matching documents, as determined by the algorithm, over all queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct normalized basedocs, sentences, and ground-truth docs embedding matrix\n",
    "\n",
    "basedocs = []\n",
    "with jsonlines.open(basedocs_emb) as reader:\n",
    "    for line in reader:\n",
    "        basedocs.append(np.array(line['embeddings'])) \n",
    "\n",
    "\n",
    "sent_embs = []\n",
    "gt_doc_embs = []\n",
    "\n",
    "with jsonlines.open(sent_doc_emb) as reader2:\n",
    "    for line2 in reader2:\n",
    "        sent_embs.append(line2['sent'])\n",
    "        gt_doc_embs.append(line2['doc'])\n",
    "\n",
    "basedocs_emb_mat = normalize(np.array(basedocs).T, axis=0)\n",
    "sent_emb_mat = normalize(np.array(sent_embs), axis=1)\n",
    "gt_emb_mat = normalize(np.array(gt_doc_embs).T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk_query_rank(sent_emb_mat, basedocs_emb_mat, gt_emb_mat, largest_k):\n",
    "    # this is a memory-consuming step if chunk is large\n",
    "    dot_with_basedocs = np.matmul(sent_emb_mat, basedocs_emb_mat)\n",
    "    dot_with_gt = np.diag(np.matmul(sent_emb_mat, gt_emb_mat))\n",
    "    final_ranking_scores = np.insert(dot_with_basedocs, 0, dot_with_gt, axis=1)\n",
    "    query_rankings = list()\n",
    "    largest_k_list = list()\n",
    "    for row in final_ranking_scores:\n",
    "        ranking_ind = np.argsort(row) # sorts row in increasing order of similarity score\n",
    "        num_scores = len(ranking_ind)\n",
    "        query_rankings.append(num_scores-list(ranking_ind).index(0))\n",
    "        largest_k_list.append(np.array(ranking_ind[-largest_k:]).astype(int))\n",
    "    return query_rankings, largest_k_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note: We evaluate the learned embeddings on chunks of test sentences-document pairs to save run-time memory; this is to make sure that our code works on the smallest notebook instance *ml.t2.medium*. If you have a larger notebook instance, you can increase the chunk_size to speed up evaluation. For instances larger than ml.t2.xlarge, you can set chunk_size = num_test_samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on the 0-th chunk\n",
      "Evaluating on the 1000-th chunk\n",
      "Evaluating on the 2000-th chunk\n",
      "Evaluating on the 3000-th chunk\n",
      "Evaluating on the 4000-th chunk\n",
      "Evaluating on the 5000-th chunk\n",
      "Evaluating on the 6000-th chunk\n",
      "Evaluating on the 7000-th chunk\n",
      "Evaluating on the 8000-th chunk\n",
      "Evaluating on the 9000-th chunk\n",
      "Summary:\n",
      "Mean query ranks is 255.3926\n",
      "Percentiles of query ranks is 50%:14.0, 80%:194.0, 90%:675.1000000000004, 99%:4018.880000000019\n",
      "The hits at 1 score is 2602/10000\n",
      "The hits at 5 score is 4096/10000\n",
      "The hits at 10 score is 4723/10000\n",
      "The hits at 20 score is 5411/10000\n",
      "The hits at 50 score is 6414/10000\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 1000\n",
    "num_test_samples = len(sent_embs)\n",
    "assert num_test_samples%chunk_size == 0, \"Chunk_size must be divisible by {}\".format(num_test_samples)\n",
    "num_chunks = int(num_test_samples / chunk_size)\n",
    "k_list = [1, 5, 10, 20, 50]\n",
    "largest_k = max(k_list)\n",
    "query_all_rankings = list()\n",
    "all_largest_k_list = list()\n",
    "\n",
    "for i in range(0, num_chunks*chunk_size, chunk_size):\n",
    "    print(\"Evaluating on the {}-th chunk\".format(i))\n",
    "    j = i+chunk_size\n",
    "    sent_emb_submat = sent_emb_mat[i:j, :]\n",
    "    gt_emb_submat = gt_emb_mat[:, i:j]\n",
    "    query_rankings, largest_k_list = get_chunk_query_rank(sent_emb_submat, basedocs_emb_mat, gt_emb_submat, largest_k)\n",
    "    query_all_rankings += query_rankings\n",
    "    all_largest_k_list.append(np.array(largest_k_list).astype(int))\n",
    "\n",
    "all_largest_k_mat = np.concatenate(all_largest_k_list, axis=0).astype(int)\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(\"Mean query ranks is {}\".format(np.mean(query_all_rankings)))\n",
    "print(\"Percentiles of query ranks is 50%:{}, 80%:{}, 90%:{}, 99%:{}\".format(*np.percentile(query_all_rankings, [50, 80, 90, 99])))\n",
    "\n",
    "for k in k_list:\n",
    "    top_k_mat = all_largest_k_mat[:, -k:]\n",
    "    unique, counts = np.unique(top_k_mat, return_counts=True)\n",
    "    print(\"The hits at {} score is {}/{}\".format(k, counts[0], len(top_k_mat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with the StarSpace algorithm \n",
    "\n",
    "We compare the performance of Object2Vec with the StarSpace (https://github.com/facebookresearch/StarSpace) algorithm on the document retrieval evaluation task, using a set of 250 thousand Wikipedia documents. The experimental results displayed in the table below, show that Object2Vec significantly outperforms StarSpace on all metrics although both models use the same kind of encoders for sentences and documents.\n",
    "\n",
    "\n",
    "| Algorithm      | hits@1       | hits@10      | hits@20      |  mean rank  |\n",
    "| :------------- | :----------: | :-----------:| :----------: | ----------: |\n",
    "|  StarSpace     | 21.98%       | 42.77%       | 50.55%       |  303.34     |\n",
    "|  Object2Vec    | 26.40%       | 47.42%       | 53.83%       |  248.67     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
