{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to the Amazon SageMaker IP Insights Algorithm\n",
    "#### Unsupervised anomaly detection for susicipous IP addresses\n",
    "-------\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setup](#Setup)\n",
    "3. [Training](#Training)\n",
    "4. [Inference](#Inference)\n",
    "5. [Epilogue](#Epilogue)\n",
    "\n",
    "## Introduction\n",
    "-------\n",
    "\n",
    "The Amazon SageMaker IP Insights algorithm uses statistical modeling and neural networks to capture associations between online resources (such as account IDs or hostnames) and IPv4 addresses. Under the hood, it learns vector representations for online resources and IP addresses. This essentially means that if the vector representing an IP address and an online resource are close together, then it is likey for that IP address to access that online resource, even if it has never accessed it before.\n",
    "\n",
    "In this notebook, we use the Amazon SageMaker IP Insights algorithm to train a model on synthetic data. We then use this model to perform inference on the data and show how to discover anomalies. After running this notebook, you should be able to:\n",
    "\n",
    "- obtain, transform, and store data for use in Amazon SageMaker,\n",
    "- create an AWS SageMaker training job to produce an IP Insights model,\n",
    "- use the model to perform inference with an Amazon SageMaker endpoint.\n",
    "\n",
    "If you would like to know more, please check out the [SageMaker IP Inisghts Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights.html). \n",
    "\n",
    "## Setup\n",
    "------\n",
    "*This notebook was created and tested on a ml.m4.xlarge notebook instance.*\n",
    "\n",
    "Our first step is to setup our AWS credentials so that AWS SageMaker can store and access training data and model artifacts.\n",
    "\n",
    "### Select Amazon S3 Bucket\n",
    "We first need to specify the locations where we will store our training data and trained model artifacts. ***This is the only cell of this notebook that you will need to edit.*** In particular, we need the following data:\n",
    "\n",
    "- `bucket` - An S3 bucket accessible by this account.\n",
    "- `prefix` - The location in the bucket where this notebook's input and output data will be stored. (The default value is sufficient.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input/output will be stored in: s3://fab-sagemaker/ipinsights-weblogs\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import os\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "#bucket = sagemaker.Session().default_bucket()\n",
    "bucket = 'fab-sagemaker'\n",
    "\n",
    "prefix = 'ipinsights-weblogs'\n",
    "execution_role = sagemaker.get_execution_role()\n",
    "\n",
    "\n",
    "# check if the bucket exists\n",
    "try:\n",
    "    boto3.Session().client('s3').head_bucket(Bucket=bucket)\n",
    "except botocore.exceptions.ParamValidationError as e:\n",
    "    print('Hey! You either forgot to specify your S3 bucket'\n",
    "          ' or you gave your bucket an invalid name!')\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == '403':\n",
    "        print(\"Hey! You don't have permission to access the bucket, {}.\".format(bucket))\n",
    "    elif e.response['Error']['Code'] == '404':\n",
    "        print(\"Hey! Your bucket, {}, doesn't exist!\".format(bucket))\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    print('Training input/output will be stored in: s3://{}/{}'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Apache Web Server (\"httpd\") is the most popular web server used on the internet. And luckily for us, it logs all requests processed by the server - by default. If a web page requires HTTP authentication, the Apache Web Server will log the IP address and authenticated user name for each requested resource. \n",
    "\n",
    "The [access logs](https://httpd.apache.org/docs/2.4/logs.html) are typically on the server under the file `/var/log/httpd/access_log`. From the example log output below, we see which IP addresses each user has connected with:\n",
    "\n",
    "```\n",
    "192.168.1.100 - user1 [15/Oct/2018:18:58:32 +0000] \"GET /login_success?userId=1 HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\"\n",
    "192.168.1.102 - user2 [15/Oct/2018:18:58:35 +0000] \"GET /login_success?userId=2 HTTP/1.1\" 200 - \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\"\n",
    "...\n",
    "```\n",
    "\n",
    "If we want to train an algorithm to detect suspicious activity, this dataset is ideal for SageMaker IP Insights.\n",
    "\n",
    "First, we determine the resource we want to be analyzing (such as a login page or access to a protected file). Then, we construct a dataset containing the history of all past user interactions with the resource. We extract out each 'access event' from the log and store the corresponding user name and IP address in a headerless CSV file with two columns. The first column will contain the user identifier string, and the second will contain the IPv4 address in decimal-dot notation. \n",
    "\n",
    "```\n",
    "user1, 192.168.1.100\n",
    "user2, 193.168.1.102\n",
    "...\n",
    "```\n",
    "\n",
    "As a side note, the dataset should include all access events. That means some `<user_name, ip_address>` pairs will be repeated. \n",
    "\n",
    "#### User Activity Simulation\n",
    "For this example, we are going to simulate our own web-traffic logs. We mock up a toy website example and simulate users logging into the website from mobile devices. \n",
    "\n",
    "The details of the simulation are explained in the script [here](./generate_data.py). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (4.44.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install dependency\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ASN List: 827696 ASNs.\n",
      "Starting User Activity Simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:14<00:00, 44.16users/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished simulating web activity for 10000 users.\n",
      "103.85.159.252 - user_63 [12/Nov/2018:00:32:42 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\r\n",
      "105.228.248.57 - user_63 [10/Nov/2018:15:30:42 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\r\n",
      "160.131.35.145 - user_63 [07/Nov/2018:08:43:49 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\r\n",
      "103.201.130.236 - user_63 [06/Nov/2018:07:36:22 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\r\n",
      "105.228.238.150 - user_63 [10/Nov/2018:14:58:54 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\r\n",
      "103.200.216.101 - user_63 [13/Nov/2018:07:44:59 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\r\n",
      "103.200.197.165 - user_63 [08/Nov/2018:05:54:37 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\r\n",
      "105.228.221.27 - user_63 [07/Nov/2018:15:51:57 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\r\n",
      "105.228.236.45 - user_63 [09/Nov/2018:03:15:52 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\r\n",
      "105.228.245.249 - user_63 [04/Nov/2018:02:52:14 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\r\n"
     ]
    }
   ],
   "source": [
    "from generate_data import generate_dataset\n",
    "\n",
    "# We simulate traffic for 10,000 users. This should yield about 3 million log lines (~700 MB). \n",
    "NUM_USERS = 10000\n",
    "log_file = 'ipinsights_web_traffic.log'\n",
    "generate_dataset(NUM_USERS, log_file)\n",
    "\n",
    "# Visualize a few log lines\n",
    "!head $log_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset\n",
    "Now that we have our logs, we need to transform them into a format that IP Insights can use. As we mentioned above, we need to:\n",
    "1. Choose the resource which we want to analyze users' history for\n",
    "2. Extract our users' usage history of IP addresses\n",
    "3. In addition, we want to separate our dataset into a training and test set. This will allow us to check for overfitting by evaluating our model on 'unseen' login events.\n",
    "\n",
    "For the rest of the notebook, we assume that the Apache Access Logs are in the Common Log Format as defined by the [Apache documentation](https://httpd.apache.org/docs/2.4/logs.html#accesslog). We start with reading the logs into a Pandas DataFrame for easy data exploration and pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_address</th>\n",
       "      <th>rcf_id</th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>request</th>\n",
       "      <th>status</th>\n",
       "      <th>size</th>\n",
       "      <th>referer</th>\n",
       "      <th>user_agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.85.159.252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user_63</td>\n",
       "      <td>[12/Nov/2018:00:32:42</td>\n",
       "      <td>+0000]</td>\n",
       "      <td>GET /login_success HTTP/1.1</td>\n",
       "      <td>200</td>\n",
       "      <td>476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.228.248.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user_63</td>\n",
       "      <td>[10/Nov/2018:15:30:42</td>\n",
       "      <td>+0000]</td>\n",
       "      <td>GET /login_success HTTP/1.1</td>\n",
       "      <td>200</td>\n",
       "      <td>476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160.131.35.145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user_63</td>\n",
       "      <td>[07/Nov/2018:08:43:49</td>\n",
       "      <td>+0000]</td>\n",
       "      <td>GET /login_success HTTP/1.1</td>\n",
       "      <td>200</td>\n",
       "      <td>476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.201.130.236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user_63</td>\n",
       "      <td>[06/Nov/2018:07:36:22</td>\n",
       "      <td>+0000]</td>\n",
       "      <td>GET /login_success HTTP/1.1</td>\n",
       "      <td>200</td>\n",
       "      <td>476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105.228.238.150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user_63</td>\n",
       "      <td>[10/Nov/2018:14:58:54</td>\n",
       "      <td>+0000]</td>\n",
       "      <td>GET /login_success HTTP/1.1</td>\n",
       "      <td>200</td>\n",
       "      <td>476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ip_address  rcf_id     user              timestamp time_zone  \\\n",
       "0   103.85.159.252     NaN  user_63  [12/Nov/2018:00:32:42    +0000]   \n",
       "1   105.228.248.57     NaN  user_63  [10/Nov/2018:15:30:42    +0000]   \n",
       "2   160.131.35.145     NaN  user_63  [07/Nov/2018:08:43:49    +0000]   \n",
       "3  103.201.130.236     NaN  user_63  [06/Nov/2018:07:36:22    +0000]   \n",
       "4  105.228.238.150     NaN  user_63  [10/Nov/2018:14:58:54    +0000]   \n",
       "\n",
       "                       request  status  size  referer  \\\n",
       "0  GET /login_success HTTP/1.1     200   476      NaN   \n",
       "1  GET /login_success HTTP/1.1     200   476      NaN   \n",
       "2  GET /login_success HTTP/1.1     200   476      NaN   \n",
       "3  GET /login_success HTTP/1.1     200   476      NaN   \n",
       "4  GET /login_success HTTP/1.1     200   476      NaN   \n",
       "\n",
       "                                          user_agent  \n",
       "0  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...  \n",
       "1  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...  \n",
       "2  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...  \n",
       "3  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...  \n",
       "4  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    log_file,\n",
    "    sep=\" \",\n",
    "    na_values='-',\n",
    "    header=None,\n",
    "    names=['ip_address','rcf_id','user','timestamp','time_zone','request', 'status', 'size', 'referer', 'user_agent']\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the log timestamp strings into Python datetimes so that we can sort and compare the data more easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time stamps to DateTime objects\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format='[%d/%b/%Y:%H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also verify the time zones of all of the time stamps. If the log contains more than one time zone, we would need to standardize the timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if they are all in the same timezone\n",
    "num_time_zones = len(df['time_zone'].unique())\n",
    "num_time_zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, there is only one value in the entire `time_zone` column. Therefore, all of the timestamps are in the same time zone, and we do not need to standardize them. We can skip the next cell and go to [1. Selecting a Resource](#1.-Select-Resource).\n",
    "\n",
    "If there is more than one time_zone in your dataset, then we parse the timezone offset and update the corresponding datetime object. \n",
    "\n",
    "**Note:** The next cell takes about 5-10 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "\n",
    "def apply_timezone(row):\n",
    "    tz = row[1]\n",
    "    tz_offset = int(tz[:3]) * 60   # Hour offset\n",
    "    tz_offset += int(tz[3:5])      # Minutes offset\n",
    "    return row[0].replace(tzinfo=pytz.FixedOffset(tz_offset))\n",
    "\n",
    "if num_time_zones > 1:\n",
    "    df['timestamp'] = df[['timestamp','time_zone']].apply(apply_timezone, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Select Resource\n",
    "Our goal is to train an IP Insights algorithm to analyze the history of user logins such that we can predict how suspicious a login event is. \n",
    "\n",
    "In our simulated web server, the server logs a `GET` request to the `/login_success` page everytime a user successfully logs in. We filter our Apache logs for `GET` requests for `/login_success`. We also filter for requests that have a `status_code == 200`, to ensure that the page request was well formed. \n",
    "\n",
    "**Note:** every web server handles logins differently. For your dataset, determine which resource you will need to be analyzing to correctly frame this problem. Depending on your usecase, you may need to do more data exploration and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['request'].str.startswith('GET /login_success')) & (df['status'] == 200)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extract Users and IP address\n",
    "Now that our DataFrame only includes log events for the resource we want to analyze, we extract the relevant fields to construct a IP Insights dataset.\n",
    "\n",
    "IP Insights takes in a headerless CSV file with two columns: an entity (username) ID string and the IPv4 address in decimal-dot notation. Fortunately, the Apache Web Server Access Logs output IP addresses and authentcated usernames in their own columns.\n",
    "\n",
    "**Note:** Each website handles user authentication differently. If the Access Log does not output an authenticated user, you could explore the website's query strings or work with your website developers on another solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['user', 'ip_address', 'timestamp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create training and test dataset\n",
    "As part of training a model, we want to evaluate how it generalizes to data it has never seen before.\n",
    "\n",
    "Typically, you create a test set by reserving a random percentage of your dataset and evaluating the model after training. However, for machine learning models that make future predictions on historical data, we want to use out-of-time testing. Instead of randomly sampling our dataset, we split our dataset into two contiguous time windows. The first window is the training set, and the second is the test set. \n",
    "\n",
    "We first look at the time range of our dataset to select a date to use as the partition between the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                 3117304\n",
       "unique                 840633\n",
       "top       2018-11-09 01:35:36\n",
       "freq                       16\n",
       "first     2018-11-04 00:00:01\n",
       "last      2018-11-14 00:00:00\n",
       "Name: timestamp, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['timestamp'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have login events for 10 days. Let's take the first week (7 days) of data as training and then use the last 3 days for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_partition = datetime(2018, 11, 11, tzinfo=pytz.FixedOffset(0)) if num_time_zones > 1 else datetime(2018, 11, 11)\n",
    "\n",
    "train_df = df[df['timestamp'] <= time_partition]\n",
    "test_df = df[df['timestamp'] > time_partition]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training dataset, we shuffle it. \n",
    "\n",
    "Shuffling improves the model's performance since SageMaker IP Insights uses stochastic gradient descent. This ensures that login events for the same user are less likely to occur in the same mini batch. This allows the model to improve its performance in between predictions of the same user, which will improve training convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>974619</th>\n",
       "      <td>user_3176</td>\n",
       "      <td>209.120.195.250</td>\n",
       "      <td>2018-11-08 05:46:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23261</th>\n",
       "      <td>user_199</td>\n",
       "      <td>185.195.145.72</td>\n",
       "      <td>2018-11-06 01:57:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604606</th>\n",
       "      <td>user_8344</td>\n",
       "      <td>216.70.182.251</td>\n",
       "      <td>2018-11-08 14:23:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60886</th>\n",
       "      <td>user_45</td>\n",
       "      <td>192.58.239.33</td>\n",
       "      <td>2018-11-10 13:01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348885</th>\n",
       "      <td>user_7659</td>\n",
       "      <td>65.6.220.131</td>\n",
       "      <td>2018-11-10 23:45:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user       ip_address           timestamp\n",
       "974619   user_3176  209.120.195.250 2018-11-08 05:46:27\n",
       "23261     user_199   185.195.145.72 2018-11-06 01:57:40\n",
       "2604606  user_8344   216.70.182.251 2018-11-08 14:23:59\n",
       "60886      user_45    192.58.239.33 2018-11-10 13:01:15\n",
       "2348885  user_7659     65.6.220.131 2018-11-10 23:45:07"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle train data \n",
    "train_df = train_df.sample(frac=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Data on S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have simulated (or scraped) our datasets, we have to prepare and upload it to S3.\n",
    "\n",
    "We will be doing local inference, therefore we don't need to upload our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output dataset as headerless CSV \n",
    "train_data = train_df.to_csv(index=False, header=False, columns=['user', 'ip_address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data to: s3://fab-sagemaker/ipinsights-weblogs/train/train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# Upload data to S3 key\n",
    "train_data_file = 'train.csv'\n",
    "key = os.path.join(prefix, 'train', train_data_file)\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, key)\n",
    "\n",
    "print('Uploading data to: {}'.format(s3_train_data))\n",
    "boto3.resource('s3').Bucket(bucket).Object(key).put(Body=train_data)\n",
    "\n",
    "# Configure SageMaker IP Insights Input Channels\n",
    "input_data = {\n",
    "    'train': sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', content_type='text/csv')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "---\n",
    "Once the data is preprocessed and available in the necessary format, the next step is to train our model on the data. There are number of parameters required by the SageMaker IP Insights algorithm to configure the model and define the computational environment in which training will take place. The first of these is to point to a container image which holds the algorithms training and hosting code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "image = get_image_uri(boto3.Session().region_name, 'ipinsights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to determine the training cluster to use. The IP Insights algorithm supports both CPU and GPU training. We recommend using GPU machines as they will train faster. However, when the size of your dataset increases, it can become more economical to use multiple CPU machines running with distributed training. See [Recommended Instance Types](https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights.html#ip-insights-instances) for more details. \n",
    "\n",
    "### Training Job Configuration\n",
    "- **train_instance_type**: the instance type to train on. We recommend `p3.2xlarge` for single GPU, `p3.8xlarge` for multi-GPU, and `m5.2xlarge` if using distributed training with CPU;\n",
    "- **train_instance_count**: the number of worker nodes in the training cluster.\n",
    "\n",
    "We need to also configure SageMaker IP Insights-specific hypeparameters:\n",
    "\n",
    "### Model Hyperparameters\n",
    "- **num_entity_vectors**: the total number of embeddings to train. We use an internal hashing mechanism to map the entity ID strings to an embedding index; therefore, using an embedding size larger than the total number of possible values helps reduce the number of hash collisions. We recommend this value to be 2x the total number of unique entites (i.e. user names) in your dataset;\n",
    "- **vector_dim**: the size of the entity and IP embedding vectors. The larger the value, the more information can be encoded using these representations but using too large vector representations may cause the model to overfit, especially for small training data sets;\n",
    "- **num_ip_encoder_layers**: the number of layers in the IP encoder network. The larger the number of layers, the higher the model capacity to capture patterns among IP addresses. However, large number of layers increases the chance of overfitting. `num_ip_encoder_layers=1` is a good value to start experimenting with;\n",
    "- **random_negative_sampling_rate**: the number of randomly generated negative samples to produce per 1 positive sample; `random_negative_sampling_rate=1` is a good value to start experimenting with;\n",
    "    - Random negative samples are produced by drawing each octet from a uniform distributed of [0, 255];\n",
    "- **shuffled_negative_sampling_rate**: the number of shuffled negative samples to produce per 1 positive sample; `shuffled_negative_sampling_rate=1` is a good value to start experimenting with;\n",
    "    - Shuffled negative samples are produced by shuffling the accounts within a batch;\n",
    "\n",
    "### Training Hyperparameters\n",
    "- **epochs**: the number of epochs to train. Increase this value if you continue to see the accuracy and cross entropy improving over the last few epochs;\n",
    "- **mini_batch_size**: how many examples in each mini_batch. A smaller number improves convergence with stochastic gradient descent. But a larger number is necessary if using shuffled_negative_sampling to avoid sampling a wrong account for a negative sample;\n",
    "- **learning_rate**: the learning rate for the Adam optimizer (try ranges in [0.001, 0.1]). Too large learning rate may cause the model to diverge since the training would be likely to overshoot minima. On the other hand, too small learning rate slows down the convergence;\n",
    "- **weight_decay**: L2 regularization coefficient. Regularization is required to prevent the model from overfitting the training data. Too large of a value will prevent the model from learning anything;\n",
    "\n",
    "For more details, see [Amazon SageMaker IP Insights (Hyperparameters)](https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights-hyperparameters.html). Additionally, most of these hyperparameters can be found using SageMaker Automatic Model Tuning; see [Amazon SageMaker IP Insights (Model Tuning)](https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights-tuning.html) for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 13:56:19 Starting - Starting the training job...\n",
      "2020-10-03 13:56:25 Starting - Launching requested ML instances......\n",
      "2020-10-03 13:57:45 Starting - Preparing the instances for training......\n",
      "2020-10-03 13:58:38 Downloading - Downloading input data\n",
      "2020-10-03 13:58:38 Training - Downloading the training image.......\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[10/03/2020 13:59:54 INFO 140573196957504] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'random_negative_sampling_rate': u'1', u'shuffled_negative_sampling_rate': u'1', u'batch_metrics_publish_interval': u'1000', u'num_entity_vectors': u'100000', u'_tuning_objective_metric': u'', u'vector_dim': u'128', u'learning_rate': u'0.001', u'epochs': u'10', u'_num_gpus': u'auto', u'weight_decay': u'0.00001', u'_kvstore': u'auto_gpu', u'_num_kv_servers': u'auto', u'mini_batch_size': u'5000', u'_log_level': u'info', u'num_ip_encoder_layers': u'1'}\u001b[0m\n",
      "\u001b[34m[10/03/2020 13:59:54 INFO 140573196957504] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'random_negative_sampling_rate': u'5', u'num_entity_vectors': u'20000', u'vector_dim': u'128', u'learning_rate': u'0.01', u'epochs': u'5', u'mini_batch_size': u'1000'}\u001b[0m\n",
      "\u001b[34m[10/03/2020 13:59:54 INFO 140573196957504] Final configuration: {u'random_negative_sampling_rate': u'5', u'shuffled_negative_sampling_rate': u'1', u'batch_metrics_publish_interval': u'1000', u'num_entity_vectors': u'20000', u'_tuning_objective_metric': u'', u'vector_dim': u'128', u'learning_rate': u'0.01', u'epochs': u'5', u'_num_gpus': u'auto', u'weight_decay': u'0.00001', u'_kvstore': u'auto_gpu', u'_num_kv_servers': u'auto', u'mini_batch_size': u'1000', u'_log_level': u'info', u'num_ip_encoder_layers': u'1'}\u001b[0m\n",
      "\u001b[34m[10/03/2020 13:59:54 WARNING 140573196957504] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[10/03/2020 13:59:54 INFO 140573196957504] nvidia-smi took: 0.0503299236298 secs to identify 1 gpus\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[10/03/2020 13:59:54 INFO 140573196957504] Using default worker.\u001b[0m\n",
      "\u001b[34m[10/03/2020 13:59:54 INFO 140573196957504] Loaded iterator creator application/x-ndarray for content type ('application/x-ndarray', '1.0')\u001b[0m\n",
      "\u001b[34m[10/03/2020 13:59:54 INFO 140573196957504] Loaded iterator creator text/csv for content type ('text/csv', '1.0')\u001b[0m\n",
      "\u001b[34m[10/03/2020 13:59:54 INFO 140573196957504] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 17.747879028320312, \"sum\": 17.747879028320312, \"min\": 17.747879028320312}}, \"EndTime\": 1601733594.28966, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601733594.271723}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1601733594.289841, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601733594.289799}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 13:59:54 INFO 140573196957504] Create Store: device\u001b[0m\n",
      "\u001b[34m[13:59:59] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_10.1.x.1334.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[13:59:59] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_10.1.x.1334.0/AL2012/generic-flavor/src/src/operator/././../common/utils.h:450: Optimizer with lazy_update = True detected. Be aware that lazy update with row_sparse gradient is different from standard update, and may lead to different empirical results. See https://mxnet.incubator.apache.org/api/python/optimization/optimization.html for more details.\u001b[0m\n",
      "\u001b[34m[10/03/2020 13:59:59 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_accuracy <score>=0.523\u001b[0m\n",
      "\u001b[34m[10/03/2020 13:59:59 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_cross_entropy <loss>=0.69298425293\u001b[0m\n",
      "\n",
      "2020-10-03 13:59:51 Training - Training image download completed. Training in progress.\u001b[34m[10/03/2020 14:00:05 INFO 140573196957504] Epoch[0] Batch [1000]#011Speed: 164091.87 samples/sec#011binary_classification_accuracy=0.927252#011binary_classification_cross_entropy=0.198613\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:05 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=1000 train binary_classification_accuracy <score>=0.927251748252\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:05 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=1000 train binary_classification_cross_entropy <loss>=0.198612849431\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:11 INFO 140573196957504] Epoch[0] Batch [2000]#011Speed: 171210.77 samples/sec#011binary_classification_accuracy=0.949572#011binary_classification_cross_entropy=0.148278\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:11 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=2000 train binary_classification_accuracy <score>=0.949571714143\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:11 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=2000 train binary_classification_cross_entropy <loss>=0.148278471875\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:16 INFO 140573196957504] Epoch[0] Batch [3000]#011Speed: 172053.28 samples/sec#011binary_classification_accuracy=0.959132#011binary_classification_cross_entropy=0.125998\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:16 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=3000 train binary_classification_accuracy <score>=0.959131956015\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:16 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=3000 train binary_classification_cross_entropy <loss>=0.125997822492\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:22 INFO 140573196957504] Epoch[0] Batch [4000]#011Speed: 171324.76 samples/sec#011binary_classification_accuracy=0.964601#011binary_classification_cross_entropy=0.112942\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:22 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=4000 train binary_classification_accuracy <score>=0.964601099725\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:22 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=4000 train binary_classification_cross_entropy <loss>=0.11294210328\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:28 INFO 140573196957504] Epoch[0] Batch [5000]#011Speed: 172476.03 samples/sec#011binary_classification_accuracy=0.968162#011binary_classification_cross_entropy=0.104427\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:28 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=5000 train binary_classification_accuracy <score>=0.968161767646\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:28 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=5000 train binary_classification_cross_entropy <loss>=0.104426789204\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:34 INFO 140573196957504] Epoch[0] Batch [6000]#011Speed: 171911.25 samples/sec#011binary_classification_accuracy=0.970707#011binary_classification_cross_entropy=0.098333\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:34 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=6000 train binary_classification_accuracy <score>=0.970707215464\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:34 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=6000 train binary_classification_cross_entropy <loss>=0.0983330217637\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:40 INFO 140573196957504] Epoch[0] Batch [7000]#011Speed: 171396.06 samples/sec#011binary_classification_accuracy=0.972631#011binary_classification_cross_entropy=0.093702\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:40 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=7000 train binary_classification_accuracy <score>=0.972630624197\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:40 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=7000 train binary_classification_cross_entropy <loss>=0.0937021601028\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:45 INFO 140573196957504] Epoch[0] Batch [8000]#011Speed: 171775.38 samples/sec#011binary_classification_accuracy=0.974109#011binary_classification_cross_entropy=0.090067\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:45 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=8000 train binary_classification_accuracy <score>=0.97410936133\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:45 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=8000 train binary_classification_cross_entropy <loss>=0.0900667861919\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:51 INFO 140573196957504] Epoch[0] Batch [9000]#011Speed: 170536.13 samples/sec#011binary_classification_accuracy=0.975322#011binary_classification_cross_entropy=0.087110\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:51 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=9000 train binary_classification_accuracy <score>=0.975321964226\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:51 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=9000 train binary_classification_cross_entropy <loss>=0.0871101724167\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:57 INFO 140573196957504] Epoch[0] Batch [10000]#011Speed: 169632.67 samples/sec#011binary_classification_accuracy=0.976336#011binary_classification_cross_entropy=0.084602\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:57 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=10000 train binary_classification_accuracy <score>=0.976335866413\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:00:57 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=10000 train binary_classification_cross_entropy <loss>=0.0846015859437\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:03 INFO 140573196957504] Epoch[0] Batch [11000]#011Speed: 170075.23 samples/sec#011binary_classification_accuracy=0.977176#011binary_classification_cross_entropy=0.082526\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:03 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=11000 train binary_classification_accuracy <score>=0.977175529497\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:03 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=11000 train binary_classification_cross_entropy <loss>=0.0825258931173\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:09 INFO 140573196957504] Epoch[0] Batch [12000]#011Speed: 168967.95 samples/sec#011binary_classification_accuracy=0.977883#011binary_classification_cross_entropy=0.080755\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:09 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=12000 train binary_classification_accuracy <score>=0.977883093076\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:09 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=12000 train binary_classification_cross_entropy <loss>=0.0807552916843\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:15 INFO 140573196957504] Epoch[0] Batch [13000]#011Speed: 170213.58 samples/sec#011binary_classification_accuracy=0.978488#011binary_classification_cross_entropy=0.079330\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:15 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=13000 train binary_classification_accuracy <score>=0.978487885547\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:15 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=13000 train binary_classification_cross_entropy <loss>=0.0793297830327\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:21 INFO 140573196957504] Epoch[0] Batch [14000]#011Speed: 169591.84 samples/sec#011binary_classification_accuracy=0.979016#011binary_classification_cross_entropy=0.078033\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:21 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=14000 train binary_classification_accuracy <score>=0.97901564174\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:21 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=14000 train binary_classification_cross_entropy <loss>=0.0780329943085\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:27 INFO 140573196957504] Epoch[0] Batch [15000]#011Speed: 170522.61 samples/sec#011binary_classification_accuracy=0.979500#011binary_classification_cross_entropy=0.076847\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:27 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=15000 train binary_classification_accuracy <score>=0.979499966669\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:27 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, batch=15000 train binary_classification_cross_entropy <loss>=0.076847064704\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:28 INFO 140573196957504] Epoch[0] Train-binary_classification_accuracy=0.979622\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:28 INFO 140573196957504] Epoch[0] Train-binary_classification_cross_entropy=0.076563\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:28 INFO 140573196957504] Epoch[0] Time cost=89.758\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:28 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, train binary_classification_accuracy <score>=0.979622014266\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:28 INFO 140573196957504] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy <loss>=0.0765632270063\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}, \"update.time\": {\"count\": 1, \"max\": 94504.92405891418, \"sum\": 94504.92405891418, \"min\": 94504.92405891418}}, \"EndTime\": 1601733688.794935, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601733594.28974}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:28 INFO 140573196957504] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15281, \"sum\": 15281.0, \"min\": 15281}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 15281, \"sum\": 15281.0, \"min\": 15281}, \"Total Records Seen\": {\"count\": 1, \"max\": 15279383, \"sum\": 15279383.0, \"min\": 15279383}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 15279383, \"sum\": 15279383.0, \"min\": 15279383}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1601733688.795184, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\", \"epoch\": 0}, \"StartTime\": 1601733594.289982}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:28 INFO 140573196957504] #throughput_metric: host=algo-1, train throughput=161677.487362 records/second\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:28 WARNING 140573196957504] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/mxnet/module/base_module.py:502: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:28 WARNING 140573196957504] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:28 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_accuracy <score>=0.984\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:28 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_cross_entropy <loss>=0.0742186737061\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:34 INFO 140573196957504] Epoch[1] Batch [1000]#011Speed: 169816.07 samples/sec#011binary_classification_accuracy=0.986343#011binary_classification_cross_entropy=0.058551\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:34 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=1000 train binary_classification_accuracy <score>=0.986342657343\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:34 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=1000 train binary_classification_cross_entropy <loss>=0.0585513433367\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:40 INFO 140573196957504] Epoch[1] Batch [2000]#011Speed: 169083.80 samples/sec#011binary_classification_accuracy=0.986426#011binary_classification_cross_entropy=0.057888\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:40 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=2000 train binary_classification_accuracy <score>=0.986426286857\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:40 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=2000 train binary_classification_cross_entropy <loss>=0.0578876003673\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:46 INFO 140573196957504] Epoch[1] Batch [3000]#011Speed: 170314.12 samples/sec#011binary_classification_accuracy=0.986415#011binary_classification_cross_entropy=0.057855\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:46 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=3000 train binary_classification_accuracy <score>=0.986415194935\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:46 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=3000 train binary_classification_cross_entropy <loss>=0.0578551869353\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:52 INFO 140573196957504] Epoch[1] Batch [4000]#011Speed: 169681.97 samples/sec#011binary_classification_accuracy=0.986439#011binary_classification_cross_entropy=0.057701\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:52 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=4000 train binary_classification_accuracy <score>=0.98643864034\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:52 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=4000 train binary_classification_cross_entropy <loss>=0.0577007701166\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:58 INFO 140573196957504] Epoch[1] Batch [5000]#011Speed: 170727.27 samples/sec#011binary_classification_accuracy=0.986463#011binary_classification_cross_entropy=0.057640\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:58 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=5000 train binary_classification_accuracy <score>=0.986462707459\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:01:58 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=5000 train binary_classification_cross_entropy <loss>=0.0576398292516\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:04 INFO 140573196957504] Epoch[1] Batch [6000]#011Speed: 171021.88 samples/sec#011binary_classification_accuracy=0.986455#011binary_classification_cross_entropy=0.057635\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:04 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=6000 train binary_classification_accuracy <score>=0.986455257457\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:04 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=6000 train binary_classification_cross_entropy <loss>=0.0576346708713\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:09 INFO 140573196957504] Epoch[1] Batch [7000]#011Speed: 170385.21 samples/sec#011binary_classification_accuracy=0.986496#011binary_classification_cross_entropy=0.057579\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:09 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=7000 train binary_classification_accuracy <score>=0.98649607199\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:09 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=7000 train binary_classification_cross_entropy <loss>=0.0575788445916\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:15 INFO 140573196957504] Epoch[1] Batch [8000]#011Speed: 169807.80 samples/sec#011binary_classification_accuracy=0.986527#011binary_classification_cross_entropy=0.057452\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:15 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=8000 train binary_classification_accuracy <score>=0.98652655918\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:15 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=8000 train binary_classification_cross_entropy <loss>=0.0574522131412\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:21 INFO 140573196957504] Epoch[1] Batch [9000]#011Speed: 169929.28 samples/sec#011binary_classification_accuracy=0.986538#011binary_classification_cross_entropy=0.057393\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:21 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=9000 train binary_classification_accuracy <score>=0.98653782913\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:21 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=9000 train binary_classification_cross_entropy <loss>=0.0573931106205\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:27 INFO 140573196957504] Epoch[1] Batch [10000]#011Speed: 170277.46 samples/sec#011binary_classification_accuracy=0.986564#011binary_classification_cross_entropy=0.057317\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:27 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=10000 train binary_classification_accuracy <score>=0.986563943606\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:27 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=10000 train binary_classification_cross_entropy <loss>=0.0573170514856\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:33 INFO 140573196957504] Epoch[1] Batch [11000]#011Speed: 170882.27 samples/sec#011binary_classification_accuracy=0.986589#011binary_classification_cross_entropy=0.057237\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:33 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=11000 train binary_classification_accuracy <score>=0.986589400964\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:33 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=11000 train binary_classification_cross_entropy <loss>=0.0572366399781\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:39 INFO 140573196957504] Epoch[1] Batch [12000]#011Speed: 169970.04 samples/sec#011binary_classification_accuracy=0.986603#011binary_classification_cross_entropy=0.057175\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:39 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=12000 train binary_classification_accuracy <score>=0.986602699775\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:39 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=12000 train binary_classification_cross_entropy <loss>=0.0571748277438\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:45 INFO 140573196957504] Epoch[1] Batch [13000]#011Speed: 169889.70 samples/sec#011binary_classification_accuracy=0.986614#011binary_classification_cross_entropy=0.057165\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:45 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=13000 train binary_classification_accuracy <score>=0.986614106607\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:45 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=13000 train binary_classification_cross_entropy <loss>=0.0571653934457\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:50 INFO 140573196957504] Epoch[1] Batch [14000]#011Speed: 173240.93 samples/sec#011binary_classification_accuracy=0.986628#011binary_classification_cross_entropy=0.057139\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:50 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=14000 train binary_classification_accuracy <score>=0.986627955146\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:50 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=14000 train binary_classification_cross_entropy <loss>=0.0571394968061\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:56 INFO 140573196957504] Epoch[1] Batch [15000]#011Speed: 172656.32 samples/sec#011binary_classification_accuracy=0.986646#011binary_classification_cross_entropy=0.057091\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:56 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=15000 train binary_classification_accuracy <score>=0.98664635691\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:56 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, batch=15000 train binary_classification_cross_entropy <loss>=0.0570910035377\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:58 INFO 140573196957504] Epoch[1] Train-binary_classification_accuracy=0.986648\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:58 INFO 140573196957504] Epoch[1] Train-binary_classification_cross_entropy=0.057099\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:58 INFO 140573196957504] Epoch[1] Time cost=89.635\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:58 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, train binary_classification_accuracy <score>=0.986648452326\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:58 INFO 140573196957504] #quality_metric: host=algo-1, epoch=1, train binary_classification_cross_entropy <loss>=0.0570991672854\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 89639.60099220276, \"sum\": 89639.60099220276, \"min\": 89639.60099220276}}, \"EndTime\": 1601733778.435118, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601733688.795011}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:58 INFO 140573196957504] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15281, \"sum\": 15281.0, \"min\": 15281}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 30562, \"sum\": 30562.0, \"min\": 30562}, \"Total Records Seen\": {\"count\": 1, \"max\": 30558766, \"sum\": 30558766.0, \"min\": 30558766}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 15279383, \"sum\": 15279383.0, \"min\": 15279383}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1601733778.435428, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\", \"epoch\": 1}, \"StartTime\": 1601733688.795475}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:58 INFO 140573196957504] #throughput_metric: host=algo-1, train throughput=170452.533478 records/second\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:58 WARNING 140573196957504] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:58 WARNING 140573196957504] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:58 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_accuracy <score>=0.98\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:02:58 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_cross_entropy <loss>=0.0755721893311\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:04 INFO 140573196957504] Epoch[2] Batch [1000]#011Speed: 169914.73 samples/sec#011binary_classification_accuracy=0.986956#011binary_classification_cross_entropy=0.055673\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:04 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=1000 train binary_classification_accuracy <score>=0.986956043956\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:04 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=1000 train binary_classification_cross_entropy <loss>=0.0556731531846\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:10 INFO 140573196957504] Epoch[2] Batch [2000]#011Speed: 172076.26 samples/sec#011binary_classification_accuracy=0.986919#011binary_classification_cross_entropy=0.055437\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:10 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=2000 train binary_classification_accuracy <score>=0.98691904048\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:10 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=2000 train binary_classification_cross_entropy <loss>=0.0554371222144\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:16 INFO 140573196957504] Epoch[2] Batch [3000]#011Speed: 170618.92 samples/sec#011binary_classification_accuracy=0.986921#011binary_classification_cross_entropy=0.055367\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:16 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=3000 train binary_classification_accuracy <score>=0.986921359547\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:16 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=3000 train binary_classification_cross_entropy <loss>=0.0553674453855\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:21 INFO 140573196957504] Epoch[2] Batch [4000]#011Speed: 173415.99 samples/sec#011binary_classification_accuracy=0.986900#011binary_classification_cross_entropy=0.055318\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:21 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=4000 train binary_classification_accuracy <score>=0.986899775056\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:21 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=4000 train binary_classification_cross_entropy <loss>=0.0553175802977\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:27 INFO 140573196957504] Epoch[2] Batch [5000]#011Speed: 171377.49 samples/sec#011binary_classification_accuracy=0.986916#011binary_classification_cross_entropy=0.055353\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:27 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=5000 train binary_classification_accuracy <score>=0.986915616877\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:27 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=5000 train binary_classification_cross_entropy <loss>=0.0553527963143\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:33 INFO 140573196957504] Epoch[2] Batch [6000]#011Speed: 169983.07 samples/sec#011binary_classification_accuracy=0.986909#011binary_classification_cross_entropy=0.055399\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:33 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=6000 train binary_classification_accuracy <score>=0.986908681886\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:33 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=6000 train binary_classification_cross_entropy <loss>=0.055398885178\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:39 INFO 140573196957504] Epoch[2] Batch [7000]#011Speed: 170427.69 samples/sec#011binary_classification_accuracy=0.986920#011binary_classification_cross_entropy=0.055372\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:39 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=7000 train binary_classification_accuracy <score>=0.98691986859\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:39 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=7000 train binary_classification_cross_entropy <loss>=0.0553719006595\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:45 INFO 140573196957504] Epoch[2] Batch [8000]#011Speed: 170011.68 samples/sec#011binary_classification_accuracy=0.986940#011binary_classification_cross_entropy=0.055265\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:45 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=8000 train binary_classification_accuracy <score>=0.986939507562\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:45 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=8000 train binary_classification_cross_entropy <loss>=0.0552645178615\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:51 INFO 140573196957504] Epoch[2] Batch [9000]#011Speed: 169433.65 samples/sec#011binary_classification_accuracy=0.986962#011binary_classification_cross_entropy=0.055240\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:51 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=9000 train binary_classification_accuracy <score>=0.986961559827\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:51 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=9000 train binary_classification_cross_entropy <loss>=0.0552402128364\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:57 INFO 140573196957504] Epoch[2] Batch [10000]#011Speed: 170715.79 samples/sec#011binary_classification_accuracy=0.986977#011binary_classification_cross_entropy=0.055221\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:57 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=10000 train binary_classification_accuracy <score>=0.98697740226\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:03:57 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=10000 train binary_classification_cross_entropy <loss>=0.0552213358941\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:02 INFO 140573196957504] Epoch[2] Batch [11000]#011Speed: 170418.25 samples/sec#011binary_classification_accuracy=0.986990#011binary_classification_cross_entropy=0.055166\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:02 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=11000 train binary_classification_accuracy <score>=0.98699009181\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:02 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=11000 train binary_classification_cross_entropy <loss>=0.055166178208\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:08 INFO 140573196957504] Epoch[2] Batch [12000]#011Speed: 170451.11 samples/sec#011binary_classification_accuracy=0.987017#011binary_classification_cross_entropy=0.055098\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:08 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=12000 train binary_classification_accuracy <score>=0.987016831931\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:08 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=12000 train binary_classification_cross_entropy <loss>=0.0550983419286\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:14 INFO 140573196957504] Epoch[2] Batch [13000]#011Speed: 171487.17 samples/sec#011binary_classification_accuracy=0.987011#011binary_classification_cross_entropy=0.055135\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:14 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=13000 train binary_classification_accuracy <score>=0.987011306823\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:14 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=13000 train binary_classification_cross_entropy <loss>=0.0551349814149\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:20 INFO 140573196957504] Epoch[2] Batch [14000]#011Speed: 170715.06 samples/sec#011binary_classification_accuracy=0.987009#011binary_classification_cross_entropy=0.055149\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:20 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=14000 train binary_classification_accuracy <score>=0.987009356475\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:20 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=14000 train binary_classification_cross_entropy <loss>=0.0551486717693\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:26 INFO 140573196957504] Epoch[2] Batch [15000]#011Speed: 170269.51 samples/sec#011binary_classification_accuracy=0.987026#011binary_classification_cross_entropy=0.055078\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:26 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=15000 train binary_classification_accuracy <score>=0.987026064929\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:26 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, batch=15000 train binary_classification_cross_entropy <loss>=0.0550775002445\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:27 INFO 140573196957504] Epoch[2] Train-binary_classification_accuracy=0.987024\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:27 INFO 140573196957504] Epoch[2] Train-binary_classification_cross_entropy=0.055090\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:27 INFO 140573196957504] Epoch[2] Time cost=89.514\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:27 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, train binary_classification_accuracy <score>=0.98702375499\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:27 INFO 140573196957504] #quality_metric: host=algo-1, epoch=2, train binary_classification_cross_entropy <loss>=0.0550904634376\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 89517.53306388855, \"sum\": 89517.53306388855, \"min\": 89517.53306388855}}, \"EndTime\": 1601733867.953293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601733778.435219}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:27 INFO 140573196957504] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15281, \"sum\": 15281.0, \"min\": 15281}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 45843, \"sum\": 45843.0, \"min\": 45843}, \"Total Records Seen\": {\"count\": 1, \"max\": 45838149, \"sum\": 45838149.0, \"min\": 45838149}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 15279383, \"sum\": 15279383.0, \"min\": 15279383}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1601733867.953517, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\", \"epoch\": 2}, \"StartTime\": 1601733778.435728}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:27 INFO 140573196957504] #throughput_metric: host=algo-1, train throughput=170685.210646 records/second\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:27 WARNING 140573196957504] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:27 WARNING 140573196957504] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:27 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_accuracy <score>=0.982\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:27 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_cross_entropy <loss>=0.0493956184387\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:33 INFO 140573196957504] Epoch[3] Batch [1000]#011Speed: 170847.68 samples/sec#011binary_classification_accuracy=0.987104#011binary_classification_cross_entropy=0.054390\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:33 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=1000 train binary_classification_accuracy <score>=0.987103896104\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:33 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=1000 train binary_classification_cross_entropy <loss>=0.0543897608586\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:39 INFO 140573196957504] Epoch[3] Batch [2000]#011Speed: 171325.61 samples/sec#011binary_classification_accuracy=0.987226#011binary_classification_cross_entropy=0.054028\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:39 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=2000 train binary_classification_accuracy <score>=0.987226386807\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:39 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=2000 train binary_classification_cross_entropy <loss>=0.0540278822848\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:45 INFO 140573196957504] Epoch[3] Batch [3000]#011Speed: 173181.86 samples/sec#011binary_classification_accuracy=0.987262#011binary_classification_cross_entropy=0.054101\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:45 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=3000 train binary_classification_accuracy <score>=0.987262245918\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:45 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=3000 train binary_classification_cross_entropy <loss>=0.054100949392\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:51 INFO 140573196957504] Epoch[3] Batch [4000]#011Speed: 172582.15 samples/sec#011binary_classification_accuracy=0.987251#011binary_classification_cross_entropy=0.054027\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:51 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=4000 train binary_classification_accuracy <score>=0.987250687328\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:51 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=4000 train binary_classification_cross_entropy <loss>=0.0540269231865\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:57 INFO 140573196957504] Epoch[3] Batch [5000]#011Speed: 171045.28 samples/sec#011binary_classification_accuracy=0.987216#011binary_classification_cross_entropy=0.054126\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:57 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=5000 train binary_classification_accuracy <score>=0.987215556889\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:04:57 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=5000 train binary_classification_cross_entropy <loss>=0.0541255700642\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:02 INFO 140573196957504] Epoch[3] Batch [6000]#011Speed: 170175.22 samples/sec#011binary_classification_accuracy=0.987206#011binary_classification_cross_entropy=0.054200\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:02 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=6000 train binary_classification_accuracy <score>=0.987205965672\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:02 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=6000 train binary_classification_cross_entropy <loss>=0.0541995036051\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:08 INFO 140573196957504] Epoch[3] Batch [7000]#011Speed: 168929.50 samples/sec#011binary_classification_accuracy=0.987177#011binary_classification_cross_entropy=0.054223\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:08 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=7000 train binary_classification_accuracy <score>=0.987176546208\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:08 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=7000 train binary_classification_cross_entropy <loss>=0.0542232687895\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:14 INFO 140573196957504] Epoch[3] Batch [8000]#011Speed: 171570.50 samples/sec#011binary_classification_accuracy=0.987199#011binary_classification_cross_entropy=0.054080\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:14 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=8000 train binary_classification_accuracy <score>=0.987199100112\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:14 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=8000 train binary_classification_cross_entropy <loss>=0.0540799600274\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:20 INFO 140573196957504] Epoch[3] Batch [9000]#011Speed: 171623.65 samples/sec#011binary_classification_accuracy=0.987204#011binary_classification_cross_entropy=0.054040\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:20 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=9000 train binary_classification_accuracy <score>=0.987204088435\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:20 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=9000 train binary_classification_cross_entropy <loss>=0.0540398165308\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:26 INFO 140573196957504] Epoch[3] Batch [10000]#011Speed: 171557.02 samples/sec#011binary_classification_accuracy=0.987218#011binary_classification_cross_entropy=0.054014\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:26 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=10000 train binary_classification_accuracy <score>=0.987217878212\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:26 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=10000 train binary_classification_cross_entropy <loss>=0.0540144953517\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:32 INFO 140573196957504] Epoch[3] Batch [11000]#011Speed: 171645.62 samples/sec#011binary_classification_accuracy=0.987238#011binary_classification_cross_entropy=0.053965\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:32 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=11000 train binary_classification_accuracy <score>=0.987238341969\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:32 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=11000 train binary_classification_cross_entropy <loss>=0.0539649768604\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:37 INFO 140573196957504] Epoch[3] Batch [12000]#011Speed: 172569.01 samples/sec#011binary_classification_accuracy=0.987252#011binary_classification_cross_entropy=0.053908\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:37 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=12000 train binary_classification_accuracy <score>=0.987251812349\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:37 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=12000 train binary_classification_cross_entropy <loss>=0.0539075658398\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:43 INFO 140573196957504] Epoch[3] Batch [13000]#011Speed: 170841.93 samples/sec#011binary_classification_accuracy=0.987257#011binary_classification_cross_entropy=0.053927\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:43 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=13000 train binary_classification_accuracy <score>=0.987257134067\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:43 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=13000 train binary_classification_cross_entropy <loss>=0.053927479048\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:49 INFO 140573196957504] Epoch[3] Batch [14000]#011Speed: 170444.54 samples/sec#011binary_classification_accuracy=0.987250#011binary_classification_cross_entropy=0.053911\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:49 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=14000 train binary_classification_accuracy <score>=0.987250482108\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:49 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=14000 train binary_classification_cross_entropy <loss>=0.0539109983941\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:55 INFO 140573196957504] Epoch[3] Batch [15000]#011Speed: 169643.60 samples/sec#011binary_classification_accuracy=0.987266#011binary_classification_cross_entropy=0.053858\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:55 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=15000 train binary_classification_accuracy <score>=0.987265915606\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:55 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, batch=15000 train binary_classification_cross_entropy <loss>=0.053858287401\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:57 INFO 140573196957504] Epoch[3] Train-binary_classification_accuracy=0.987261\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:57 INFO 140573196957504] Epoch[3] Train-binary_classification_cross_entropy=0.053872\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:57 INFO 140573196957504] Epoch[3] Time cost=89.299\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:57 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, train binary_classification_accuracy <score>=0.987260846803\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:57 INFO 140573196957504] #quality_metric: host=algo-1, epoch=3, train binary_classification_cross_entropy <loss>=0.0538721618853\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 89303.32088470459, \"sum\": 89303.32088470459, \"min\": 89303.32088470459}}, \"EndTime\": 1601733957.257108, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601733867.953358}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:57 INFO 140573196957504] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15281, \"sum\": 15281.0, \"min\": 15281}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 61124, \"sum\": 61124.0, \"min\": 61124}, \"Total Records Seen\": {\"count\": 1, \"max\": 61117532, \"sum\": 61117532.0, \"min\": 61117532}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 15279383, \"sum\": 15279383.0, \"min\": 15279383}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1601733957.257395, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\", \"epoch\": 3}, \"StartTime\": 1601733867.953754}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:57 INFO 140573196957504] #throughput_metric: host=algo-1, train throughput=171094.443928 records/second\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:57 WARNING 140573196957504] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:57 WARNING 140573196957504] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:57 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_accuracy <score>=0.992\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:05:57 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_cross_entropy <loss>=0.042989982605\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:03 INFO 140573196957504] Epoch[4] Batch [1000]#011Speed: 169340.26 samples/sec#011binary_classification_accuracy=0.987347#011binary_classification_cross_entropy=0.053430\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:03 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=1000 train binary_classification_accuracy <score>=0.987346653347\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:03 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=1000 train binary_classification_cross_entropy <loss>=0.0534295195866\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:09 INFO 140573196957504] Epoch[4] Batch [2000]#011Speed: 171316.54 samples/sec#011binary_classification_accuracy=0.987373#011binary_classification_cross_entropy=0.053119\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:09 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=2000 train binary_classification_accuracy <score>=0.987373313343\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:09 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=2000 train binary_classification_cross_entropy <loss>=0.0531192274232\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:14 INFO 140573196957504] Epoch[4] Batch [3000]#011Speed: 169859.08 samples/sec#011binary_classification_accuracy=0.987317#011binary_classification_cross_entropy=0.053343\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:14 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=3000 train binary_classification_accuracy <score>=0.987316894369\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:14 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=3000 train binary_classification_cross_entropy <loss>=0.053342843705\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:20 INFO 140573196957504] Epoch[4] Batch [4000]#011Speed: 170251.31 samples/sec#011binary_classification_accuracy=0.987338#011binary_classification_cross_entropy=0.053249\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:20 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=4000 train binary_classification_accuracy <score>=0.987337665584\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:20 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=4000 train binary_classification_cross_entropy <loss>=0.0532490812867\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:26 INFO 140573196957504] Epoch[4] Batch [5000]#011Speed: 171406.90 samples/sec#011binary_classification_accuracy=0.987294#011binary_classification_cross_entropy=0.053387\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:26 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=5000 train binary_classification_accuracy <score>=0.987293941212\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:26 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=5000 train binary_classification_cross_entropy <loss>=0.0533872996462\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:32 INFO 140573196957504] Epoch[4] Batch [6000]#011Speed: 171976.09 samples/sec#011binary_classification_accuracy=0.987287#011binary_classification_cross_entropy=0.053400\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:32 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=6000 train binary_classification_accuracy <score>=0.987287452091\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:32 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=6000 train binary_classification_cross_entropy <loss>=0.0533995025837\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:38 INFO 140573196957504] Epoch[4] Batch [7000]#011Speed: 173922.96 samples/sec#011binary_classification_accuracy=0.987306#011binary_classification_cross_entropy=0.053342\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:38 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=7000 train binary_classification_accuracy <score>=0.987306241965\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:38 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=7000 train binary_classification_cross_entropy <loss>=0.0533419476991\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:43 INFO 140573196957504] Epoch[4] Batch [8000]#011Speed: 172171.54 samples/sec#011binary_classification_accuracy=0.987314#011binary_classification_cross_entropy=0.053279\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:43 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=8000 train binary_classification_accuracy <score>=0.987314335708\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:43 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=8000 train binary_classification_cross_entropy <loss>=0.0532794637979\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:49 INFO 140573196957504] Epoch[4] Batch [9000]#011Speed: 172179.68 samples/sec#011binary_classification_accuracy=0.987319#011binary_classification_cross_entropy=0.053261\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:49 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=9000 train binary_classification_accuracy <score>=0.987318631263\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:49 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=9000 train binary_classification_cross_entropy <loss>=0.0532608159793\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:55 INFO 140573196957504] Epoch[4] Batch [10000]#011Speed: 171511.79 samples/sec#011binary_classification_accuracy=0.987327#011binary_classification_cross_entropy=0.053251\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:55 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=10000 train binary_classification_accuracy <score>=0.987327167283\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:06:55 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=10000 train binary_classification_cross_entropy <loss>=0.053250532686\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:01 INFO 140573196957504] Epoch[4] Batch [11000]#011Speed: 171836.22 samples/sec#011binary_classification_accuracy=0.987357#011binary_classification_cross_entropy=0.053183\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:01 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=11000 train binary_classification_accuracy <score>=0.987356876648\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:01 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=11000 train binary_classification_cross_entropy <loss>=0.0531834254302\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:07 INFO 140573196957504] Epoch[4] Batch [12000]#011Speed: 171480.00 samples/sec#011binary_classification_accuracy=0.987362#011binary_classification_cross_entropy=0.053127\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:07 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=12000 train binary_classification_accuracy <score>=0.987361719857\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:07 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=12000 train binary_classification_cross_entropy <loss>=0.0531273158566\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:13 INFO 140573196957504] Epoch[4] Batch [13000]#011Speed: 173296.74 samples/sec#011binary_classification_accuracy=0.987366#011binary_classification_cross_entropy=0.053135\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:13 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=13000 train binary_classification_accuracy <score>=0.987365741097\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:13 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=13000 train binary_classification_cross_entropy <loss>=0.0531352605304\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:18 INFO 140573196957504] Epoch[4] Batch [14000]#011Speed: 172316.22 samples/sec#011binary_classification_accuracy=0.987357#011binary_classification_cross_entropy=0.053138\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:18 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=14000 train binary_classification_accuracy <score>=0.987356688808\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:18 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=14000 train binary_classification_cross_entropy <loss>=0.0531383400613\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:24 INFO 140573196957504] Epoch[4] Batch [15000]#011Speed: 170859.71 samples/sec#011binary_classification_accuracy=0.987357#011binary_classification_cross_entropy=0.053107\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:24 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=15000 train binary_classification_accuracy <score>=0.98735724285\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:24 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, batch=15000 train binary_classification_cross_entropy <loss>=0.0531070498313\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:26 INFO 140573196957504] Epoch[4] Train-binary_classification_accuracy=0.987359\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:26 INFO 140573196957504] Epoch[4] Train-binary_classification_cross_entropy=0.053108\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:26 INFO 140573196957504] Epoch[4] Time cost=89.126\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:26 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, train binary_classification_accuracy <score>=0.987358877037\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:26 INFO 140573196957504] #quality_metric: host=algo-1, epoch=4, train binary_classification_cross_entropy <loss>=0.053108147517\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 89129.57000732422, \"sum\": 89129.57000732422, \"min\": 89129.57000732422}}, \"EndTime\": 1601734046.387258, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601733957.257186}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:26 INFO 140573196957504] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15281, \"sum\": 15281.0, \"min\": 15281}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 76405, \"sum\": 76405.0, \"min\": 76405}, \"Total Records Seen\": {\"count\": 1, \"max\": 76396915, \"sum\": 76396915.0, \"min\": 76396915}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 15279383, \"sum\": 15279383.0, \"min\": 15279383}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1601734046.387537, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\", \"epoch\": 4}, \"StartTime\": 1601733957.257657}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:26 INFO 140573196957504] #throughput_metric: host=algo-1, train throughput=171428.029193 records/second\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:26 INFO 140573196957504] Saved checkpoint to \"/tmp/tmpWMi3nD/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:26 WARNING 140573196957504] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 0.39505958557128906, \"sum\": 0.39505958557128906, \"min\": 0.39505958557128906}}, \"EndTime\": 1601734046.426404, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601734046.387329}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:26 INFO 140573196957504] Saved checkpoint to \"/tmp/tmprLxr5e/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:07:26 INFO 140573196957504] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 452402.5790691376, \"sum\": 452402.5790691376, \"min\": 452402.5790691376}, \"setuptime\": {\"count\": 1, \"max\": 68.89104843139648, \"sum\": 68.89104843139648, \"min\": 68.89104843139648}}, \"EndTime\": 1601734046.46331, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601734046.426471}\n",
      "\u001b[0m\n",
      "\n",
      "2020-10-03 14:07:37 Uploading - Uploading generated training model\n",
      "2020-10-03 14:07:37 Completed - Training job completed\n",
      "Training seconds: 545\n",
      "Billable seconds: 545\n"
     ]
    }
   ],
   "source": [
    "# Set up the estimator with training job configuration\n",
    "ip_insights = sagemaker.estimator.Estimator(\n",
    "    image, \n",
    "    execution_role, \n",
    "    train_instance_count=1, \n",
    "    train_instance_type='ml.p3.2xlarge',\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker.Session())\n",
    "\n",
    "# Configure algorithm-specific hyperparameters\n",
    "ip_insights.set_hyperparameters(\n",
    "    num_entity_vectors='20000',\n",
    "    random_negative_sampling_rate='5',\n",
    "    vector_dim='128', \n",
    "    mini_batch_size='1000',\n",
    "    epochs='5',\n",
    "    learning_rate='0.01',\n",
    ")\n",
    "\n",
    "# Start the training job (should take about ~1.5 minute / epoch to complete)  \n",
    "ip_insights.fit(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see the message\n",
    "\n",
    "    > Completed - Training job completed\n",
    "\n",
    "at the bottom of the output logs then that means training successfully completed and the output of the SageMaker IP Insights model was stored in the specified output path. You can also view information about and the status of a training job using the AWS SageMaker console. Just click on the \"Jobs\" tab and select training job matching the training job name, below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name: ipinsights-2020-10-03-13-56-19-559\n"
     ]
    }
   ],
   "source": [
    "print('Training job name: {}'.format(ip_insights.latest_training_job.job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "-----\n",
    "\n",
    "Now that we have trained a SageMaker IP Insights model, we can deploy the model to an endpoint to start performing inference on data. In this case, that means providing it a `<user, IP address>` pair and predicting their compatability scores.\n",
    "\n",
    "We can create an inference endpoint using the SageMaker Python SDK `deploy()`function from the job we defined above. We specify the instance type where inference will be performed, as well as the initial number of instnaces to spin up. We recommend using the `ml.m5` instance as it provides the most memory at the lowest cost. Verify how large your model is in S3 and pick the instance type with the appropriate amount of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "predictor = ip_insights.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you now have a SageMaker IP Insights inference endpoint! You could start integrating this endpoint with your production services to start querying incoming requests for abnormal behavior. \n",
    "\n",
    "You can confirm the endpoint configuration and status by navigating to the \"Endpoints\" tab in the AWS SageMaker console and selecting the endpoint matching the endpoint name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: ipinsights-2020-10-03-13-56-19-559\n"
     ]
    }
   ],
   "source": [
    "print('Endpoint name: {}'.format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Serialization/Deserialization\n",
    "We can pass data in a variety of formats to our inference endpoint. In this example, we will pass CSV-formmated data. Other available formats are JSON-formated and JSON Lines-formatted. We make use of the SageMaker Python SDK utilities: `csv_serializer` and `json_deserializer` when configuring the inference endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "predictor.content_type = 'text/csv'\n",
    "predictor.serializer = csv_serializer\n",
    "predictor.accept = 'application/json'\n",
    "predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the predictor is configured, it is as easy as passing in a matrix of inference data.\n",
    "We can take a few samples from the simulated dataset above, so we can see what the output looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'dot_product': 5.108431816101074},\n",
       "  {'dot_product': 10.972567558288574},\n",
       "  {'dot_product': 1.3550143241882324},\n",
       "  {'dot_product': 4.033393383026123},\n",
       "  {'dot_product': 3.846628427505493}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_data = [(data[0], data[1]) for data in train_df[:5].values]\n",
    "predictor.predict(inference_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the predictor will only output the `dot_product` between the learned IP address and the online resource (in this case, the user ID). The dot product summarizes the compatibility between the IP address and online resource. The larger the value, the more the algorithm thinks the IP address is likely to be used by the user. This compatability score is sufficient for most applications, as we can define a threshold for what we constitute as an anomalous score.\n",
    "\n",
    "However, more advanced users may want to inspect the learned embeddings and use them in further applications. We can configure the predictor to provide the learned embeddings by specifing the `verbose=True` parameter to the Accept heading. You should see that each 'prediction' object contains three keys: `ip_embedding`, `entity_embedding`, and `dot_product`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'ip_embedding': [-0.4995935261249542,\n",
       "    0.7505828738212585,\n",
       "    -0.16287297010421753,\n",
       "    0.650463342666626,\n",
       "    0.4240000247955322,\n",
       "    0.6244646310806274,\n",
       "    0.12638409435749054,\n",
       "    -0.04740038514137268,\n",
       "    0.06568674743175507,\n",
       "    -0.5632657408714294,\n",
       "    -0.07945491373538971,\n",
       "    0.09044234454631805,\n",
       "    -0.1905529946088791,\n",
       "    1.1120517253875732,\n",
       "    0.32880815863609314,\n",
       "    0.006505325436592102,\n",
       "    -0.034861862659454346,\n",
       "    0.04380425810813904,\n",
       "    0.06196163594722748,\n",
       "    0.0010447129607200623,\n",
       "    0.2601086497306824,\n",
       "    0.527064323425293,\n",
       "    -0.10049109905958176,\n",
       "    0.06218159198760986,\n",
       "    0.13895288109779358,\n",
       "    -0.8514293432235718,\n",
       "    0.011176498606801033,\n",
       "    -0.18074637651443481,\n",
       "    0.2778764069080353,\n",
       "    0.5318735837936401,\n",
       "    0.2905173599720001,\n",
       "    0.06495775282382965,\n",
       "    -0.026719585061073303,\n",
       "    -0.046609148383140564,\n",
       "    0.6962219476699829,\n",
       "    -0.23349106311798096,\n",
       "    0.09211498498916626,\n",
       "    -0.04006025195121765,\n",
       "    -0.5002489686012268,\n",
       "    0.520909309387207,\n",
       "    -0.19002272188663483,\n",
       "    -0.2270870953798294,\n",
       "    -0.5383949279785156,\n",
       "    -0.0520906038582325,\n",
       "    0.2341843694448471,\n",
       "    -0.07536560297012329,\n",
       "    -0.2852873206138611,\n",
       "    0.4512604773044586,\n",
       "    0.09471537917852402,\n",
       "    -0.06933479011058807,\n",
       "    -0.49091917276382446,\n",
       "    0.03500485420227051,\n",
       "    -0.150887131690979,\n",
       "    0.45322954654693604,\n",
       "    -0.01774001121520996,\n",
       "    -0.09693174809217453,\n",
       "    -0.0460248738527298,\n",
       "    -0.14994174242019653,\n",
       "    0.010479986667633057,\n",
       "    0.09663518518209457,\n",
       "    -0.6520595550537109,\n",
       "    0.3095397353172302,\n",
       "    -0.04478389769792557,\n",
       "    0.13676731288433075,\n",
       "    0.19234664738178253,\n",
       "    0.04290194809436798,\n",
       "    0.47905445098876953,\n",
       "    0.04356939345598221,\n",
       "    0.8680469989776611,\n",
       "    0.1794103980064392,\n",
       "    0.07355856150388718,\n",
       "    -0.08371992409229279,\n",
       "    -0.6446992754936218,\n",
       "    0.169219508767128,\n",
       "    0.3895522356033325,\n",
       "    0.21072161197662354,\n",
       "    -0.11016595363616943,\n",
       "    0.4796057939529419,\n",
       "    -0.5026887655258179,\n",
       "    -0.18487125635147095,\n",
       "    -0.12197984755039215,\n",
       "    -0.245774507522583,\n",
       "    0.31386321783065796,\n",
       "    -0.09944875538349152,\n",
       "    0.5782226324081421,\n",
       "    -0.010975301265716553,\n",
       "    0.3632432818412781,\n",
       "    0.020049849525094032,\n",
       "    0.028393391519784927,\n",
       "    0.32050830125808716,\n",
       "    -0.12701359391212463,\n",
       "    0.07274045050144196,\n",
       "    0.32413506507873535,\n",
       "    0.10639408230781555,\n",
       "    0.001913502812385559,\n",
       "    0.2249997854232788,\n",
       "    1.0016348361968994,\n",
       "    0.012747511267662048,\n",
       "    0.24535980820655823,\n",
       "    -0.2781359851360321,\n",
       "    0.10707936435937881,\n",
       "    -0.3796101212501526,\n",
       "    -0.13528890907764435,\n",
       "    0.5110046863555908,\n",
       "    0.07288302481174469,\n",
       "    0.5832189917564392,\n",
       "    0.8387538194656372,\n",
       "    0.3367289900779724,\n",
       "    0.03951321542263031,\n",
       "    -0.13509076833724976,\n",
       "    -0.01755174994468689,\n",
       "    0.006498962640762329,\n",
       "    0.1374754160642624,\n",
       "    -0.3648504316806793,\n",
       "    -0.38128986954689026,\n",
       "    -0.011390343308448792,\n",
       "    -0.47852739691734314,\n",
       "    -0.06670168787240982,\n",
       "    0.00045191869139671326,\n",
       "    -0.5465757250785828,\n",
       "    0.671931803226471,\n",
       "    -0.08005376160144806,\n",
       "    -0.7319909334182739,\n",
       "    -0.2957536578178406,\n",
       "    0.12595972418785095,\n",
       "    0.24667227268218994,\n",
       "    -0.006874978542327881,\n",
       "    0.16610020399093628],\n",
       "   'entity_embedding': [-0.7292880415916443,\n",
       "    0.401649534702301,\n",
       "    -0.5012910962104797,\n",
       "    0.9280292391777039,\n",
       "    0.5746766924858093,\n",
       "    -0.48367705941200256,\n",
       "    -0.02329327166080475,\n",
       "    0.28027060627937317,\n",
       "    -0.8144545555114746,\n",
       "    -0.08711908757686615,\n",
       "    -0.16181887686252594,\n",
       "    -0.611667275428772,\n",
       "    -0.17796827852725983,\n",
       "    0.36203259229660034,\n",
       "    -0.1010940670967102,\n",
       "    0.4851782023906708,\n",
       "    0.13961434364318848,\n",
       "    0.05802561715245247,\n",
       "    0.2829638421535492,\n",
       "    -0.52313631772995,\n",
       "    -0.18916942179203033,\n",
       "    -0.1789589822292328,\n",
       "    -0.5371429324150085,\n",
       "    0.13450516760349274,\n",
       "    0.2721632421016693,\n",
       "    -0.24709339439868927,\n",
       "    0.6711393594741821,\n",
       "    -0.5048409700393677,\n",
       "    -0.3537999391555786,\n",
       "    0.11611274629831314,\n",
       "    0.23288223147392273,\n",
       "    0.22169333696365356,\n",
       "    -0.26995187997817993,\n",
       "    -0.06980552524328232,\n",
       "    0.39680466055870056,\n",
       "    -0.34034302830696106,\n",
       "    0.34294313192367554,\n",
       "    -0.2600628435611725,\n",
       "    -0.2282147854566574,\n",
       "    0.6650767922401428,\n",
       "    -0.23563459515571594,\n",
       "    -0.5922373533248901,\n",
       "    -0.3401678800582886,\n",
       "    0.08277848362922668,\n",
       "    -0.6715487837791443,\n",
       "    -0.4017212688922882,\n",
       "    0.5710395574569702,\n",
       "    0.19496187567710876,\n",
       "    -0.20349761843681335,\n",
       "    -0.34943699836730957,\n",
       "    0.29682937264442444,\n",
       "    -0.3597797751426697,\n",
       "    -0.29823994636535645,\n",
       "    0.22372636198997498,\n",
       "    0.07595761120319366,\n",
       "    0.042181551456451416,\n",
       "    -0.2570135295391083,\n",
       "    0.07639279216527939,\n",
       "    -0.7823087573051453,\n",
       "    0.039536796510219574,\n",
       "    -0.45739760994911194,\n",
       "    -0.7352187037467957,\n",
       "    -0.2638421654701233,\n",
       "    -0.052016276866197586,\n",
       "    -0.41486796736717224,\n",
       "    -0.06964830309152603,\n",
       "    0.21716037392616272,\n",
       "    -0.0014064953429624438,\n",
       "    0.11910749226808548,\n",
       "    -0.06035146862268448,\n",
       "    -0.13078032433986664,\n",
       "    -0.01105298101902008,\n",
       "    -0.2764735817909241,\n",
       "    -0.20875103771686554,\n",
       "    0.7321193218231201,\n",
       "    0.3371849060058594,\n",
       "    -0.5431355237960815,\n",
       "    -0.4203966557979584,\n",
       "    -0.4012052118778229,\n",
       "    0.050695933401584625,\n",
       "    0.1820490062236786,\n",
       "    0.16894946992397308,\n",
       "    0.769218385219574,\n",
       "    -0.1484334021806717,\n",
       "    -0.012334547936916351,\n",
       "    0.3106785714626312,\n",
       "    0.4552220404148102,\n",
       "    -0.5659564733505249,\n",
       "    -0.19809459149837494,\n",
       "    -0.3292631506919861,\n",
       "    -0.19332264363765717,\n",
       "    0.10710380226373672,\n",
       "    -0.047740157693624496,\n",
       "    0.08759912848472595,\n",
       "    -0.6905533075332642,\n",
       "    -0.09133131802082062,\n",
       "    0.12511305510997772,\n",
       "    -0.49954479932785034,\n",
       "    0.025725118815898895,\n",
       "    -0.24639344215393066,\n",
       "    0.3205471336841583,\n",
       "    -0.20336927473545074,\n",
       "    -0.1627919226884842,\n",
       "    -0.44203847646713257,\n",
       "    0.00021510873921215534,\n",
       "    -0.2038085013628006,\n",
       "    0.792845606803894,\n",
       "    -0.5338010787963867,\n",
       "    0.31372320652008057,\n",
       "    0.09878601133823395,\n",
       "    -0.3321293890476227,\n",
       "    0.8451970219612122,\n",
       "    0.06757288426160812,\n",
       "    -0.3706400394439697,\n",
       "    -0.33891141414642334,\n",
       "    -0.13961631059646606,\n",
       "    -0.20642679929733276,\n",
       "    0.4547938108444214,\n",
       "    0.14008112251758575,\n",
       "    0.11169050633907318,\n",
       "    -0.14299196004867554,\n",
       "    0.3869953155517578,\n",
       "    -0.8159078359603882,\n",
       "    0.0036963182501494884,\n",
       "    -0.1108342632651329,\n",
       "    -0.10287386178970337,\n",
       "    -0.26392632722854614,\n",
       "    -0.08385824412107468],\n",
       "   'dot_product': 5.108431816101074},\n",
       "  {'ip_embedding': [-0.19009625911712646,\n",
       "    0.3593386113643646,\n",
       "    0.06418224424123764,\n",
       "    0.13100743293762207,\n",
       "    0.14595991373062134,\n",
       "    0.008749423548579216,\n",
       "    0.16600370407104492,\n",
       "    0.07058188319206238,\n",
       "    0.32396289706230164,\n",
       "    -0.46584561467170715,\n",
       "    0.09268218278884888,\n",
       "    -0.0685037225484848,\n",
       "    0.10887488722801208,\n",
       "    0.7841405868530273,\n",
       "    -0.04308968782424927,\n",
       "    -0.485729455947876,\n",
       "    -0.016822785139083862,\n",
       "    0.1958288699388504,\n",
       "    -0.13208431005477905,\n",
       "    0.05173913389444351,\n",
       "    -0.28648698329925537,\n",
       "    -0.02183174341917038,\n",
       "    -0.13783550262451172,\n",
       "    0.45209863781929016,\n",
       "    -0.3516806960105896,\n",
       "    0.11993912607431412,\n",
       "    -0.5693004727363586,\n",
       "    0.36406034231185913,\n",
       "    0.07073046267032623,\n",
       "    -0.09330134093761444,\n",
       "    0.08154650032520294,\n",
       "    -0.034897446632385254,\n",
       "    0.3068770468235016,\n",
       "    0.3938491940498352,\n",
       "    0.043125029653310776,\n",
       "    -0.19672565162181854,\n",
       "    -0.6674146056175232,\n",
       "    -0.25834348797798157,\n",
       "    0.1543017327785492,\n",
       "    0.27188119292259216,\n",
       "    0.34658190608024597,\n",
       "    0.2820538580417633,\n",
       "    -0.013639412820339203,\n",
       "    -0.16460853815078735,\n",
       "    0.3887176513671875,\n",
       "    -0.006132733076810837,\n",
       "    -0.15248188376426697,\n",
       "    0.20328500866889954,\n",
       "    0.013888869434595108,\n",
       "    0.3901962637901306,\n",
       "    -0.5240857005119324,\n",
       "    0.4325608015060425,\n",
       "    -0.0902462750673294,\n",
       "    0.10915254056453705,\n",
       "    -0.08605939149856567,\n",
       "    0.16630512475967407,\n",
       "    0.028278343379497528,\n",
       "    0.19813214242458344,\n",
       "    0.46550649404525757,\n",
       "    0.279715359210968,\n",
       "    0.11994631588459015,\n",
       "    0.2558150887489319,\n",
       "    -0.1835610270500183,\n",
       "    -0.08384589105844498,\n",
       "    0.0711868479847908,\n",
       "    -0.10952150821685791,\n",
       "    0.43352392315864563,\n",
       "    -0.07658877223730087,\n",
       "    0.2976374328136444,\n",
       "    0.5085077285766602,\n",
       "    0.1199691891670227,\n",
       "    -0.27635642886161804,\n",
       "    -0.2584000527858734,\n",
       "    0.03815542906522751,\n",
       "    -0.061282940208911896,\n",
       "    0.030584067106246948,\n",
       "    0.02346016839146614,\n",
       "    0.18869337439537048,\n",
       "    -0.2041500061750412,\n",
       "    0.34006616473197937,\n",
       "    -0.32778096199035645,\n",
       "    -0.24216756224632263,\n",
       "    -0.10333804041147232,\n",
       "    -0.025675326585769653,\n",
       "    0.7608157992362976,\n",
       "    -0.3654075264930725,\n",
       "    0.27802789211273193,\n",
       "    -0.0261424258351326,\n",
       "    -0.1343599557876587,\n",
       "    0.30958402156829834,\n",
       "    -0.008508611470460892,\n",
       "    -0.07853208482265472,\n",
       "    0.022464938461780548,\n",
       "    0.4918414354324341,\n",
       "    0.2536006271839142,\n",
       "    0.17369864881038666,\n",
       "    -0.16230793297290802,\n",
       "    0.1327374279499054,\n",
       "    0.015754438936710358,\n",
       "    -0.09869427978992462,\n",
       "    0.35304832458496094,\n",
       "    0.21074740588665009,\n",
       "    0.0600593239068985,\n",
       "    0.3723644018173218,\n",
       "    0.18157009780406952,\n",
       "    0.4610866904258728,\n",
       "    -0.2972719669342041,\n",
       "    0.5221856236457825,\n",
       "    -0.5465478897094727,\n",
       "    -0.31485822796821594,\n",
       "    -0.14258608222007751,\n",
       "    -0.20550939440727234,\n",
       "    0.37172311544418335,\n",
       "    0.2497176080942154,\n",
       "    0.16363555192947388,\n",
       "    0.128403902053833,\n",
       "    -0.30043697357177734,\n",
       "    0.00498534319922328,\n",
       "    0.2152862846851349,\n",
       "    -0.07560627907514572,\n",
       "    -0.331759512424469,\n",
       "    0.056996025145053864,\n",
       "    0.29408523440361023,\n",
       "    -0.15730081498622894,\n",
       "    -0.03071320429444313,\n",
       "    0.17019128799438477,\n",
       "    -0.1159457415342331,\n",
       "    -0.2369372695684433],\n",
       "   'entity_embedding': [1.4383416175842285,\n",
       "    -3.156733512878418,\n",
       "    -1.6493598222732544,\n",
       "    1.1575212478637695,\n",
       "    -0.40059229731559753,\n",
       "    -2.7358901500701904,\n",
       "    0.12413892149925232,\n",
       "    -2.203078508377075,\n",
       "    -1.0256842374801636,\n",
       "    1.229261875152588,\n",
       "    2.942490577697754,\n",
       "    -2.446758508682251,\n",
       "    1.7145916223526,\n",
       "    1.45263671875,\n",
       "    -2.198908567428589,\n",
       "    -0.17648594081401825,\n",
       "    2.217163562774658,\n",
       "    -0.7976709008216858,\n",
       "    -1.1051466464996338,\n",
       "    -0.5764345526695251,\n",
       "    -1.4386107921600342,\n",
       "    -3.0327630043029785,\n",
       "    1.4467545747756958,\n",
       "    0.43185651302337646,\n",
       "    1.1435232162475586,\n",
       "    2.796123504638672,\n",
       "    0.5895785689353943,\n",
       "    -0.8412591814994812,\n",
       "    -1.888136625289917,\n",
       "    -3.003462791442871,\n",
       "    0.9047307968139648,\n",
       "    -2.7862887382507324,\n",
       "    3.077425718307495,\n",
       "    1.7182108163833618,\n",
       "    -1.0111027956008911,\n",
       "    0.30698952078819275,\n",
       "    -1.5068315267562866,\n",
       "    -0.5743647813796997,\n",
       "    3.50115966796875,\n",
       "    -0.7272639870643616,\n",
       "    1.1375197172164917,\n",
       "    -1.6222532987594604,\n",
       "    0.5229111313819885,\n",
       "    0.31741538643836975,\n",
       "    -0.07279414683580399,\n",
       "    1.9562908411026,\n",
       "    -0.1595308780670166,\n",
       "    -3.470174789428711,\n",
       "    -0.6092429757118225,\n",
       "    1.0508265495300293,\n",
       "    -2.044595956802368,\n",
       "    1.3230279684066772,\n",
       "    0.25848060846328735,\n",
       "    3.061556100845337,\n",
       "    -2.803107738494873,\n",
       "    1.9861550331115723,\n",
       "    -0.4579881727695465,\n",
       "    -0.25342607498168945,\n",
       "    -0.9952711462974548,\n",
       "    2.0636184215545654,\n",
       "    -0.47656261920928955,\n",
       "    -0.5971106886863708,\n",
       "    -0.02122412621974945,\n",
       "    -2.1466281414031982,\n",
       "    0.5229194164276123,\n",
       "    -2.38557767868042,\n",
       "    1.5106700658798218,\n",
       "    0.26162806153297424,\n",
       "    -0.47989338636398315,\n",
       "    -0.999527096748352,\n",
       "    -2.6716976165771484,\n",
       "    -0.12299806624650955,\n",
       "    0.4990200698375702,\n",
       "    0.4803659915924072,\n",
       "    0.29408401250839233,\n",
       "    3.537076950073242,\n",
       "    -0.1438540667295456,\n",
       "    -0.25728732347488403,\n",
       "    -0.0279274582862854,\n",
       "    0.5673556327819824,\n",
       "    -1.6183432340621948,\n",
       "    0.6893630027770996,\n",
       "    1.261297345161438,\n",
       "    0.7354844808578491,\n",
       "    0.693321943283081,\n",
       "    -0.9755440950393677,\n",
       "    -1.344766616821289,\n",
       "    -3.4639341831207275,\n",
       "    -0.010040448978543282,\n",
       "    -0.2654087543487549,\n",
       "    0.009166824631392956,\n",
       "    0.3481513559818268,\n",
       "    -1.490921139717102,\n",
       "    0.09026957303285599,\n",
       "    -1.4057484865188599,\n",
       "    1.0333950519561768,\n",
       "    -3.042781352996826,\n",
       "    0.4658620059490204,\n",
       "    -1.279606819152832,\n",
       "    0.9718457460403442,\n",
       "    0.20618321001529694,\n",
       "    -1.456334114074707,\n",
       "    -0.8248358964920044,\n",
       "    -0.12342332303524017,\n",
       "    0.882671058177948,\n",
       "    1.2446887493133545,\n",
       "    -4.380813121795654,\n",
       "    -0.506317138671875,\n",
       "    -2.0040204524993896,\n",
       "    -0.7761566638946533,\n",
       "    0.996772825717926,\n",
       "    0.5559011101722717,\n",
       "    -1.0785244703292847,\n",
       "    3.796295166015625,\n",
       "    1.127764344215393,\n",
       "    2.9309704303741455,\n",
       "    -0.14889977872371674,\n",
       "    1.5409672260284424,\n",
       "    0.546217679977417,\n",
       "    0.4310244917869568,\n",
       "    -3.7908482551574707,\n",
       "    0.8128640055656433,\n",
       "    -1.876348853111267,\n",
       "    0.2841232120990753,\n",
       "    0.24710839986801147,\n",
       "    0.19364000856876373,\n",
       "    -1.4272971153259277,\n",
       "    -2.5770387649536133],\n",
       "   'dot_product': 10.972567558288574},\n",
       "  {'ip_embedding': [-0.1473400890827179,\n",
       "    0.17552661895751953,\n",
       "    -0.08886117488145828,\n",
       "    -0.13933420181274414,\n",
       "    -0.1595686674118042,\n",
       "    0.24851499497890472,\n",
       "    0.29994910955429077,\n",
       "    -0.04911735653877258,\n",
       "    0.06509178876876831,\n",
       "    0.09785915166139603,\n",
       "    0.030803769826889038,\n",
       "    0.09576993435621262,\n",
       "    -0.015015145763754845,\n",
       "    0.12999248504638672,\n",
       "    -0.06634311378002167,\n",
       "    -0.29202449321746826,\n",
       "    -0.053198181092739105,\n",
       "    0.35984718799591064,\n",
       "    0.027848295867443085,\n",
       "    -0.13991938531398773,\n",
       "    0.22928103804588318,\n",
       "    0.10651889443397522,\n",
       "    -0.28226155042648315,\n",
       "    0.38891738653182983,\n",
       "    0.025605320930480957,\n",
       "    -0.2995951473712921,\n",
       "    -0.09816321730613708,\n",
       "    -0.15552662312984467,\n",
       "    0.04399413615465164,\n",
       "    0.3571324348449707,\n",
       "    0.4663826823234558,\n",
       "    0.676947832107544,\n",
       "    0.11938439309597015,\n",
       "    -0.10109648108482361,\n",
       "    0.0966075211763382,\n",
       "    0.1808772087097168,\n",
       "    -0.046590421348810196,\n",
       "    0.17305748164653778,\n",
       "    0.07741741091012955,\n",
       "    0.18800877034664154,\n",
       "    0.3680490255355835,\n",
       "    -0.2424311488866806,\n",
       "    -0.14057612419128418,\n",
       "    0.13115999102592468,\n",
       "    0.2579537630081177,\n",
       "    -0.14747028052806854,\n",
       "    -0.17377236485481262,\n",
       "    0.14027735590934753,\n",
       "    0.16284474730491638,\n",
       "    -0.04517270624637604,\n",
       "    0.15726707875728607,\n",
       "    0.007815506309270859,\n",
       "    -0.0101536326110363,\n",
       "    0.09761378169059753,\n",
       "    0.20109233260154724,\n",
       "    -0.3195631206035614,\n",
       "    -0.01105181872844696,\n",
       "    0.15122337639331818,\n",
       "    -0.3075178265571594,\n",
       "    0.08946221321821213,\n",
       "    -0.2324269413948059,\n",
       "    0.003134116530418396,\n",
       "    0.007588796317577362,\n",
       "    0.08324971795082092,\n",
       "    -0.06326885521411896,\n",
       "    -0.009960278868675232,\n",
       "    0.08753511309623718,\n",
       "    -0.2075686752796173,\n",
       "    0.22492600977420807,\n",
       "    0.19784680008888245,\n",
       "    0.14859792590141296,\n",
       "    -0.00833970122039318,\n",
       "    -0.15040051937103271,\n",
       "    0.0899496078491211,\n",
       "    0.06463390588760376,\n",
       "    -0.26789939403533936,\n",
       "    0.27687230706214905,\n",
       "    -0.03317488729953766,\n",
       "    0.07908675074577332,\n",
       "    -0.020581327378749847,\n",
       "    -0.10234767198562622,\n",
       "    -0.14886099100112915,\n",
       "    0.2597305178642273,\n",
       "    -0.04553414136171341,\n",
       "    0.21694613993167877,\n",
       "    0.07935510575771332,\n",
       "    0.14270934462547302,\n",
       "    -0.009661495685577393,\n",
       "    -0.14637458324432373,\n",
       "    0.06639210134744644,\n",
       "    -0.2730622887611389,\n",
       "    -0.7536301612854004,\n",
       "    0.0882042646408081,\n",
       "    0.9942945837974548,\n",
       "    -0.012482792139053345,\n",
       "    0.5071896910667419,\n",
       "    0.16386857628822327,\n",
       "    0.28616178035736084,\n",
       "    0.2738066613674164,\n",
       "    -0.47271624207496643,\n",
       "    0.11503876745700836,\n",
       "    0.3972150683403015,\n",
       "    0.13395975530147552,\n",
       "    0.19956806302070618,\n",
       "    -0.026041511446237564,\n",
       "    0.034494780004024506,\n",
       "    0.43971389532089233,\n",
       "    0.3511706590652466,\n",
       "    0.11821061372756958,\n",
       "    -0.0608290359377861,\n",
       "    -0.14586836099624634,\n",
       "    0.27133458852767944,\n",
       "    0.24534258246421814,\n",
       "    -0.11869315057992935,\n",
       "    -0.10630840808153152,\n",
       "    0.14764003455638885,\n",
       "    -0.181930810213089,\n",
       "    0.05072386562824249,\n",
       "    -0.16384270787239075,\n",
       "    0.03490675613284111,\n",
       "    0.4058550298213959,\n",
       "    0.05135076120495796,\n",
       "    0.4785693883895874,\n",
       "    0.1440141797065735,\n",
       "    -0.08305889368057251,\n",
       "    0.1760743409395218,\n",
       "    0.3553122878074646,\n",
       "    -0.07406536489725113],\n",
       "   'entity_embedding': [0.007415952160954475,\n",
       "    -0.9262223839759827,\n",
       "    -0.5591395497322083,\n",
       "    -0.46026626229286194,\n",
       "    -0.7871957421302795,\n",
       "    -0.1259513944387436,\n",
       "    -0.5612031817436218,\n",
       "    -0.12204001843929291,\n",
       "    -0.3056672215461731,\n",
       "    0.8574630618095398,\n",
       "    -0.3597375750541687,\n",
       "    -1.0678273439407349,\n",
       "    -0.13045160472393036,\n",
       "    0.1403602808713913,\n",
       "    -0.8035605549812317,\n",
       "    0.8532956838607788,\n",
       "    0.0019044838845729828,\n",
       "    0.10704192519187927,\n",
       "    1.1397582292556763,\n",
       "    -0.36545318365097046,\n",
       "    -0.4743562936782837,\n",
       "    -0.434048593044281,\n",
       "    -0.10683850198984146,\n",
       "    -0.042522408068180084,\n",
       "    0.6180214881896973,\n",
       "    -0.2138577401638031,\n",
       "    -0.39607125520706177,\n",
       "    0.19633197784423828,\n",
       "    0.2986256778240204,\n",
       "    0.30958253145217896,\n",
       "    0.06332182884216309,\n",
       "    0.4622701108455658,\n",
       "    0.007434075232595205,\n",
       "    0.15186037123203278,\n",
       "    -0.2818506360054016,\n",
       "    0.06554160267114639,\n",
       "    -0.1387188732624054,\n",
       "    -0.09372080117464066,\n",
       "    1.1771827936172485,\n",
       "    -0.32607460021972656,\n",
       "    0.333237886428833,\n",
       "    -0.9198384881019592,\n",
       "    0.2507765293121338,\n",
       "    -0.10372191667556763,\n",
       "    -0.6226346492767334,\n",
       "    -0.5187451243400574,\n",
       "    1.3853522539138794,\n",
       "    0.05330923572182655,\n",
       "    -0.9904131889343262,\n",
       "    0.18146570026874542,\n",
       "    0.7260778546333313,\n",
       "    -1.016350507736206,\n",
       "    0.50264972448349,\n",
       "    -0.1444212645292282,\n",
       "    -0.3818434178829193,\n",
       "    0.08765733987092972,\n",
       "    -0.2556239366531372,\n",
       "    -0.04135935753583908,\n",
       "    -0.5746747851371765,\n",
       "    -0.3379535973072052,\n",
       "    0.3737594485282898,\n",
       "    -1.1835676431655884,\n",
       "    0.020426785573363304,\n",
       "    -0.2628256380558014,\n",
       "    -0.028811173513531685,\n",
       "    -0.096133753657341,\n",
       "    -0.4086363613605499,\n",
       "    -0.252319872379303,\n",
       "    0.4314843714237213,\n",
       "    0.3015602231025696,\n",
       "    0.2915549576282501,\n",
       "    -0.14228101074695587,\n",
       "    0.23889662325382233,\n",
       "    0.2484963983297348,\n",
       "    -0.571881115436554,\n",
       "    0.19345629215240479,\n",
       "    0.6620160341262817,\n",
       "    -0.47976598143577576,\n",
       "    0.5684242248535156,\n",
       "    0.5199841856956482,\n",
       "    0.40980979800224304,\n",
       "    -0.5150115489959717,\n",
       "    1.2592676877975464,\n",
       "    -0.12191811203956604,\n",
       "    -1.027004599571228,\n",
       "    -0.003781434614211321,\n",
       "    -0.8390214443206787,\n",
       "    -1.0326690673828125,\n",
       "    0.24731391668319702,\n",
       "    -0.7815259099006653,\n",
       "    -0.8921517133712769,\n",
       "    0.35979753732681274,\n",
       "    0.05936841666698456,\n",
       "    0.9993947744369507,\n",
       "    -0.8151134848594666,\n",
       "    0.048883482813835144,\n",
       "    -0.31700438261032104,\n",
       "    -0.2848747968673706,\n",
       "    0.1806904822587967,\n",
       "    0.1379893273115158,\n",
       "    0.6218113303184509,\n",
       "    -0.014620290137827396,\n",
       "    0.6214461922645569,\n",
       "    -0.0413956418633461,\n",
       "    0.1457543969154358,\n",
       "    -0.6569600701332092,\n",
       "    0.2930200695991516,\n",
       "    0.04779818281531334,\n",
       "    -0.21674101054668427,\n",
       "    0.4749467968940735,\n",
       "    -0.4739801585674286,\n",
       "    0.4677651822566986,\n",
       "    -0.41603589057922363,\n",
       "    0.2516736686229706,\n",
       "    0.8790931105613708,\n",
       "    0.9218749403953552,\n",
       "    0.45595869421958923,\n",
       "    0.5427054166793823,\n",
       "    0.01837504468858242,\n",
       "    1.078136682510376,\n",
       "    -0.038446150720119476,\n",
       "    -0.07359596341848373,\n",
       "    -0.1716773808002472,\n",
       "    0.4625515937805176,\n",
       "    -0.034783896058797836,\n",
       "    0.16379404067993164,\n",
       "    -0.15190261602401733,\n",
       "    0.5264821648597717],\n",
       "   'dot_product': 1.3550143241882324},\n",
       "  {'ip_embedding': [0.12954458594322205,\n",
       "    0.5368351936340332,\n",
       "    0.15891918540000916,\n",
       "    0.3202747702598572,\n",
       "    -0.17780108749866486,\n",
       "    0.46272116899490356,\n",
       "    -0.05258076637983322,\n",
       "    0.16450151801109314,\n",
       "    -0.08526773750782013,\n",
       "    0.07353077828884125,\n",
       "    0.18846763670444489,\n",
       "    -0.07644607871770859,\n",
       "    -0.26706624031066895,\n",
       "    0.013724148273468018,\n",
       "    -0.18241924047470093,\n",
       "    0.45539605617523193,\n",
       "    0.2304222285747528,\n",
       "    0.18064112961292267,\n",
       "    -0.014392979443073273,\n",
       "    -0.11570227891206741,\n",
       "    0.07030221819877625,\n",
       "    0.6074551939964294,\n",
       "    0.06752970814704895,\n",
       "    0.1462244689464569,\n",
       "    -0.23091226816177368,\n",
       "    -0.39723291993141174,\n",
       "    0.3611762523651123,\n",
       "    0.174997478723526,\n",
       "    -0.030597031116485596,\n",
       "    0.6279662847518921,\n",
       "    0.10329292714595795,\n",
       "    0.04124872386455536,\n",
       "    0.4103583097457886,\n",
       "    0.23019056022167206,\n",
       "    0.24846500158309937,\n",
       "    0.11313149333000183,\n",
       "    -0.39348551630973816,\n",
       "    -0.061636462807655334,\n",
       "    -0.21913756430149078,\n",
       "    -0.29723069071769714,\n",
       "    0.1654263734817505,\n",
       "    0.05679713189601898,\n",
       "    -0.18790315091609955,\n",
       "    0.10869912803173065,\n",
       "    0.45233628153800964,\n",
       "    0.536412239074707,\n",
       "    0.1825025975704193,\n",
       "    0.5030864477157593,\n",
       "    -0.14884760975837708,\n",
       "    0.24430158734321594,\n",
       "    -0.2138414829969406,\n",
       "    0.39258038997650146,\n",
       "    0.005107022821903229,\n",
       "    0.3523680865764618,\n",
       "    -0.08415532112121582,\n",
       "    -0.1650916337966919,\n",
       "    -0.27663564682006836,\n",
       "    -0.17351624369621277,\n",
       "    0.21902620792388916,\n",
       "    -0.18906061351299286,\n",
       "    0.13498777151107788,\n",
       "    0.47075003385543823,\n",
       "    0.10787695646286011,\n",
       "    0.05939813703298569,\n",
       "    -0.11900615692138672,\n",
       "    0.04418167471885681,\n",
       "    0.0865713581442833,\n",
       "    0.18691758811473846,\n",
       "    0.1033775806427002,\n",
       "    0.15408936142921448,\n",
       "    0.3593882918357849,\n",
       "    0.21973244845867157,\n",
       "    -0.003810059279203415,\n",
       "    0.05766134709119797,\n",
       "    -0.021260283887386322,\n",
       "    0.06826731562614441,\n",
       "    -0.11420541256666183,\n",
       "    -0.12270444631576538,\n",
       "    -0.09479285776615143,\n",
       "    0.17767758667469025,\n",
       "    -0.2957823872566223,\n",
       "    0.23675712943077087,\n",
       "    0.021854601800441742,\n",
       "    0.1350599229335785,\n",
       "    0.6339633464813232,\n",
       "    0.20663459599018097,\n",
       "    -0.34153205156326294,\n",
       "    0.2676600217819214,\n",
       "    0.17617672681808472,\n",
       "    -0.11942446231842041,\n",
       "    0.22957447171211243,\n",
       "    -0.025803277269005775,\n",
       "    -0.06553274393081665,\n",
       "    0.1166069507598877,\n",
       "    0.06431508809328079,\n",
       "    0.43775245547294617,\n",
       "    1.0063729286193848,\n",
       "    -0.1380966305732727,\n",
       "    -0.42797431349754333,\n",
       "    -0.2923208773136139,\n",
       "    -0.33731111884117126,\n",
       "    0.2649521231651306,\n",
       "    -0.09892486035823822,\n",
       "    -0.22569113969802856,\n",
       "    -0.22934001684188843,\n",
       "    0.2025967687368393,\n",
       "    0.1080840528011322,\n",
       "    0.12325647473335266,\n",
       "    0.5143450498580933,\n",
       "    0.00014262646436691284,\n",
       "    0.36040252447128296,\n",
       "    0.11765411496162415,\n",
       "    0.29310256242752075,\n",
       "    0.07680977880954742,\n",
       "    -0.4027993381023407,\n",
       "    -0.27614933252334595,\n",
       "    -0.22020778059959412,\n",
       "    -0.027824312448501587,\n",
       "    -0.3809933662414551,\n",
       "    -0.08521860837936401,\n",
       "    0.6263195276260376,\n",
       "    0.15239565074443817,\n",
       "    0.0824812799692154,\n",
       "    -0.13329708576202393,\n",
       "    0.5343942642211914,\n",
       "    0.12015143036842346,\n",
       "    -0.29108500480651855,\n",
       "    -0.1284441351890564],\n",
       "   'entity_embedding': [-0.3737509250640869,\n",
       "    -0.4747692346572876,\n",
       "    -0.24574334919452667,\n",
       "    0.18705856800079346,\n",
       "    -0.3304366171360016,\n",
       "    -0.4308302700519562,\n",
       "    0.2199133336544037,\n",
       "    -0.027608094736933708,\n",
       "    0.2687079608440399,\n",
       "    -1.196541666984558,\n",
       "    0.32224640250205994,\n",
       "    0.2957972288131714,\n",
       "    0.2758448123931885,\n",
       "    -0.32475289702415466,\n",
       "    0.0967169925570488,\n",
       "    1.4826308488845825,\n",
       "    0.7156611084938049,\n",
       "    0.3332851231098175,\n",
       "    -0.3202745020389557,\n",
       "    -0.5832414031028748,\n",
       "    -0.2177414745092392,\n",
       "    -0.9555225968360901,\n",
       "    -0.23745547235012054,\n",
       "    0.17748072743415833,\n",
       "    -0.44699904322624207,\n",
       "    -0.2891116142272949,\n",
       "    1.6125109195709229,\n",
       "    0.05525659769773483,\n",
       "    -1.3951215744018555,\n",
       "    0.2140410840511322,\n",
       "    -0.6756012439727783,\n",
       "    -0.715580940246582,\n",
       "    0.9535748958587646,\n",
       "    1.6319409608840942,\n",
       "    0.2901383936405182,\n",
       "    -0.11660527437925339,\n",
       "    -0.21687930822372437,\n",
       "    -0.5033085942268372,\n",
       "    -0.567712664604187,\n",
       "    0.4162905514240265,\n",
       "    -0.1301749050617218,\n",
       "    -1.0371949672698975,\n",
       "    -0.32867079973220825,\n",
       "    0.8498659133911133,\n",
       "    -0.6611577272415161,\n",
       "    1.2216216325759888,\n",
       "    0.8177437782287598,\n",
       "    0.7861708402633667,\n",
       "    0.5726208090782166,\n",
       "    -0.9734963178634644,\n",
       "    0.3677035868167877,\n",
       "    0.48776623606681824,\n",
       "    0.3810621500015259,\n",
       "    0.7377263903617859,\n",
       "    -0.35936906933784485,\n",
       "    -0.3546881079673767,\n",
       "    -0.8438427448272705,\n",
       "    -0.23446102440357208,\n",
       "    -0.03597700223326683,\n",
       "    -0.1058337613940239,\n",
       "    -0.7594379782676697,\n",
       "    -0.5468219518661499,\n",
       "    -0.9649543762207031,\n",
       "    -0.2334223985671997,\n",
       "    0.26607102155685425,\n",
       "    -0.0737951323390007,\n",
       "    0.06703555583953857,\n",
       "    -0.5564695000648499,\n",
       "    -0.12567342817783356,\n",
       "    0.13055892288684845,\n",
       "    0.2218342423439026,\n",
       "    -0.05155021697282791,\n",
       "    0.16485251486301422,\n",
       "    0.78717041015625,\n",
       "    -0.24643178284168243,\n",
       "    0.7738814353942871,\n",
       "    0.6771656274795532,\n",
       "    -1.1576181650161743,\n",
       "    0.5662741661071777,\n",
       "    0.5824176073074341,\n",
       "    0.21199443936347961,\n",
       "    0.6903084516525269,\n",
       "    0.3253461420536041,\n",
       "    0.7500134110450745,\n",
       "    0.2902674973011017,\n",
       "    0.04423516243696213,\n",
       "    0.842370867729187,\n",
       "    -0.6141182780265808,\n",
       "    0.4994626045227051,\n",
       "    -0.7024169564247131,\n",
       "    -0.8690761923789978,\n",
       "    -0.4523239731788635,\n",
       "    -1.498144268989563,\n",
       "    -1.0789995193481445,\n",
       "    -0.4062109589576721,\n",
       "    0.019209831953048706,\n",
       "    0.4879585802555084,\n",
       "    -1.4681527614593506,\n",
       "    -0.9240540862083435,\n",
       "    0.7285930514335632,\n",
       "    -0.39669549465179443,\n",
       "    0.3718036115169525,\n",
       "    -0.0021687850821763277,\n",
       "    -0.31509312987327576,\n",
       "    0.2729984521865845,\n",
       "    -0.43483513593673706,\n",
       "    -1.1093122959136963,\n",
       "    -0.46659234166145325,\n",
       "    0.6202253699302673,\n",
       "    1.4016320705413818,\n",
       "    -0.021779490634799004,\n",
       "    0.8954707980155945,\n",
       "    -1.0082149505615234,\n",
       "    -0.2612198293209076,\n",
       "    -0.7121738791465759,\n",
       "    -0.28310006856918335,\n",
       "    -0.2272709757089615,\n",
       "    0.7420648336410522,\n",
       "    0.728194534778595,\n",
       "    0.6882469654083252,\n",
       "    -0.24301277101039886,\n",
       "    0.6600844860076904,\n",
       "    0.5360656380653381,\n",
       "    -1.0834304094314575,\n",
       "    0.2170678824186325,\n",
       "    -0.8296200633049011,\n",
       "    -0.6549420356750488,\n",
       "    -0.7491257190704346],\n",
       "   'dot_product': 4.033393383026123},\n",
       "  {'ip_embedding': [0.3963010907173157,\n",
       "    0.24212327599525452,\n",
       "    0.3720831871032715,\n",
       "    -0.1695125848054886,\n",
       "    0.059113189578056335,\n",
       "    0.36018437147140503,\n",
       "    0.00574386864900589,\n",
       "    0.07598613202571869,\n",
       "    -0.19386246800422668,\n",
       "    -0.10630981624126434,\n",
       "    0.04112395644187927,\n",
       "    0.06170573830604553,\n",
       "    -0.1608000099658966,\n",
       "    -0.10520755499601364,\n",
       "    -0.17964892089366913,\n",
       "    -0.03153429925441742,\n",
       "    -0.6867263913154602,\n",
       "    -0.0782809853553772,\n",
       "    -0.26639071106910706,\n",
       "    0.015044104307889938,\n",
       "    0.6231657266616821,\n",
       "    0.5102109313011169,\n",
       "    -0.19623830914497375,\n",
       "    0.4301297962665558,\n",
       "    0.31715822219848633,\n",
       "    -0.232630655169487,\n",
       "    -0.8320136666297913,\n",
       "    0.3168967366218567,\n",
       "    0.1874598264694214,\n",
       "    0.766497015953064,\n",
       "    0.24557054042816162,\n",
       "    0.2593652009963989,\n",
       "    0.18776516616344452,\n",
       "    0.04369691014289856,\n",
       "    0.14921924471855164,\n",
       "    0.13058409094810486,\n",
       "    -0.5227522253990173,\n",
       "    0.04469366744160652,\n",
       "    -0.1583307981491089,\n",
       "    0.8804988861083984,\n",
       "    0.2669506072998047,\n",
       "    0.48039817810058594,\n",
       "    -0.2208375334739685,\n",
       "    0.11741194128990173,\n",
       "    0.16046682000160217,\n",
       "    -0.16914181411266327,\n",
       "    0.010906655341386795,\n",
       "    0.41692906618118286,\n",
       "    0.049657292664051056,\n",
       "    -0.12685127556324005,\n",
       "    0.2908565402030945,\n",
       "    0.5343525409698486,\n",
       "    0.02244197577238083,\n",
       "    0.03505724295973778,\n",
       "    0.45126140117645264,\n",
       "    -0.04801732674241066,\n",
       "    0.09807116538286209,\n",
       "    0.8811372518539429,\n",
       "    0.4831162691116333,\n",
       "    0.15038003027439117,\n",
       "    -0.30036795139312744,\n",
       "    -0.42230385541915894,\n",
       "    -0.1938069760799408,\n",
       "    -0.06918640434741974,\n",
       "    0.022014163434505463,\n",
       "    -0.019885271787643433,\n",
       "    -0.11831048130989075,\n",
       "    0.3502669632434845,\n",
       "    0.7254056334495544,\n",
       "    0.03368467092514038,\n",
       "    0.227310910820961,\n",
       "    -0.11463708430528641,\n",
       "    -0.0893886536359787,\n",
       "    -0.07494094967842102,\n",
       "    -0.11387757956981659,\n",
       "    -0.13017170131206512,\n",
       "    0.13528838753700256,\n",
       "    0.060215748846530914,\n",
       "    -0.08994725346565247,\n",
       "    -0.14704330265522003,\n",
       "    0.1107727587223053,\n",
       "    0.039129842072725296,\n",
       "    0.028164103627204895,\n",
       "    -0.31623896956443787,\n",
       "    0.5722837448120117,\n",
       "    0.09120456129312515,\n",
       "    0.4541701376438141,\n",
       "    0.5520740747451782,\n",
       "    -0.07614506781101227,\n",
       "    0.10089616477489471,\n",
       "    0.14719009399414062,\n",
       "    -0.6166157722473145,\n",
       "    0.07045522332191467,\n",
       "    1.0654466152191162,\n",
       "    0.7207898497581482,\n",
       "    -0.12965261936187744,\n",
       "    0.13189329206943512,\n",
       "    0.34677475690841675,\n",
       "    0.00210392102599144,\n",
       "    -0.4966444969177246,\n",
       "    0.6803810596466064,\n",
       "    -0.1058412715792656,\n",
       "    -0.06913739442825317,\n",
       "    0.147075355052948,\n",
       "    0.2321513146162033,\n",
       "    -0.013616424053907394,\n",
       "    0.05792475864291191,\n",
       "    0.30277425050735474,\n",
       "    -0.4814375042915344,\n",
       "    0.2853860855102539,\n",
       "    0.4532918632030487,\n",
       "    0.06585599482059479,\n",
       "    0.36826732754707336,\n",
       "    0.12985587120056152,\n",
       "    -0.13495442271232605,\n",
       "    0.20003408193588257,\n",
       "    -0.20919442176818848,\n",
       "    0.03669236600399017,\n",
       "    -0.06054726615548134,\n",
       "    -0.42169779539108276,\n",
       "    0.15896977484226227,\n",
       "    0.09926028549671173,\n",
       "    0.4721844792366028,\n",
       "    0.1929541528224945,\n",
       "    -0.10329069197177887,\n",
       "    -0.09517654776573181,\n",
       "    -0.2243393212556839,\n",
       "    0.2593485713005066],\n",
       "   'entity_embedding': [0.036232173442840576,\n",
       "    -0.36496248841285706,\n",
       "    -0.16696500778198242,\n",
       "    -0.29749077558517456,\n",
       "    -0.33495017886161804,\n",
       "    -0.2229176163673401,\n",
       "    0.11536576598882675,\n",
       "    -0.9013962745666504,\n",
       "    -0.5582156181335449,\n",
       "    1.7669188976287842,\n",
       "    0.39703288674354553,\n",
       "    -0.49209511280059814,\n",
       "    -0.12323556840419769,\n",
       "    0.13705545663833618,\n",
       "    -1.8354501724243164,\n",
       "    1.5817605257034302,\n",
       "    -0.5052080154418945,\n",
       "    -0.8587211966514587,\n",
       "    0.47352930903434753,\n",
       "    -0.16342143714427948,\n",
       "    0.3783601224422455,\n",
       "    -0.15063105523586273,\n",
       "    0.3668566346168518,\n",
       "    -0.20582365989685059,\n",
       "    0.5984835028648376,\n",
       "    0.018063299357891083,\n",
       "    -0.04344867542386055,\n",
       "    -0.15536637604236603,\n",
       "    -0.4608319103717804,\n",
       "    0.4971690773963928,\n",
       "    0.772587776184082,\n",
       "    -1.050729513168335,\n",
       "    0.21309597790241241,\n",
       "    0.5429162383079529,\n",
       "    -0.2894017696380615,\n",
       "    -0.21875351667404175,\n",
       "    -0.7818527221679688,\n",
       "    0.6416674256324768,\n",
       "    0.9240373969078064,\n",
       "    -0.2679501473903656,\n",
       "    -0.0324026383459568,\n",
       "    -0.42231485247612,\n",
       "    0.45106831192970276,\n",
       "    1.2358267307281494,\n",
       "    -1.079267144203186,\n",
       "    -0.10199779272079468,\n",
       "    0.9996285438537598,\n",
       "    -0.08036740124225616,\n",
       "    0.14549848437309265,\n",
       "    -0.2569458782672882,\n",
       "    0.3247007429599762,\n",
       "    0.38715317845344543,\n",
       "    0.6030965447425842,\n",
       "    0.22615671157836914,\n",
       "    -0.5409250855445862,\n",
       "    1.4237924814224243,\n",
       "    0.05572928488254547,\n",
       "    1.0008479356765747,\n",
       "    -0.1719174087047577,\n",
       "    -1.0967110395431519,\n",
       "    -0.24846471846103668,\n",
       "    -0.3985668420791626,\n",
       "    -0.0753609836101532,\n",
       "    -0.5131237506866455,\n",
       "    -0.44797593355178833,\n",
       "    -0.23857347667217255,\n",
       "    0.00645877979695797,\n",
       "    0.24614986777305603,\n",
       "    0.4949055314064026,\n",
       "    0.19013623893260956,\n",
       "    -0.45812469720840454,\n",
       "    0.5350602865219116,\n",
       "    0.294256329536438,\n",
       "    -0.33965569734573364,\n",
       "    -0.8032093048095703,\n",
       "    0.2904661297798157,\n",
       "    1.1973116397857666,\n",
       "    -0.5942168235778809,\n",
       "    -0.05020301043987274,\n",
       "    0.4029175341129303,\n",
       "    -0.02360324189066887,\n",
       "    0.05813378840684891,\n",
       "    0.715019941329956,\n",
       "    0.18219485878944397,\n",
       "    0.18886691331863403,\n",
       "    0.10325690358877182,\n",
       "    -0.1682140976190567,\n",
       "    1.356516718864441,\n",
       "    0.6087813377380371,\n",
       "    -0.5011938214302063,\n",
       "    -0.5339759588241577,\n",
       "    -0.17676450312137604,\n",
       "    -1.0542200803756714,\n",
       "    -0.014027166180312634,\n",
       "    -0.3617990016937256,\n",
       "    -0.19894841313362122,\n",
       "    -1.8049665689468384,\n",
       "    -1.573879599571228,\n",
       "    -0.7408590316772461,\n",
       "    0.4393894374370575,\n",
       "    0.8339792490005493,\n",
       "    0.16120515763759613,\n",
       "    -0.2193717062473297,\n",
       "    -0.3102317154407501,\n",
       "    0.5507173538208008,\n",
       "    -1.6429827213287354,\n",
       "    0.01880108006298542,\n",
       "    0.6464909911155701,\n",
       "    -1.01433527469635,\n",
       "    0.7044556736946106,\n",
       "    1.1099404096603394,\n",
       "    1.2158465385437012,\n",
       "    1.316286325454712,\n",
       "    0.692371129989624,\n",
       "    -0.4933314323425293,\n",
       "    0.34971073269844055,\n",
       "    0.6691073775291443,\n",
       "    0.6464257836341858,\n",
       "    -0.33356747031211853,\n",
       "    -0.12347407639026642,\n",
       "    -0.5868409872055054,\n",
       "    -0.4473250210285187,\n",
       "    -0.14246784150600433,\n",
       "    0.2907085120677948,\n",
       "    0.32233554124832153,\n",
       "    -0.4389541447162628,\n",
       "    -0.5134966373443604,\n",
       "    0.043318603187799454],\n",
       "   'dot_product': 3.846628427505493}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.accept = 'application/json; verbose=True'\n",
    "predictor.predict(inference_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Anomaly Scores\n",
    "----\n",
    "The `dot_product` output of the model provides a good measure of how compatible an IP address and online resource are. However, the range of the dot_product is unbounded. This means to be able to consider an event as anomolous we need to define a threshold. Such that when we score an event, if the dot_product is above the threshold we can flag the behavior as anomolous.However, picking a threshold can be more of an art, and a good threshold depends on the specifics of your problem and dataset. \n",
    "\n",
    "In the following section, we show how to pick a simple threshold by comparing the score distributions between known normal and malicious traffic:\n",
    "1. We construct a test set of 'Normal' traffic;\n",
    "2. Inject 'Malicious' traffic into the dataset;\n",
    "3. Plot the distribution of dot_product scores for the model on 'Normal' trafic and the 'Malicious' traffic.\n",
    "3. Select a threshold value which separates the normal distribution from the malicious traffic threshold. This value is based on your false-positive tolerance.\n",
    "\n",
    "### 1. Construct 'Normal' Traffic Dataset\n",
    "\n",
    "We previously [created a test set](#3.-Create-training-and-test-dataset) from our simulated Apache access logs dataset. We use this test dataset as the 'Normal' traffic in the test case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_63</td>\n",
       "      <td>103.85.159.252</td>\n",
       "      <td>2018-11-12 00:32:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>user_63</td>\n",
       "      <td>103.200.216.101</td>\n",
       "      <td>2018-11-13 07:44:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>user_63</td>\n",
       "      <td>103.201.131.201</td>\n",
       "      <td>2018-11-12 12:15:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>user_63</td>\n",
       "      <td>103.201.24.207</td>\n",
       "      <td>2018-11-13 22:32:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>user_63</td>\n",
       "      <td>103.201.128.58</td>\n",
       "      <td>2018-11-13 11:19:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user       ip_address           timestamp\n",
       "0   user_63   103.85.159.252 2018-11-12 00:32:42\n",
       "5   user_63  103.200.216.101 2018-11-13 07:44:59\n",
       "11  user_63  103.201.131.201 2018-11-12 12:15:48\n",
       "12  user_63   103.201.24.207 2018-11-13 22:32:43\n",
       "14  user_63   103.201.128.58 2018-11-13 11:19:38"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Inject Malicious Traffic\n",
    "If we had a dataset with enough real malicious activity, we would use that to determine a good threshold. Those are hard to come by. So instead, we simulate malicious web traffic that mimics a realistic attack scenario. \n",
    "\n",
    "We take a set of user accounts from the test set and randomly generate IP addresses. The users should not have used these IP addresses during training. This simulates an attacker logging in to a user account without knowledge of their IP history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from generate_data import draw_ip\n",
    "\n",
    "# We only need the dot product. Let's reset the predictor output type.\n",
    "predictor.accept = 'application/json; verbose=False'\n",
    "\n",
    "\n",
    "def score_ip_insights(predictor, df):\n",
    "    \n",
    "    def get_score(result):\n",
    "        \"\"\"Return the negative to the dot product of the predictions from the model.\"\"\"\n",
    "        return [-prediction[\"dot_product\"] for prediction in result[\"predictions\"]]\n",
    "    \n",
    "    df = df[['user', 'ip_address']]\n",
    "    result = predictor.predict(df.values)\n",
    "    return get_score(result)\n",
    "\n",
    "\n",
    "def create_test_case(train_df, test_df, num_samples, attack_freq):\n",
    "    \"\"\"Creates a test case from provided train and test data frames. \n",
    "    \n",
    "    This generates test case for accounts that are both in training and testing data sets.\n",
    "\n",
    "    :param train_df: (panda.DataFrame with columns ['user', 'ip_address']) training DataFrame\n",
    "    :param test_df: (panda.DataFrame with columns ['user', 'ip_address']) testing DataFrame\n",
    "    :param num_samples: (int) number of test samples to use\n",
    "    :param attack_freq: (float) the ratio of negative_samples:positive_samples to generate for test case \n",
    "    :return: DataFrame with both good and bad traffic, with labels\n",
    "    \"\"\"\n",
    "    # Get all possible accounts. The IP Insights model can only make predictions on users it has seen in training\n",
    "    # Therefore, filter the test dataset for unseen accounts, as their results will not mean anything.\n",
    "    valid_accounts = set(train_df['user'])\n",
    "    valid_test_df = test_df[test_df['user'].isin(valid_accounts)]\n",
    "\n",
    "    good_traffic = valid_test_df.sample(num_samples, replace=False)\n",
    "    good_traffic = good_traffic[['user', 'ip_address']]\n",
    "    good_traffic['label'] = 0\n",
    "\n",
    "    # Generate malicious traffic\n",
    "    num_bad_traffic = int(num_samples * attack_freq)\n",
    "    bad_traffic_accounts = np.random.choice(list(valid_accounts), size=num_bad_traffic, replace=True) \n",
    "    bad_traffic_ips = [draw_ip() for i in range(num_bad_traffic)]\n",
    "    bad_traffic = pd.DataFrame({'user': bad_traffic_accounts, 'ip_address': bad_traffic_ips})\n",
    "    bad_traffic['label'] = 1\n",
    "    \n",
    "    # All traffic labels are: 0 for good traffic; 1 for bad traffic. \n",
    "    all_traffic = good_traffic.append(bad_traffic)\n",
    "\n",
    "    return all_traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1016954</th>\n",
       "      <td>user_3059</td>\n",
       "      <td>189.203.140.201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770704</th>\n",
       "      <td>user_5690</td>\n",
       "      <td>109.67.248.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779165</th>\n",
       "      <td>user_8850</td>\n",
       "      <td>116.72.6.156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380250</th>\n",
       "      <td>user_1174</td>\n",
       "      <td>181.59.94.165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735792</th>\n",
       "      <td>user_5641</td>\n",
       "      <td>161.217.193.201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user       ip_address  label\n",
       "1016954  user_3059  189.203.140.201      0\n",
       "1770704  user_5690    109.67.248.97      0\n",
       "2779165  user_8850     116.72.6.156      0\n",
       "380250   user_1174    181.59.94.165      0\n",
       "1735792  user_5641  161.217.193.201      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_SAMPLES = 100000\n",
    "test_case = create_test_case(train_df, test_df, num_samples=NUM_SAMPLES, attack_freq=1)\n",
    "test_case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case_scores = score_ip_insights(predictor, test_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plot Distribution\n",
    "\n",
    "Now, we plot the distribution of scores. Looking at this distribution will inform us on where we can set a good threshold, based on our risk tolerance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n, x = np.histogram(test_case_scores[:NUM_SAMPLES], bins=100, density=True)\n",
    "plt.plot(x[1:], n)\n",
    "\n",
    "n, x = np.histogram(test_case_scores[NUM_SAMPLES:], bins=100, density=True)\n",
    "plt.plot(x[1:], n)\n",
    "\n",
    "plt.legend([\"Normal\", \"Random IP\"])\n",
    "plt.xlabel(\"IP Insights Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Selecting a Good Threshold\n",
    "\n",
    "As we see in the figure above, there is a clear separation between normal traffic and random traffic. \n",
    "We could select a threshold depending on the application.\n",
    "\n",
    "- If we were working with low impact decisions, such as whether to ask for another factor or authentication during login, we could use a `threshold = 0.0`. This would result in catching more true-positives, at the cost of more false-positives. \n",
    "\n",
    "- If our decision system were more sensitive to false positives, we could choose a larger threshold, such as `threshold = 10.0`. That way if we were sending the flagged cases to manual investigation, we would have a higher confidence that the acitivty was suspicious. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When threshold is set to: 0.0\n",
      "Total of 102424 flagged cases\n",
      "Total of 98137 flagged cases are true positives\n",
      "True Positive Rate: 0.9581445754901196\n",
      "Recall: 0.98137\n",
      "Precision: 0.9581445754901196\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.0\n",
    "\n",
    "flagged_cases = test_case[np.array(test_case_scores) > threshold]\n",
    "\n",
    "num_flagged_cases = len(flagged_cases)\n",
    "num_true_positives = len(flagged_cases[flagged_cases['label'] == 1])\n",
    "num_false_positives = len(flagged_cases[flagged_cases['label'] == 0])\n",
    "num_all_positives = len(test_case.loc[test_case['label'] == 1])\n",
    "\n",
    "print(\"When threshold is set to: {}\".format(threshold))\n",
    "print(\"Total of {} flagged cases\".format(num_flagged_cases))\n",
    "print(\"Total of {} flagged cases are true positives\".format(num_true_positives))\n",
    "print(\"True Positive Rate: {}\".format(num_true_positives/float(num_flagged_cases)))\n",
    "print(\"Recall: {}\".format(num_true_positives/float(num_all_positives)))\n",
    "print(\"Precision: {}\".format(num_true_positives/float(num_flagged_cases)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epilogue\n",
    "----\n",
    "\n",
    "In this notebook, we have showed how to configure the basic training, deployment, and usage of the Amazon SageMaker IP Insights algorithm. All SageMaker algorithms come with support for two additional services that make optimizing and using the algorithm that much easier: Automatic Model Tuning and Batch Transform service. \n",
    "\n",
    "\n",
    "### Amazon SageMaker Automatic Model Tuning\n",
    "The results above were based on using the default hyperparameters of the SageMaker IP Insights algorithm. If we wanted to improve the model's performance even more, we can use [Amazon SageMaker Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) to automate the process of finding the hyperparameters. \n",
    "\n",
    "#### Validation Dataset\n",
    "Previously, we separated our dataset into a training and test set to validate the performance of a single IP Insights model. However, when we do model tuning, we train many IP Insights models in parallel. If we were to use the same test dataset to select the best model, we bias our model selection such that we don't know if we selected the best model in general, or just the best model for that particular dateaset. \n",
    "\n",
    "Therefore, we need to separate our test set into a validation dataset and a test dataset. The validation dataset is used for model selection. Then once we pick the model with the best performance, we evaluate it the winner on a test set just as before. \n",
    "\n",
    "#### Validation Metrics\n",
    "For SageMaker Automatic Model Tuning to work, we need an objective metric which determines the performance of the model we want to optimize. Because SageMaker IP Insights is an usupervised algorithm, we do not have a clearly defined metric for performance (such as percentage of fraudulent events discovered). \n",
    "\n",
    "We allow the user to provide a validation set of sample data (same format as training data bove) through the `validation` channel. We then fix the negative sampling strategy to use `random_negative_sampling_rate=1` and `shuffled_negative_sampling_rate=0` and generate a validation dataset by assigning corresponding labels to the real and simulated data. We then calculate the model's `descriminator_auc` metric. We do this by taking the model's predicted labels and the 'true' simulated labels and compute the Area Under ROC Curve (AUC) on the model's performance.\n",
    "\n",
    "We set up the `HyperParameterTuner` to maximize the `discriminator_auc` on the validation dataset. We also need to set the search space for the hyperparameters. We give recommended ranges for the hyperparmaeters in the [Amazon SageMaker IP Insights (Hyperparameters)](https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights-hyperparameters.html) documentation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                  934535\n",
       "unique                 252208\n",
       "top       2018-11-12 19:13:44\n",
       "freq                       15\n",
       "first     2018-11-11 00:00:01\n",
       "last      2018-11-14 00:00:00\n",
       "Name: timestamp, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['timestamp'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set we constructed above spans 3 days. We reserve the first day as the validation set and the subsequent two days for the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_partition = datetime(2018, 11, 13, tzinfo=pytz.FixedOffset(0)) if num_time_zones > 1 else datetime(2018, 11, 13)\n",
    "\n",
    "validation_df = test_df[test_df['timestamp'] < time_partition]\n",
    "test_df = test_df[test_df['timestamp'] >= time_partition]\n",
    "\n",
    "valid_data = validation_df.to_csv(index=False, header=False, columns=['user', 'ip_address'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then upload the validation data to S3 and specify it as the validation channel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data has been uploaded to: s3://fab-sagemaker/ipinsights-weblogs/validation/valid.csv\n"
     ]
    }
   ],
   "source": [
    "# Upload data to S3 key\n",
    "validation_data_file = 'valid.csv'\n",
    "key = os.path.join(prefix, 'validation', validation_data_file)\n",
    "boto3.resource('s3').Bucket(bucket).Object(key).put(Body=valid_data)\n",
    "s3_valid_data = 's3://{}/{}'.format(bucket, key)\n",
    "\n",
    "print('Validation data has been uploaded to: {}'.format(s3_valid_data))\n",
    "\n",
    "# Configure SageMaker IP Insights Input Channels\n",
    "input_data = {\n",
    "    'train': s3_train_data,\n",
    "    'validation': s3_valid_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter\n",
    "\n",
    "# Configure HyperparameterTuner\n",
    "ip_insights_tuner = HyperparameterTuner(\n",
    "    estimator=ip_insights,  # previously-configured Estimator object\n",
    "    objective_metric_name='validation:discriminator_auc',\n",
    "    hyperparameter_ranges={'vector_dim': IntegerParameter(64, 1024)},\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=2)\n",
    "\n",
    "# Start hyperparameter tuning job\n",
    "ip_insights_tuner.fit(input_data, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................................................................................................................................................................................................................................................!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector_dim</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170.0</td>\n",
       "      <td>ipinsights-201003-1420-004-18db41b2</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.991297</td>\n",
       "      <td>2020-10-03 14:38:13+00:00</td>\n",
       "      <td>2020-10-03 14:47:24+00:00</td>\n",
       "      <td>551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119.0</td>\n",
       "      <td>ipinsights-201003-1420-003-ee581f8c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.991306</td>\n",
       "      <td>2020-10-03 14:38:02+00:00</td>\n",
       "      <td>2020-10-03 14:47:31+00:00</td>\n",
       "      <td>569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>462.0</td>\n",
       "      <td>ipinsights-201003-1420-002-01cf4c71</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.990167</td>\n",
       "      <td>2020-10-03 14:23:45+00:00</td>\n",
       "      <td>2020-10-03 14:33:30+00:00</td>\n",
       "      <td>585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264.0</td>\n",
       "      <td>ipinsights-201003-1420-001-98052dbb</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.991193</td>\n",
       "      <td>2020-10-03 14:23:20+00:00</td>\n",
       "      <td>2020-10-03 14:33:26+00:00</td>\n",
       "      <td>606.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vector_dim                      TrainingJobName TrainingJobStatus  \\\n",
       "0       170.0  ipinsights-201003-1420-004-18db41b2         Completed   \n",
       "1       119.0  ipinsights-201003-1420-003-ee581f8c         Completed   \n",
       "2       462.0  ipinsights-201003-1420-002-01cf4c71         Completed   \n",
       "3       264.0  ipinsights-201003-1420-001-98052dbb         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "0             0.991297 2020-10-03 14:38:13+00:00 2020-10-03 14:47:24+00:00   \n",
       "1             0.991306 2020-10-03 14:38:02+00:00 2020-10-03 14:47:31+00:00   \n",
       "2             0.990167 2020-10-03 14:23:45+00:00 2020-10-03 14:33:30+00:00   \n",
       "3             0.991193 2020-10-03 14:23:20+00:00 2020-10-03 14:33:26+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                       551.0  \n",
       "1                       569.0  \n",
       "2                       585.0  \n",
       "3                       606.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait for all the jobs to finish\n",
    "ip_insights_tuner.wait()\n",
    "\n",
    "# Visualize training job results\n",
    "ip_insights_tuner.analytics().dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 14:47:31 Starting - Preparing the instances for training\n",
      "2020-10-03 14:47:31 Downloading - Downloading input data\n",
      "2020-10-03 14:47:31 Training - Training image download completed. Training in progress.\n",
      "2020-10-03 14:47:31 Uploading - Uploading generated training model\n",
      "2020-10-03 14:47:31 Completed - Training job completed\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:18 INFO 139806301841216] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'random_negative_sampling_rate': u'1', u'shuffled_negative_sampling_rate': u'1', u'batch_metrics_publish_interval': u'1000', u'num_entity_vectors': u'100000', u'_tuning_objective_metric': u'', u'vector_dim': u'128', u'learning_rate': u'0.001', u'epochs': u'10', u'_num_gpus': u'auto', u'weight_decay': u'0.00001', u'_kvstore': u'auto_gpu', u'_num_kv_servers': u'auto', u'mini_batch_size': u'5000', u'_log_level': u'info', u'num_ip_encoder_layers': u'1'}\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:18 INFO 139806301841216] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'random_negative_sampling_rate': u'5', u'num_entity_vectors': u'20000', u'_tuning_objective_metric': u'validation:discriminator_auc', u'vector_dim': u'119', u'learning_rate': u'0.01', u'epochs': u'5', u'mini_batch_size': u'1000'}\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:18 INFO 139806301841216] Final configuration: {u'random_negative_sampling_rate': u'5', u'num_entity_vectors': u'20000', u'_tuning_objective_metric': u'validation:discriminator_auc', u'learning_rate': u'0.01', u'epochs': u'5', u'_num_kv_servers': u'auto', u'mini_batch_size': u'1000', u'weight_decay': u'0.00001', u'num_ip_encoder_layers': u'1', u'shuffled_negative_sampling_rate': u'1', u'batch_metrics_publish_interval': u'1000', u'vector_dim': u'119', u'_log_level': u'info', u'_num_gpus': u'auto', u'_kvstore': u'auto_gpu'}\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:18 WARNING 139806301841216] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:18 INFO 139806301841216] nvidia-smi took: 0.050342798233 secs to identify 1 gpus\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:18 INFO 139806301841216] Using default worker.\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:18 INFO 139806301841216] Loaded iterator creator application/x-ndarray for content type ('application/x-ndarray', '1.0')\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:18 INFO 139806301841216] Loaded iterator creator text/csv for content type ('text/csv', '1.0')\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:18 INFO 139806301841216] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 17.548084259033203, \"sum\": 17.548084259033203, \"min\": 17.548084259033203}}, \"EndTime\": 1601735958.627291, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601735958.609519}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1601735958.627461, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601735958.627425}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:18 INFO 139806301841216] Create Store: device\u001b[0m\n",
      "\u001b[34m[14:39:24] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_10.1.x.1334.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[14:39:24] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_10.1.x.1334.0/AL2012/generic-flavor/src/src/operator/././../common/utils.h:450: Optimizer with lazy_update = True detected. Be aware that lazy update with row_sparse gradient is different from standard update, and may lead to different empirical results. See https://mxnet.incubator.apache.org/api/python/optimization/optimization.html for more details.\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:24 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_accuracy <score>=0.51\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:24 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_cross_entropy <loss>=0.693081176758\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:30 INFO 139806301841216] Epoch[0] Batch [1000]#011Speed: 167150.65 samples/sec#011binary_classification_accuracy=0.925915#011binary_classification_cross_entropy=0.201506\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:30 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=1000 train binary_classification_accuracy <score>=0.925915084915\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:30 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=1000 train binary_classification_cross_entropy <loss>=0.201505941332\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:35 INFO 139806301841216] Epoch[0] Batch [2000]#011Speed: 171633.98 samples/sec#011binary_classification_accuracy=0.948605#011binary_classification_cross_entropy=0.150445\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:35 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=2000 train binary_classification_accuracy <score>=0.948604697651\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:35 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=2000 train binary_classification_cross_entropy <loss>=0.150445379577\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:41 INFO 139806301841216] Epoch[0] Batch [3000]#011Speed: 171871.51 samples/sec#011binary_classification_accuracy=0.958276#011binary_classification_cross_entropy=0.127823\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:41 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=3000 train binary_classification_accuracy <score>=0.958276241253\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:41 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=3000 train binary_classification_cross_entropy <loss>=0.127823439363\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:47 INFO 139806301841216] Epoch[0] Batch [4000]#011Speed: 172820.37 samples/sec#011binary_classification_accuracy=0.963893#011binary_classification_cross_entropy=0.114637\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:47 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=4000 train binary_classification_accuracy <score>=0.963892776806\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:47 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=4000 train binary_classification_cross_entropy <loss>=0.114636619163\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:53 INFO 139806301841216] Epoch[0] Batch [5000]#011Speed: 171607.03 samples/sec#011binary_classification_accuracy=0.967556#011binary_classification_cross_entropy=0.105950\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:53 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=5000 train binary_classification_accuracy <score>=0.967556288742\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:53 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=5000 train binary_classification_cross_entropy <loss>=0.105949951615\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:59 INFO 139806301841216] Epoch[0] Batch [6000]#011Speed: 172455.39 samples/sec#011binary_classification_accuracy=0.970124#011binary_classification_cross_entropy=0.099833\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:59 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=6000 train binary_classification_accuracy <score>=0.970123812698\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:39:59 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=6000 train binary_classification_cross_entropy <loss>=0.0998327950165\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:05 INFO 139806301841216] Epoch[0] Batch [7000]#011Speed: 172149.90 samples/sec#011binary_classification_accuracy=0.972092#011binary_classification_cross_entropy=0.095152\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:05 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=7000 train binary_classification_accuracy <score>=0.972091986859\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:05 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=7000 train binary_classification_cross_entropy <loss>=0.0951521065381\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:10 INFO 139806301841216] Epoch[0] Batch [8000]#011Speed: 173130.85 samples/sec#011binary_classification_accuracy=0.973633#011binary_classification_cross_entropy=0.091390\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:10 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=8000 train binary_classification_accuracy <score>=0.973633170854\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:10 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=8000 train binary_classification_cross_entropy <loss>=0.0913901773512\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:16 INFO 139806301841216] Epoch[0] Batch [9000]#011Speed: 172667.82 samples/sec#011binary_classification_accuracy=0.974856#011binary_classification_cross_entropy=0.088456\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:16 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=9000 train binary_classification_accuracy <score>=0.974856460393\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:16 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=9000 train binary_classification_cross_entropy <loss>=0.0884555232155\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:22 INFO 139806301841216] Epoch[0] Batch [10000]#011Speed: 172282.69 samples/sec#011binary_classification_accuracy=0.975864#011binary_classification_cross_entropy=0.085951\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:22 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=10000 train binary_classification_accuracy <score>=0.975863713629\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:22 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=10000 train binary_classification_cross_entropy <loss>=0.0859507037524\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:28 INFO 139806301841216] Epoch[0] Batch [11000]#011Speed: 172105.49 samples/sec#011binary_classification_accuracy=0.976712#011binary_classification_cross_entropy=0.083886\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:28 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=11000 train binary_classification_accuracy <score>=0.976711753477\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:28 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=11000 train binary_classification_cross_entropy <loss>=0.0838858169682\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:34 INFO 139806301841216] Epoch[0] Batch [12000]#011Speed: 171614.87 samples/sec#011binary_classification_accuracy=0.977429#011binary_classification_cross_entropy=0.082100\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:34 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=12000 train binary_classification_accuracy <score>=0.977429130906\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:34 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=12000 train binary_classification_cross_entropy <loss>=0.0821001496531\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:39 INFO 139806301841216] Epoch[0] Batch [13000]#011Speed: 172103.15 samples/sec#011binary_classification_accuracy=0.978025#011binary_classification_cross_entropy=0.080663\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:39 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=13000 train binary_classification_accuracy <score>=0.978025382663\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:39 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=13000 train binary_classification_cross_entropy <loss>=0.080663488397\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:45 INFO 139806301841216] Epoch[0] Batch [14000]#011Speed: 173361.75 samples/sec#011binary_classification_accuracy=0.978573#011binary_classification_cross_entropy=0.079345\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:45 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=14000 train binary_classification_accuracy <score>=0.978572959074\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:45 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=14000 train binary_classification_cross_entropy <loss>=0.0793446452027\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:51 INFO 139806301841216] Epoch[0] Batch [15000]#011Speed: 173157.11 samples/sec#011binary_classification_accuracy=0.979061#011binary_classification_cross_entropy=0.078150\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:51 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=15000 train binary_classification_accuracy <score>=0.979060729285\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:51 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, batch=15000 train binary_classification_cross_entropy <loss>=0.0781498462497\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:53 INFO 139806301841216] Epoch[0] Train-binary_classification_accuracy=0.979179\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:53 INFO 139806301841216] Epoch[0] Train-binary_classification_cross_entropy=0.077868\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:53 INFO 139806301841216] Epoch[0] Time cost=88.900\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:53 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, train binary_classification_accuracy <score>=0.979178784111\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:53 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy <loss>=0.0778683652378\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:58 INFO 139806301841216] Num unique classes of label: [0. 1.]\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:59 INFO 139806301841216] #quality_metric: host=algo-1, epoch=0, validation discriminator_auc <score>=0.990609243174\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}, \"update.time\": {\"count\": 1, \"max\": 101200.58798789978, \"sum\": 101200.58798789978, \"min\": 101200.58798789978}}, \"EndTime\": 1601736059.828224, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601735958.627368}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:59 INFO 139806301841216] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15281, \"sum\": 15281.0, \"min\": 15281}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 15281, \"sum\": 15281.0, \"min\": 15281}, \"Total Records Seen\": {\"count\": 1, \"max\": 15279383, \"sum\": 15279383.0, \"min\": 15279383}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 15279383, \"sum\": 15279383.0, \"min\": 15279383}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1601736059.828575, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\", \"epoch\": 0}, \"StartTime\": 1601735958.627588}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:59 INFO 139806301841216] #throughput_metric: host=algo-1, train throughput=150980.441545 records/second\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:59 WARNING 139806301841216] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/mxnet/module/base_module.py:502: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:59 WARNING 139806301841216] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:59 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_accuracy <score>=0.99\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:40:59 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_cross_entropy <loss>=0.060448299408\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:05 INFO 139806301841216] Epoch[1] Batch [1000]#011Speed: 171559.49 samples/sec#011binary_classification_accuracy=0.986078#011binary_classification_cross_entropy=0.059908\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:05 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=1000 train binary_classification_accuracy <score>=0.986077922078\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:05 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=1000 train binary_classification_cross_entropy <loss>=0.059907772693\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:11 INFO 139806301841216] Epoch[1] Batch [2000]#011Speed: 173202.76 samples/sec#011binary_classification_accuracy=0.986096#011binary_classification_cross_entropy=0.059403\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:11 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=2000 train binary_classification_accuracy <score>=0.986095952024\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:11 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=2000 train binary_classification_cross_entropy <loss>=0.059403165905\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:17 INFO 139806301841216] Epoch[1] Batch [3000]#011Speed: 171998.30 samples/sec#011binary_classification_accuracy=0.986035#011binary_classification_cross_entropy=0.059169\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:17 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=3000 train binary_classification_accuracy <score>=0.986035321559\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:17 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=3000 train binary_classification_cross_entropy <loss>=0.059169445041\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:23 INFO 139806301841216] Epoch[1] Batch [4000]#011Speed: 173200.57 samples/sec#011binary_classification_accuracy=0.986070#011binary_classification_cross_entropy=0.059020\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:23 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=4000 train binary_classification_accuracy <score>=0.986070482379\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:23 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=4000 train binary_classification_cross_entropy <loss>=0.0590200712695\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:28 INFO 139806301841216] Epoch[1] Batch [5000]#011Speed: 172357.96 samples/sec#011binary_classification_accuracy=0.986073#011binary_classification_cross_entropy=0.059043\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:28 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=5000 train binary_classification_accuracy <score>=0.986072985403\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:28 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=5000 train binary_classification_cross_entropy <loss>=0.0590425594611\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:34 INFO 139806301841216] Epoch[1] Batch [6000]#011Speed: 172174.17 samples/sec#011binary_classification_accuracy=0.986082#011binary_classification_cross_entropy=0.059054\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:34 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=6000 train binary_classification_accuracy <score>=0.986082319613\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:34 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=6000 train binary_classification_cross_entropy <loss>=0.0590535834388\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:40 INFO 139806301841216] Epoch[1] Batch [7000]#011Speed: 172559.66 samples/sec#011binary_classification_accuracy=0.986106#011binary_classification_cross_entropy=0.058924\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:40 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=7000 train binary_classification_accuracy <score>=0.986105699186\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:40 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=7000 train binary_classification_cross_entropy <loss>=0.0589241970132\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:46 INFO 139806301841216] Epoch[1] Batch [8000]#011Speed: 172723.06 samples/sec#011binary_classification_accuracy=0.986149#011binary_classification_cross_entropy=0.058773\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:46 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=8000 train binary_classification_accuracy <score>=0.986148731409\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:46 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=8000 train binary_classification_cross_entropy <loss>=0.0587730525667\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:52 INFO 139806301841216] Epoch[1] Batch [9000]#011Speed: 172085.47 samples/sec#011binary_classification_accuracy=0.986169#011binary_classification_cross_entropy=0.058722\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:52 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=9000 train binary_classification_accuracy <score>=0.986169092323\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:52 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=9000 train binary_classification_cross_entropy <loss>=0.0587224407709\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:57 INFO 139806301841216] Epoch[1] Batch [10000]#011Speed: 171915.73 samples/sec#011binary_classification_accuracy=0.986207#011binary_classification_cross_entropy=0.058604\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:57 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=10000 train binary_classification_accuracy <score>=0.986207279272\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:41:57 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=10000 train binary_classification_cross_entropy <loss>=0.058603621782\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:03 INFO 139806301841216] Epoch[1] Batch [11000]#011Speed: 171246.48 samples/sec#011binary_classification_accuracy=0.986254#011binary_classification_cross_entropy=0.058467\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:03 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=11000 train binary_classification_accuracy <score>=0.98625388601\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:03 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=11000 train binary_classification_cross_entropy <loss>=0.0584669304362\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:09 INFO 139806301841216] Epoch[1] Batch [12000]#011Speed: 171110.96 samples/sec#011binary_classification_accuracy=0.986276#011binary_classification_cross_entropy=0.058368\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:09 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=12000 train binary_classification_accuracy <score>=0.986276393634\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:09 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=12000 train binary_classification_cross_entropy <loss>=0.0583680540633\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:15 INFO 139806301841216] Epoch[1] Batch [13000]#011Speed: 171021.91 samples/sec#011binary_classification_accuracy=0.986279#011binary_classification_cross_entropy=0.058372\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:15 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=13000 train binary_classification_accuracy <score>=0.986279132374\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:15 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=13000 train binary_classification_cross_entropy <loss>=0.0583719197534\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:21 INFO 139806301841216] Epoch[1] Batch [14000]#011Speed: 171525.76 samples/sec#011binary_classification_accuracy=0.986297#011binary_classification_cross_entropy=0.058336\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:21 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=14000 train binary_classification_accuracy <score>=0.986296693093\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:21 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=14000 train binary_classification_cross_entropy <loss>=0.0583362952375\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:27 INFO 139806301841216] Epoch[1] Batch [15000]#011Speed: 171566.96 samples/sec#011binary_classification_accuracy=0.986321#011binary_classification_cross_entropy=0.058254\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:27 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=15000 train binary_classification_accuracy <score>=0.986320778615\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:27 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, batch=15000 train binary_classification_cross_entropy <loss>=0.058253586287\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:28 INFO 139806301841216] Epoch[1] Train-binary_classification_accuracy=0.986321\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:28 INFO 139806301841216] Epoch[1] Train-binary_classification_cross_entropy=0.058256\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:28 INFO 139806301841216] Epoch[1] Time cost=88.851\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:28 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, train binary_classification_accuracy <score>=0.986320725083\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:28 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, train binary_classification_cross_entropy <loss>=0.0582555036362\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:34 INFO 139806301841216] Num unique classes of label: [0. 1.]\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:35 INFO 139806301841216] #quality_metric: host=algo-1, epoch=1, validation discriminator_auc <score>=0.990990789345\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 95653.5918712616, \"sum\": 95653.5918712616, \"min\": 95653.5918712616}}, \"EndTime\": 1601736155.482432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601736059.828329}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:35 INFO 139806301841216] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15281, \"sum\": 15281.0, \"min\": 15281}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 30562, \"sum\": 30562.0, \"min\": 30562}, \"Total Records Seen\": {\"count\": 1, \"max\": 30558766, \"sum\": 30558766.0, \"min\": 30558766}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 15279383, \"sum\": 15279383.0, \"min\": 15279383}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1601736155.482803, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\", \"epoch\": 1}, \"StartTime\": 1601736059.828796}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:35 INFO 139806301841216] #throughput_metric: host=algo-1, train throughput=159735.75783 records/second\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:35 WARNING 139806301841216] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:35 WARNING 139806301841216] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:35 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_accuracy <score>=0.992\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:35 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_cross_entropy <loss>=0.0459280357361\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:41 INFO 139806301841216] Epoch[2] Batch [1000]#011Speed: 172674.38 samples/sec#011binary_classification_accuracy=0.986531#011binary_classification_cross_entropy=0.057335\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:41 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=1000 train binary_classification_accuracy <score>=0.986531468531\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:41 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=1000 train binary_classification_cross_entropy <loss>=0.0573353624106\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:47 INFO 139806301841216] Epoch[2] Batch [2000]#011Speed: 172277.36 samples/sec#011binary_classification_accuracy=0.986694#011binary_classification_cross_entropy=0.056711\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:47 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=2000 train binary_classification_accuracy <score>=0.986694152924\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:47 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=2000 train binary_classification_cross_entropy <loss>=0.0567110896818\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:52 INFO 139806301841216] Epoch[2] Batch [3000]#011Speed: 169979.08 samples/sec#011binary_classification_accuracy=0.986692#011binary_classification_cross_entropy=0.056594\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:52 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=3000 train binary_classification_accuracy <score>=0.986692102632\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:52 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=3000 train binary_classification_cross_entropy <loss>=0.0565942139274\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:58 INFO 139806301841216] Epoch[2] Batch [4000]#011Speed: 171813.87 samples/sec#011binary_classification_accuracy=0.986691#011binary_classification_cross_entropy=0.056519\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:58 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=4000 train binary_classification_accuracy <score>=0.986690577356\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:42:58 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=4000 train binary_classification_cross_entropy <loss>=0.056519240462\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:04 INFO 139806301841216] Epoch[2] Batch [5000]#011Speed: 170466.10 samples/sec#011binary_classification_accuracy=0.986695#011binary_classification_cross_entropy=0.056548\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:04 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=5000 train binary_classification_accuracy <score>=0.986694861028\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:04 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=5000 train binary_classification_cross_entropy <loss>=0.0565482477529\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:10 INFO 139806301841216] Epoch[2] Batch [6000]#011Speed: 171122.76 samples/sec#011binary_classification_accuracy=0.986665#011binary_classification_cross_entropy=0.056631\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:10 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=6000 train binary_classification_accuracy <score>=0.986665222463\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:10 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=6000 train binary_classification_cross_entropy <loss>=0.0566309676816\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:16 INFO 139806301841216] Epoch[2] Batch [7000]#011Speed: 172021.14 samples/sec#011binary_classification_accuracy=0.986679#011binary_classification_cross_entropy=0.056593\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:16 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=7000 train binary_classification_accuracy <score>=0.986679045851\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:16 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=7000 train binary_classification_cross_entropy <loss>=0.0565926435365\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:22 INFO 139806301841216] Epoch[2] Batch [8000]#011Speed: 171156.00 samples/sec#011binary_classification_accuracy=0.986722#011binary_classification_cross_entropy=0.056416\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:22 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=8000 train binary_classification_accuracy <score>=0.986722034746\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:22 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=8000 train binary_classification_cross_entropy <loss>=0.0564164096345\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:27 INFO 139806301841216] Epoch[2] Batch [9000]#011Speed: 171937.94 samples/sec#011binary_classification_accuracy=0.986745#011binary_classification_cross_entropy=0.056393\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:27 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=9000 train binary_classification_accuracy <score>=0.986745361626\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:27 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=9000 train binary_classification_cross_entropy <loss>=0.0563926551706\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:33 INFO 139806301841216] Epoch[2] Batch [10000]#011Speed: 171807.19 samples/sec#011binary_classification_accuracy=0.986762#011binary_classification_cross_entropy=0.056327\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:33 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=10000 train binary_classification_accuracy <score>=0.986762323768\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:33 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=10000 train binary_classification_cross_entropy <loss>=0.0563268216466\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:39 INFO 139806301841216] Epoch[2] Batch [11000]#011Speed: 171546.65 samples/sec#011binary_classification_accuracy=0.986783#011binary_classification_cross_entropy=0.056277\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:39 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=11000 train binary_classification_accuracy <score>=0.986782565221\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:39 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=11000 train binary_classification_cross_entropy <loss>=0.0562774180546\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:45 INFO 139806301841216] Epoch[2] Batch [12000]#011Speed: 171775.55 samples/sec#011binary_classification_accuracy=0.986788#011binary_classification_cross_entropy=0.056227\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:45 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=12000 train binary_classification_accuracy <score>=0.986788184318\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:45 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=12000 train binary_classification_cross_entropy <loss>=0.0562268590262\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:51 INFO 139806301841216] Epoch[2] Batch [13000]#011Speed: 171745.12 samples/sec#011binary_classification_accuracy=0.986783#011binary_classification_cross_entropy=0.056254\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:51 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=13000 train binary_classification_accuracy <score>=0.98678332436\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:51 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=13000 train binary_classification_cross_entropy <loss>=0.0562543951772\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:57 INFO 139806301841216] Epoch[2] Batch [14000]#011Speed: 171762.55 samples/sec#011binary_classification_accuracy=0.986777#011binary_classification_cross_entropy=0.056249\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:57 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=14000 train binary_classification_accuracy <score>=0.98677687308\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:43:57 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=14000 train binary_classification_cross_entropy <loss>=0.0562488034148\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:02 INFO 139806301841216] Epoch[2] Batch [15000]#011Speed: 170996.97 samples/sec#011binary_classification_accuracy=0.986784#011binary_classification_cross_entropy=0.056216\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:02 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=15000 train binary_classification_accuracy <score>=0.986784214386\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:02 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, batch=15000 train binary_classification_cross_entropy <loss>=0.0562164168244\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:04 INFO 139806301841216] Epoch[2] Train-binary_classification_accuracy=0.986783\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:04 INFO 139806301841216] Epoch[2] Train-binary_classification_cross_entropy=0.056221\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:04 INFO 139806301841216] Epoch[2] Time cost=89.063\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:04 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, train binary_classification_accuracy <score>=0.986782736732\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:04 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, train binary_classification_cross_entropy <loss>=0.0562207297455\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:10 INFO 139806301841216] Num unique classes of label: [0. 1.]\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:11 INFO 139806301841216] #quality_metric: host=algo-1, epoch=2, validation discriminator_auc <score>=0.990993696297\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 95873.59595298767, \"sum\": 95873.59595298767, \"min\": 95873.59595298767}}, \"EndTime\": 1601736251.356704, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601736155.482532}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:11 INFO 139806301841216] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15281, \"sum\": 15281.0, \"min\": 15281}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 45843, \"sum\": 45843.0, \"min\": 45843}, \"Total Records Seen\": {\"count\": 1, \"max\": 45838149, \"sum\": 45838149.0, \"min\": 45838149}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 15279383, \"sum\": 15279383.0, \"min\": 15279383}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1601736251.357023, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\", \"epoch\": 2}, \"StartTime\": 1601736155.483061}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:11 INFO 139806301841216] #throughput_metric: host=algo-1, train throughput=159369.285391 records/second\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:11 WARNING 139806301841216] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:11 WARNING 139806301841216] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:11 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_accuracy <score>=0.994\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:11 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_cross_entropy <loss>=0.038408454895\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:17 INFO 139806301841216] Epoch[3] Batch [1000]#011Speed: 172840.88 samples/sec#011binary_classification_accuracy=0.987056#011binary_classification_cross_entropy=0.055160\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:17 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=1000 train binary_classification_accuracy <score>=0.987055944056\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:17 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=1000 train binary_classification_cross_entropy <loss>=0.0551599350547\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:23 INFO 139806301841216] Epoch[3] Batch [2000]#011Speed: 170636.55 samples/sec#011binary_classification_accuracy=0.987005#011binary_classification_cross_entropy=0.055081\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:23 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=2000 train binary_classification_accuracy <score>=0.987005497251\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:23 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=2000 train binary_classification_cross_entropy <loss>=0.0550805940109\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:28 INFO 139806301841216] Epoch[3] Batch [3000]#011Speed: 171064.80 samples/sec#011binary_classification_accuracy=0.986973#011binary_classification_cross_entropy=0.055133\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:28 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=3000 train binary_classification_accuracy <score>=0.986973008997\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:28 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=3000 train binary_classification_cross_entropy <loss>=0.0551330104289\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:34 INFO 139806301841216] Epoch[3] Batch [4000]#011Speed: 172543.73 samples/sec#011binary_classification_accuracy=0.986966#011binary_classification_cross_entropy=0.055196\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:34 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=4000 train binary_classification_accuracy <score>=0.986965508623\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:34 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=4000 train binary_classification_cross_entropy <loss>=0.055196466864\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:40 INFO 139806301841216] Epoch[3] Batch [5000]#011Speed: 172167.63 samples/sec#011binary_classification_accuracy=0.986942#011binary_classification_cross_entropy=0.055276\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:40 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=5000 train binary_classification_accuracy <score>=0.986942211558\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:40 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=5000 train binary_classification_cross_entropy <loss>=0.05527563256\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:46 INFO 139806301841216] Epoch[3] Batch [6000]#011Speed: 172416.88 samples/sec#011binary_classification_accuracy=0.986931#011binary_classification_cross_entropy=0.055382\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:46 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=6000 train binary_classification_accuracy <score>=0.98693067822\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:46 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=6000 train binary_classification_cross_entropy <loss>=0.0553824154419\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:52 INFO 139806301841216] Epoch[3] Batch [7000]#011Speed: 172825.38 samples/sec#011binary_classification_accuracy=0.986935#011binary_classification_cross_entropy=0.055350\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:52 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=7000 train binary_classification_accuracy <score>=0.986934723611\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:52 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=7000 train binary_classification_cross_entropy <loss>=0.0553499040123\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:57 INFO 139806301841216] Epoch[3] Batch [8000]#011Speed: 173179.49 samples/sec#011binary_classification_accuracy=0.986937#011binary_classification_cross_entropy=0.055259\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:57 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=8000 train binary_classification_accuracy <score>=0.986936632921\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:44:57 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=8000 train binary_classification_cross_entropy <loss>=0.055259325488\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:03 INFO 139806301841216] Epoch[3] Batch [9000]#011Speed: 170592.92 samples/sec#011binary_classification_accuracy=0.986959#011binary_classification_cross_entropy=0.055195\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:03 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=9000 train binary_classification_accuracy <score>=0.986959226753\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:03 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=9000 train binary_classification_cross_entropy <loss>=0.0551949976773\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:09 INFO 139806301841216] Epoch[3] Batch [10000]#011Speed: 171744.88 samples/sec#011binary_classification_accuracy=0.986958#011binary_classification_cross_entropy=0.055178\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:09 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=10000 train binary_classification_accuracy <score>=0.98695790421\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:09 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=10000 train binary_classification_cross_entropy <loss>=0.0551775386317\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:15 INFO 139806301841216] Epoch[3] Batch [11000]#011Speed: 171053.13 samples/sec#011binary_classification_accuracy=0.986975#011binary_classification_cross_entropy=0.055141\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:15 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=11000 train binary_classification_accuracy <score>=0.986975365876\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:15 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=11000 train binary_classification_cross_entropy <loss>=0.0551407765051\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:21 INFO 139806301841216] Epoch[3] Batch [12000]#011Speed: 171914.76 samples/sec#011binary_classification_accuracy=0.986974#011binary_classification_cross_entropy=0.055077\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:21 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=12000 train binary_classification_accuracy <score>=0.986974168819\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:21 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=12000 train binary_classification_cross_entropy <loss>=0.0550766045116\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:27 INFO 139806301841216] Epoch[3] Batch [13000]#011Speed: 171063.51 samples/sec#011binary_classification_accuracy=0.986968#011binary_classification_cross_entropy=0.055103\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:27 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=13000 train binary_classification_accuracy <score>=0.98696831013\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:27 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=13000 train binary_classification_cross_entropy <loss>=0.05510259625\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:32 INFO 139806301841216] Epoch[3] Batch [14000]#011Speed: 171809.05 samples/sec#011binary_classification_accuracy=0.986957#011binary_classification_cross_entropy=0.055112\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:32 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=14000 train binary_classification_accuracy <score>=0.986956860224\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:32 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=14000 train binary_classification_cross_entropy <loss>=0.0551115316866\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:38 INFO 139806301841216] Epoch[3] Batch [15000]#011Speed: 171593.37 samples/sec#011binary_classification_accuracy=0.986966#011binary_classification_cross_entropy=0.055075\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:38 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=15000 train binary_classification_accuracy <score>=0.986965602293\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:38 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, batch=15000 train binary_classification_cross_entropy <loss>=0.0550754725375\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:40 INFO 139806301841216] Epoch[3] Train-binary_classification_accuracy=0.986963\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:40 INFO 139806301841216] Epoch[3] Train-binary_classification_cross_entropy=0.055087\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:40 INFO 139806301841216] Epoch[3] Time cost=88.911\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:40 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, train binary_classification_accuracy <score>=0.986962698776\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:40 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, train binary_classification_cross_entropy <loss>=0.055087389752\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:46 INFO 139806301841216] Num unique classes of label: [0. 1.]\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:46 INFO 139806301841216] #quality_metric: host=algo-1, epoch=3, validation discriminator_auc <score>=0.991101985056\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 95724.16400909424, \"sum\": 95724.16400909424, \"min\": 95724.16400909424}}, \"EndTime\": 1601736347.081451, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601736251.356803}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:47 INFO 139806301841216] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15281, \"sum\": 15281.0, \"min\": 15281}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 61124, \"sum\": 61124.0, \"min\": 61124}, \"Total Records Seen\": {\"count\": 1, \"max\": 61117532, \"sum\": 61117532.0, \"min\": 61117532}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 15279383, \"sum\": 15279383.0, \"min\": 15279383}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1601736347.081778, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\", \"epoch\": 3}, \"StartTime\": 1601736251.357241}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:47 INFO 139806301841216] #throughput_metric: host=algo-1, train throughput=159618.035474 records/second\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:47 WARNING 139806301841216] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:47 WARNING 139806301841216] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:47 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_accuracy <score>=0.988\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:47 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_cross_entropy <loss>=0.0592544250488\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:52 INFO 139806301841216] Epoch[4] Batch [1000]#011Speed: 171161.89 samples/sec#011binary_classification_accuracy=0.987015#011binary_classification_cross_entropy=0.054651\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:52 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=1000 train binary_classification_accuracy <score>=0.987014985015\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:52 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=1000 train binary_classification_cross_entropy <loss>=0.0546507419601\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:58 INFO 139806301841216] Epoch[4] Batch [2000]#011Speed: 171585.48 samples/sec#011binary_classification_accuracy=0.987060#011binary_classification_cross_entropy=0.054463\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:58 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=2000 train binary_classification_accuracy <score>=0.987060469765\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:45:58 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=2000 train binary_classification_cross_entropy <loss>=0.0544629154806\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:04 INFO 139806301841216] Epoch[4] Batch [3000]#011Speed: 171022.58 samples/sec#011binary_classification_accuracy=0.987044#011binary_classification_cross_entropy=0.054543\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:04 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=3000 train binary_classification_accuracy <score>=0.98704431856\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:04 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=3000 train binary_classification_cross_entropy <loss>=0.0545434764505\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:10 INFO 139806301841216] Epoch[4] Batch [4000]#011Speed: 171708.57 samples/sec#011binary_classification_accuracy=0.987088#011binary_classification_cross_entropy=0.054493\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:10 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=4000 train binary_classification_accuracy <score>=0.987087728068\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:10 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=4000 train binary_classification_cross_entropy <loss>=0.0544930564415\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:16 INFO 139806301841216] Epoch[4] Batch [5000]#011Speed: 171548.10 samples/sec#011binary_classification_accuracy=0.987061#011binary_classification_cross_entropy=0.054520\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:16 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=5000 train binary_classification_accuracy <score>=0.987060987802\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:16 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=5000 train binary_classification_cross_entropy <loss>=0.0545203151833\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:22 INFO 139806301841216] Epoch[4] Batch [6000]#011Speed: 171901.50 samples/sec#011binary_classification_accuracy=0.987040#011binary_classification_cross_entropy=0.054603\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:22 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=6000 train binary_classification_accuracy <score>=0.987040159973\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:22 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=6000 train binary_classification_cross_entropy <loss>=0.0546033045097\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:27 INFO 139806301841216] Epoch[4] Batch [7000]#011Speed: 171767.15 samples/sec#011binary_classification_accuracy=0.987049#011binary_classification_cross_entropy=0.054530\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:27 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=7000 train binary_classification_accuracy <score>=0.987048564491\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:27 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=7000 train binary_classification_cross_entropy <loss>=0.0545301807013\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:33 INFO 139806301841216] Epoch[4] Batch [8000]#011Speed: 170963.05 samples/sec#011binary_classification_accuracy=0.987063#011binary_classification_cross_entropy=0.054436\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:33 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=8000 train binary_classification_accuracy <score>=0.987062867142\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:33 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=8000 train binary_classification_cross_entropy <loss>=0.0544358782356\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:39 INFO 139806301841216] Epoch[4] Batch [9000]#011Speed: 172789.70 samples/sec#011binary_classification_accuracy=0.987042#011binary_classification_cross_entropy=0.054492\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:39 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=9000 train binary_classification_accuracy <score>=0.987041550939\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:39 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=9000 train binary_classification_cross_entropy <loss>=0.0544915369106\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:45 INFO 139806301841216] Epoch[4] Batch [10000]#011Speed: 171738.39 samples/sec#011binary_classification_accuracy=0.987043#011binary_classification_cross_entropy=0.054446\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:45 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=10000 train binary_classification_accuracy <score>=0.9870429957\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:45 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=10000 train binary_classification_cross_entropy <loss>=0.0544458772323\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:51 INFO 139806301841216] Epoch[4] Batch [11000]#011Speed: 171141.32 samples/sec#011binary_classification_accuracy=0.987059#011binary_classification_cross_entropy=0.054382\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:51 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=11000 train binary_classification_accuracy <score>=0.987058631034\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:51 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=11000 train binary_classification_cross_entropy <loss>=0.0543821079276\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:57 INFO 139806301841216] Epoch[4] Batch [12000]#011Speed: 172624.99 samples/sec#011binary_classification_accuracy=0.987063#011binary_classification_cross_entropy=0.054317\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:57 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=12000 train binary_classification_accuracy <score>=0.987063328056\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:46:57 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=12000 train binary_classification_cross_entropy <loss>=0.0543170872372\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:02 INFO 139806301841216] Epoch[4] Batch [13000]#011Speed: 170112.78 samples/sec#011binary_classification_accuracy=0.987059#011binary_classification_cross_entropy=0.054353\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:02 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=13000 train binary_classification_accuracy <score>=0.987058687793\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:02 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=13000 train binary_classification_cross_entropy <loss>=0.0543534121122\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:08 INFO 139806301841216] Epoch[4] Batch [14000]#011Speed: 170763.51 samples/sec#011binary_classification_accuracy=0.987059#011binary_classification_cross_entropy=0.054359\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:08 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=14000 train binary_classification_accuracy <score>=0.987059210056\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:08 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=14000 train binary_classification_cross_entropy <loss>=0.0543589816147\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:14 INFO 139806301841216] Epoch[4] Batch [15000]#011Speed: 171398.79 samples/sec#011binary_classification_accuracy=0.987059#011binary_classification_cross_entropy=0.054369\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:14 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=15000 train binary_classification_accuracy <score>=0.987059062729\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:14 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, batch=15000 train binary_classification_cross_entropy <loss>=0.0543692498447\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:16 INFO 139806301841216] Epoch[4] Train-binary_classification_accuracy=0.987059\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:16 INFO 139806301841216] Epoch[4] Train-binary_classification_cross_entropy=0.054380\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:16 INFO 139806301841216] Epoch[4] Time cost=89.109\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:16 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, train binary_classification_accuracy <score>=0.987059354754\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:16 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, train binary_classification_cross_entropy <loss>=0.0543797280136\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:22 INFO 139806301841216] Num unique classes of label: [0. 1.]\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:22 INFO 139806301841216] #quality_metric: host=algo-1, epoch=4, validation discriminator_auc <score>=0.991306109073\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 95855.34310340881, \"sum\": 95855.34310340881, \"min\": 95855.34310340881}}, \"EndTime\": 1601736442.937402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601736347.08155}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:22 INFO 139806301841216] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 15281, \"sum\": 15281.0, \"min\": 15281}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 76405, \"sum\": 76405.0, \"min\": 76405}, \"Total Records Seen\": {\"count\": 1, \"max\": 76396915, \"sum\": 76396915.0, \"min\": 76396915}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 15279383, \"sum\": 15279383.0, \"min\": 15279383}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1601736442.937779, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\", \"epoch\": 4}, \"StartTime\": 1601736347.082011}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:22 INFO 139806301841216] #throughput_metric: host=algo-1, train throughput=159399.526606 records/second\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:22 INFO 139806301841216] Saved checkpoint to \"/tmp/tmpFMOOEW/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:22 WARNING 139806301841216] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 0.3161430358886719, \"sum\": 0.3161430358886719, \"min\": 0.3161430358886719}}, \"EndTime\": 1601736442.972469, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601736442.937501}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:22 INFO 139806301841216] Saved checkpoint to \"/tmp/tmp2eOn3Z/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[10/03/2020 14:47:23 INFO 139806301841216] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 484602.098941803, \"sum\": 484602.098941803, \"min\": 484602.098941803}, \"setuptime\": {\"count\": 1, \"max\": 69.20099258422852, \"sum\": 69.20099258422852, \"min\": 69.20099258422852}}, \"EndTime\": 1601736443.005067, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ipinsights\"}, \"StartTime\": 1601736442.972525}\n",
      "\u001b[0m\n",
      "Training seconds: 569\n",
      "Billable seconds: 569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# Deploy best model\n",
    "tuned_predictor = ip_insights_tuner.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.m4.xlarge',\n",
    "    content_type='text/csv',\n",
    "    serializer=csv_serializer,\n",
    "    accept='application/json',\n",
    "    deserializer=json_deserializer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'dot_product': 3.177488088607788},\n",
       "  {'dot_product': 6.489774703979492},\n",
       "  {'dot_product': 1.9023349285125732},\n",
       "  {'dot_product': 1.148545265197754},\n",
       "  {'dot_product': 5.216797351837158}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a prediction against the SageMaker endpoint\n",
    "tuned_predictor.predict(inference_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have the best performing model from the training job! Now we can determine thresholds and make predictions just like we did with the inference endpoint [above](#Inference)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Transform\n",
    "Let's say we want to score all of the login events at the end of the day and aggregate flagged cases for investigators to look at in the morning. If we store the daily login events in S3, we can use IP Insights with [Amazon SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html) to run inference and store the IP Insights scores back in S3 for future analysis.\n",
    "\n",
    "Below, we take the training job from before and evaluate it on the validation data we put in S3.\n",
    "A critical parameter to set properly here is `split_type`. We'll specify 'Line', which ensures we only pass one line at a time to our algorithm for prediction. Had we not specified this, we'd attempt to pass all lines in our file, which would exhaust our transformer instance's memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Using already existing model: ipinsights-2020-10-03-13-56-19-559\n"
     ]
    }
   ],
   "source": [
    "transformer = ip_insights.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    ")\n",
    "\n",
    "transformer.transform(\n",
    "    s3_valid_data,\n",
    "    content_type='text/csv',\n",
    "    split_type='Line'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................\n",
      "\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[35mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[35mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] loading entry points\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] Loaded iterator creator application/x-ndarray for content type ('application/x-ndarray', '1.0')\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] Loaded iterator creator text/csv for content type ('text/csv', '1.0')\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] Loaded iterator creator application/x-ndarray for content type ('application/x-ndarray', '1.0')\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] Loaded iterator creator text/csv for content type ('text/csv', '1.0')\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] loading model...\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 WARNING 140339049625408] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] loading entry points\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] Loaded iterator creator application/x-ndarray for content type ('application/x-ndarray', '1.0')\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] Loaded iterator creator text/csv for content type ('text/csv', '1.0')\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] loaded request iterator application/json\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] loaded response encoder application/json\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] Loaded iterator creator application/x-ndarray for content type ('application/x-ndarray', '1.0')\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] Loaded iterator creator text/csv for content type ('text/csv', '1.0')\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] loading model...\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 WARNING 140339049625408] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] nvidia-smi took: 0.0252628326416 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] ...model loaded.\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:01 INFO 140339049625408] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[2020-10-03 15:05:01 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-10-03 15:05:01 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-10-03 15:05:01 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2020-10-03 15:05:01 +0000] [81] [INFO] Booting worker with pid: 81\u001b[0m\n",
      "\u001b[34m[2020-10-03 15:05:01 +0000] [90] [INFO] Booting worker with pid: 90\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601737501.735875, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"IPInsightsModel\"}, \"StartTime\": 1601737501.615437}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-10-03 15:05:01 +0000] [99] [INFO] Booting worker with pid: 99\u001b[0m\n",
      "\u001b[34m[2020-10-03 15:05:01 +0000] [108] [INFO] Booting worker with pid: 108\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] nvidia-smi took: 0.0252628326416 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] ...model loaded.\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:01 INFO 140339049625408] Number of server workers: 4\u001b[0m\n",
      "\u001b[35m[2020-10-03 15:05:01 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-10-03 15:05:01 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-10-03 15:05:01 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2020-10-03 15:05:01 +0000] [81] [INFO] Booting worker with pid: 81\u001b[0m\n",
      "\u001b[35m[2020-10-03 15:05:01 +0000] [90] [INFO] Booting worker with pid: 90\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"execution_parameters.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601737501.735875, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"IPInsightsModel\"}, \"StartTime\": 1601737501.615437}\n",
      "\u001b[0m\n",
      "\u001b[35m[2020-10-03 15:05:01 +0000] [99] [INFO] Booting worker with pid: 99\u001b[0m\n",
      "\u001b[35m[2020-10-03 15:05:01 +0000] [108] [INFO] Booting worker with pid: 108\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:02 WARNING 140339049625408] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:02 INFO 140339049625408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:02 WARNING 140339049625408] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:02 INFO 140339049625408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:02 WARNING 140339049625408] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[10/03/2020 15:05:02 INFO 140339049625408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:02 WARNING 140339049625408] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:02 INFO 140339049625408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:02 WARNING 140339049625408] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:02 INFO 140339049625408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:02 WARNING 140339049625408] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[10/03/2020 15:05:02 INFO 140339049625408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[32m2020-10-03T15:05:01.740:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601737504.868079, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"IPInsightsModel\"}, \"StartTime\": 1601737501.615437}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601737504.868079, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"IPInsightsModel\"}, \"StartTime\": 1601737501.615437}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601737506.436598, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"IPInsightsModel\"}, \"StartTime\": 1601737501.615437}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601737506.436598, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"IPInsightsModel\"}, \"StartTime\": 1601737501.615437}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601737506.457458, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"IPInsightsModel\"}, \"StartTime\": 1601737501.735963}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"Metrics\": {\"invocations.count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1601737506.457458, \"Dimensions\": {\"Host\": \"UNKNOWN\", \"Operation\": \"scoring\", \"Algorithm\": \"IPInsightsModel\"}, \"StartTime\": 1601737501.735963}\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Wait for Transform Job to finish\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Transform output is at: s3://sagemaker-us-east-1-640463227255/ipinsights-2020-10-03-14-58-59-689\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch Transform output is at: {}\".format(transformer.output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop and Delete the Endpoint\n",
    "If you are done with this model, then we should delete the endpoint before we close the notebook. Or else you will continue to pay for the endpoint while it is running. \n",
    "\n",
    "To do so execute the cell below. Alternately, you can navigate to the \"Endpoints\" tab in the SageMaker console, select the endpoint with the name stored in the variable endpoint_name, and select \"Delete\" from the \"Actions\" dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HyperparameterTuner.delete_endpoint() will be deprecated in SageMaker Python SDK v2. Please use the delete_endpoint() function on your predictor instead.\n"
     ]
    }
   ],
   "source": [
    "ip_insights_tuner.delete_endpoint()\n",
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
